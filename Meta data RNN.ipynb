{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51dac736",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle = pd.read_csv('Metadata Learning/cle_metadata.csv')\n",
    "vir = pd.read_csv('Metadata Learning/vir_metadata.csv')\n",
    "hun = pd.read_csv('Metadata Learning/hun_metadata.csv')\n",
    "#swi = pd.read_csv('Metadata Learning/swi_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.3</th>\n",
       "      <th>8.3</th>\n",
       "      <th>9.3</th>\n",
       "      <th>10.3</th>\n",
       "      <th>11.3</th>\n",
       "      <th>12.3</th>\n",
       "      <th>13.3</th>\n",
       "      <th>14.3</th>\n",
       "      <th>15.3</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.099659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872684</td>\n",
       "      <td>1.073222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.189892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.457568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589020</td>\n",
       "      <td>0.882712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.598649</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.849904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620106</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.943316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.594235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.488225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637975</td>\n",
       "      <td>0.901482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643992</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.224025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119797</td>\n",
       "      <td>0.067982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.657312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.285271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.199812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546282</td>\n",
       "      <td>0.756742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.321362</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.738161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520788</td>\n",
       "      <td>0.593032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.272287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.677983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.394613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627924</td>\n",
       "      <td>0.883689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.631824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.402882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570546</td>\n",
       "      <td>0.819004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.494263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586185</td>\n",
       "      <td>0.768512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.481180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.422223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578819</td>\n",
       "      <td>2.094908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.605741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586183</td>\n",
       "      <td>1.008786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.694298</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1.000110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861659</td>\n",
       "      <td>1.051443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.024231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.636214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.354551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525308</td>\n",
       "      <td>0.802558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.329718</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.683189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.050482</td>\n",
       "      <td>1.465678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.295259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.193003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392138</td>\n",
       "      <td>0.773857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.350265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.430704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.305973</td>\n",
       "      <td>1.338072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.838146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.834124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224826</td>\n",
       "      <td>0.598739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.036542</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.361153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.471989</td>\n",
       "      <td>1.519014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234061</td>\n",
       "      <td>0.570413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2         3         4    5         6    7         8  \\\n",
       "0    1.099659  0.0  0.0  0.872684  1.073222  0.0  1.486944  0.0  2.189892   \n",
       "1    1.849904  0.0  0.0  0.620106  0.811350  0.0  1.943316  0.0  2.594235   \n",
       "2    2.224025  0.0  0.0  0.119797  0.067982  0.0  2.657312  0.0  3.285271   \n",
       "3    1.738161  0.0  0.0  0.520788  0.593032  0.0  2.272287  0.0  2.677983   \n",
       "4    1.402882  0.0  0.0  0.570546  0.819004  0.0  1.494263  0.0  2.169592   \n",
       "..        ...  ...  ...       ...       ...  ...       ...  ...       ...   \n",
       "289  0.422223  0.0  0.0  1.578819  2.094908  0.0  0.299324  0.0  0.996861   \n",
       "290  1.000110  0.0  0.0  0.861659  1.051443  0.0  1.024231  0.0  1.636214   \n",
       "291  0.683189  0.0  0.0  1.050482  1.465678  0.0  0.638660  0.0  1.295259   \n",
       "292  0.430704  0.0  0.0  1.305973  1.338072  0.0  0.316563  0.0  0.838146   \n",
       "293  0.361153  0.0  0.0  1.471989  1.519014  0.0  0.451082  0.0  0.982792   \n",
       "\n",
       "       9  ...  7.3       8.3  9.3  10.3      11.3      12.3  13.3  14.3  \\\n",
       "0    0.0  ...  0.0  1.457568  0.0   0.0  0.589020  0.882712   0.0   0.0   \n",
       "1    0.0  ...  0.0  1.488225  0.0   0.0  0.637975  0.901482   0.0   0.0   \n",
       "2    0.0  ...  0.0  1.199812  0.0   0.0  0.546282  0.756742   0.0   0.0   \n",
       "3    0.0  ...  0.0  1.394613  0.0   0.0  0.627924  0.883689   0.0   0.0   \n",
       "4    0.0  ...  0.0  1.280468  0.0   0.0  0.586185  0.768512   0.0   0.0   \n",
       "..   ...  ...  ...       ...  ...   ...       ...       ...   ...   ...   \n",
       "289  0.0  ...  0.0  1.605741  0.0   0.0  0.586183  1.008786   0.0   0.0   \n",
       "290  0.0  ...  0.0  1.354551  0.0   0.0  0.525308  0.802558   0.0   0.0   \n",
       "291  0.0  ...  0.0  1.193003  0.0   0.0  0.392138  0.773857   0.0   0.0   \n",
       "292  0.0  ...  0.0  0.834124  0.0   0.0  0.224826  0.598739   0.0   0.0   \n",
       "293  0.0  ...  0.0  0.823496  0.0   0.0  0.234061  0.570413   0.0   0.0   \n",
       "\n",
       "         15.3  num  \n",
       "0    1.598649  0.0  \n",
       "1    1.643992  0.0  \n",
       "2    1.321362  0.0  \n",
       "3    1.631824  0.0  \n",
       "4    1.481180  0.0  \n",
       "..        ...  ...  \n",
       "289  1.694298  1.0  \n",
       "290  1.329718  1.0  \n",
       "291  1.350265  1.0  \n",
       "292  1.036542  0.0  \n",
       "293  0.965527  0.0  \n",
       "\n",
       "[797 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([cle,vir,hun])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:48]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c86ca29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 6s 49ms/step - loss: 0.4717 - accuracy: 0.7824\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.4035 - accuracy: 0.8443\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 1s 47ms/step - loss: 0.3690 - accuracy: 0.8555\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3583 - accuracy: 0.8668\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3631 - accuracy: 0.8499\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3443 - accuracy: 0.8743\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3468 - accuracy: 0.8780\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3439 - accuracy: 0.8762\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 0.3626 - accuracy: 0.8630\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 1s 51ms/step - loss: 0.3569 - accuracy: 0.8668\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 1s 51ms/step - loss: 0.3429 - accuracy: 0.8762\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3439 - accuracy: 0.8762\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3491 - accuracy: 0.8668\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3401 - accuracy: 0.8762\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3439 - accuracy: 0.8724\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3388 - accuracy: 0.8799\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3514 - accuracy: 0.8705\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3396 - accuracy: 0.8762\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3383 - accuracy: 0.8818\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3409 - accuracy: 0.8705\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 1s 53ms/step - loss: 0.3414 - accuracy: 0.8799\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 0.3306 - accuracy: 0.8799\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3207 - accuracy: 0.8799\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 1s 51ms/step - loss: 0.3165 - accuracy: 0.8856\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 1s 53ms/step - loss: 0.3353 - accuracy: 0.8893\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3242 - accuracy: 0.8762\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3286 - accuracy: 0.8687\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 1s 45ms/step - loss: 0.3212 - accuracy: 0.8874\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3131 - accuracy: 0.8780\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3044 - accuracy: 0.8893\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.2960 - accuracy: 0.8912\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3090 - accuracy: 0.8893\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3165 - accuracy: 0.8856\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.3183 - accuracy: 0.8893\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.2880 - accuracy: 0.8949\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.3286 - accuracy: 0.8649\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3261 - accuracy: 0.8762\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.3140 - accuracy: 0.8818\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.2954 - accuracy: 0.8949\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.2937 - accuracy: 0.8931\n",
      "[[100  16]\n",
      " [ 25 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       125\n",
      "           1       0.83      0.88      0.86       139\n",
      "\n",
      "    accuracy                           0.84       264\n",
      "   macro avg       0.85      0.84      0.84       264\n",
      "weighted avg       0.85      0.84      0.84       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(48, 1)))\n",
    "model.add(SimpleRNN(units=32, return_sequences=True))\n",
    "model.add(SimpleRNN(units=16))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15bc89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
