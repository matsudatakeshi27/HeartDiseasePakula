{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f37971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Activation, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f4ebcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = ['cle_metadata', 'vir_metadata', 'hun_metadata', 'swi_metadata']\n",
    "\n",
    "for file in data_files:\n",
    "    data = pd.read_csv('../TrainTestData/' + file + '.csv', index_col = 0)\n",
    "    \n",
    "    X = data.iloc[:, :-1]\n",
    "    Y = data.iloc[:, -1]\n",
    "    \n",
    "    Y_binary = Y.apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
    "    \n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    test = pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    train.to_csv('../TrainTestData/'+ file + \"_train.csv\")\n",
    "    test.to_csv('../TrainTestData/' + file + \"_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05fdffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_files = ['cle_metadata_train.csv','cle_metadata_test.csv','hun_metadata_train.csv','hun_metadata_test.csv','swi_metadata_train.csv','swi_metadata_test.csv','vir_metadata_train.csv','vir_metadata_test.csv']\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for file in data_files:\n",
    "    data = pd.read_csv('../TrainTestData/' + file)\n",
    "    \n",
    "    X = data.iloc[:, :-1]\n",
    "    Y = data.iloc[:, -1]\n",
    "    \n",
    "    Y_binary = Y.apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Extract the name from the file path\n",
    "    name = file.split('.')[0]\n",
    "    \n",
    "    # Store the dataset components in a dictionary\n",
    "    datasets[name] = {'X': X, 'Y': Y, 'Y_binary': Y_binary}\n",
    "\n",
    "# Unpack the dictionary values in a loop\n",
    "variables = ['cle', 'hun', 'swi', 'vir']\n",
    "train_test = ['train', 'test']\n",
    "\n",
    "for var in variables:\n",
    "    for tt in train_test:\n",
    "        X, Y, Y_binary = datasets[f'{var}_metadata_{tt}'].values()\n",
    "        globals()[f'{var}_X_{tt}'] = X\n",
    "        globals()[f'{var}_Y_{tt}'] = Y\n",
    "        globals()[f'{var}_Y_{tt}_binary'] = Y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8171119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([cle_X_test,hun_X_test,swi_X_test,vir_X_test])\n",
    "y_test = pd.concat([cle_Y_test_binary,hun_Y_test_binary,swi_Y_test_binary,vir_Y_test_binary])\n",
    "\n",
    "X_train = pd.concat([cle_X_train,hun_X_train,swi_X_train,vir_X_train])\n",
    "y_train = pd.concat([cle_Y_train_binary,hun_Y_train_binary,swi_Y_train_binary,vir_Y_train_binary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc05e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients():\n",
    "    cle_zip = list(zip(cle_X_train.values,cle_Y_train_binary))\n",
    "    hun_zip = list(zip(hun_X_train.values,hun_Y_train_binary))\n",
    "    vir_zip = list(zip(vir_X_train.values,vir_Y_train_binary))\n",
    "    swi_zip = list(zip(swi_X_train.values,swi_Y_train_binary))\n",
    "    \n",
    "    shards = [cle_zip, hun_zip, vir_zip,swi_zip]\n",
    "    client_names = [\"client_1\",\"client_2\",\"client_3\",\"client_4\"]\n",
    "    dic = {client_names[i] : shards[i] for i in range(len(client_names))}\n",
    "    return dic\n",
    "\n",
    "\n",
    "def batch_data(data_shard, bs=32):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)\n",
    "\n",
    "\n",
    "class CNN:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(64,1)))\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "        model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    length = len(y_test)\n",
    "    Y_test = tf.reshape(Y_test,(length,1))\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), Y_test)\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c94fcc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 0 | global_acc: 81.949% | global_loss: 0.6751745939254761\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 1 | global_acc: 82.310% | global_loss: 0.6596728563308716\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 2 | global_acc: 82.671% | global_loss: 0.6424713134765625\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 3 | global_acc: 83.394% | global_loss: 0.6251180768013\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 4 | global_acc: 83.032% | global_loss: 0.6080196499824524\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 5 | global_acc: 83.032% | global_loss: 0.5926786661148071\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 6 | global_acc: 83.032% | global_loss: 0.5816078186035156\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 7 | global_acc: 83.032% | global_loss: 0.5732547640800476\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 8 | global_acc: 83.032% | global_loss: 0.5679089426994324\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 9 | global_acc: 83.032% | global_loss: 0.5622199177742004\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 10 | global_acc: 83.394% | global_loss: 0.5587852001190186\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 11 | global_acc: 83.032% | global_loss: 0.5555699467658997\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 12 | global_acc: 82.671% | global_loss: 0.5531630516052246\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 13 | global_acc: 83.394% | global_loss: 0.552279531955719\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 14 | global_acc: 83.755% | global_loss: 0.550538957118988\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 15 | global_acc: 83.032% | global_loss: 0.5512139201164246\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 16 | global_acc: 83.394% | global_loss: 0.549198567867279\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 17 | global_acc: 83.394% | global_loss: 0.5487508177757263\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 18 | global_acc: 83.032% | global_loss: 0.548906147480011\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 19 | global_acc: 83.394% | global_loss: 0.5489653944969177\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 20 | global_acc: 83.394% | global_loss: 0.5478960871696472\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 21 | global_acc: 83.032% | global_loss: 0.5492368936538696\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 22 | global_acc: 82.671% | global_loss: 0.5480115413665771\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 23 | global_acc: 83.394% | global_loss: 0.5481616854667664\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 24 | global_acc: 83.032% | global_loss: 0.5477349758148193\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 25 | global_acc: 83.394% | global_loss: 0.5464139580726624\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 26 | global_acc: 83.032% | global_loss: 0.5461203455924988\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 27 | global_acc: 83.394% | global_loss: 0.5453441143035889\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 28 | global_acc: 83.394% | global_loss: 0.546044111251831\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 29 | global_acc: 83.032% | global_loss: 0.5451046228408813\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 30 | global_acc: 83.394% | global_loss: 0.5456041097640991\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 31 | global_acc: 83.032% | global_loss: 0.5450049042701721\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 32 | global_acc: 83.032% | global_loss: 0.5455209016799927\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 33 | global_acc: 82.671% | global_loss: 0.5439327359199524\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 34 | global_acc: 82.671% | global_loss: 0.5460574626922607\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 35 | global_acc: 83.032% | global_loss: 0.5457665920257568\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 36 | global_acc: 83.032% | global_loss: 0.5457214713096619\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 37 | global_acc: 83.032% | global_loss: 0.5450412034988403\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 38 | global_acc: 83.394% | global_loss: 0.545077383518219\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 39 | global_acc: 83.032% | global_loss: 0.5451751947402954\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 40 | global_acc: 82.671% | global_loss: 0.5450479388237\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 41 | global_acc: 83.032% | global_loss: 0.5463185906410217\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 42 | global_acc: 83.032% | global_loss: 0.5443757176399231\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 43 | global_acc: 82.671% | global_loss: 0.5447332859039307\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 44 | global_acc: 83.032% | global_loss: 0.5446500778198242\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 45 | global_acc: 83.032% | global_loss: 0.5454831123352051\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 46 | global_acc: 83.032% | global_loss: 0.5439178347587585\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 47 | global_acc: 83.032% | global_loss: 0.543769121170044\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 48 | global_acc: 83.032% | global_loss: 0.5443964004516602\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 49 | global_acc: 83.394% | global_loss: 0.5429606437683105\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 50 | global_acc: 83.032% | global_loss: 0.5429609417915344\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 51 | global_acc: 83.032% | global_loss: 0.5439782738685608\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 52 | global_acc: 82.671% | global_loss: 0.5442224740982056\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 53 | global_acc: 83.032% | global_loss: 0.5455681085586548\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 54 | global_acc: 83.755% | global_loss: 0.5448445081710815\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 55 | global_acc: 83.032% | global_loss: 0.5448811650276184\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 56 | global_acc: 83.032% | global_loss: 0.5456305146217346\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 57 | global_acc: 83.394% | global_loss: 0.5444891452789307\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 58 | global_acc: 83.755% | global_loss: 0.5442354679107666\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "comm_round: 59 | global_acc: 83.755% | global_loss: 0.5420403480529785\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 60 | global_acc: 83.032% | global_loss: 0.5432322025299072\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 61 | global_acc: 83.755% | global_loss: 0.5439239740371704\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 62 | global_acc: 83.755% | global_loss: 0.5435044169425964\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 63 | global_acc: 83.755% | global_loss: 0.5436491966247559\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 64 | global_acc: 83.032% | global_loss: 0.5430417656898499\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 65 | global_acc: 83.032% | global_loss: 0.5420085191726685\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 66 | global_acc: 83.755% | global_loss: 0.5431854724884033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 67 | global_acc: 83.394% | global_loss: 0.541802167892456\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 68 | global_acc: 83.032% | global_loss: 0.5427709817886353\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 69 | global_acc: 83.755% | global_loss: 0.5463430285453796\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 70 | global_acc: 83.755% | global_loss: 0.5435642600059509\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 71 | global_acc: 83.032% | global_loss: 0.5432946085929871\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 72 | global_acc: 83.755% | global_loss: 0.5429310202598572\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 73 | global_acc: 83.755% | global_loss: 0.5419237613677979\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 74 | global_acc: 83.032% | global_loss: 0.5427101850509644\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 75 | global_acc: 83.032% | global_loss: 0.5427268147468567\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 76 | global_acc: 83.394% | global_loss: 0.5438041090965271\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 77 | global_acc: 83.755% | global_loss: 0.5437203645706177\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 78 | global_acc: 83.755% | global_loss: 0.5437803268432617\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 79 | global_acc: 83.394% | global_loss: 0.5435314774513245\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 80 | global_acc: 83.032% | global_loss: 0.5437354445457458\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 81 | global_acc: 83.032% | global_loss: 0.5449908971786499\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 82 | global_acc: 83.032% | global_loss: 0.5433565974235535\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 83 | global_acc: 83.755% | global_loss: 0.5452589988708496\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 84 | global_acc: 83.394% | global_loss: 0.5424827337265015\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 85 | global_acc: 83.755% | global_loss: 0.5422650575637817\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 86 | global_acc: 83.755% | global_loss: 0.542655885219574\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 87 | global_acc: 83.755% | global_loss: 0.5431526303291321\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 88 | global_acc: 83.755% | global_loss: 0.543322741985321\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 89 | global_acc: 83.394% | global_loss: 0.5436928272247314\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 90 | global_acc: 83.032% | global_loss: 0.5430176258087158\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 91 | global_acc: 83.394% | global_loss: 0.5452666282653809\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 92 | global_acc: 83.755% | global_loss: 0.5446853041648865\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 93 | global_acc: 83.755% | global_loss: 0.5436846613883972\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 94 | global_acc: 83.755% | global_loss: 0.5442727208137512\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 95 | global_acc: 83.755% | global_loss: 0.5423478484153748\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 96 | global_acc: 83.755% | global_loss: 0.5435080528259277\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 97 | global_acc: 84.116% | global_loss: 0.543164074420929\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 98 | global_acc: 83.755% | global_loss: 0.5438311100006104\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "comm_round: 99 | global_acc: 83.755% | global_loss: 0.5445494055747986\n",
      "9/9 [==============================] - 0s 4ms/step\n",
      "comm_round: 1 | global_acc: 83.032% | global_loss: 0.5416183471679688\n"
     ]
    }
   ],
   "source": [
    "#create clients\n",
    "clients = create_clients()\n",
    "\n",
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "\n",
    "comms_round = 100\n",
    "    \n",
    "#create optimizer\n",
    "lr = 0.01 \n",
    "loss='sparse_categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(lr=lr, decay=lr / comms_round, momentum=0.9) \n",
    "\n",
    "#initialize global model\n",
    "smlp_global = CNN()\n",
    "global_model = smlp_global.build(64, 2)\n",
    "        \n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = CNN()\n",
    "        local_model = smlp_local.build(64, 2)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(250)\n",
    "        smlp_SGD = CNN()\n",
    "        SGD_model = smlp_SGD.build(64, 2) \n",
    "\n",
    "        SGD_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "# fit the SGD training data to model\n",
    "_ = SGD_model.fit(SGD_dataset, epochs=100, verbose=0)\n",
    "\n",
    "#test the SGD global model and print out metrics\n",
    "for(X_test, Y_test) in test_batched:\n",
    "        SGD_acc, SGD_loss = test_model(X_test, Y_test, SGD_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b13ff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_predictions = np.argmax(SGD_model.predict(X_test),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bc551a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86,  12],\n",
       "       [ 35, 144]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_predictions, Y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a83e0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8776    0.7107    0.7854       121\n",
      "           1     0.8045    0.9231    0.8597       156\n",
      "\n",
      "    accuracy                         0.8303       277\n",
      "   macro avg     0.8410    0.8169    0.8225       277\n",
      "weighted avg     0.8364    0.8303    0.8272       277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_predictions,digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56495b0e",
   "metadata": {},
   "source": [
    "# Testing on each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac91bf",
   "metadata": {},
   "source": [
    "## Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec02651a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "[[38  5]\n",
      " [10 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7917    0.8837    0.8352        43\n",
      "           1     0.8837    0.7917    0.8352        48\n",
      "\n",
      "    accuracy                         0.8352        91\n",
      "   macro avg     0.8377    0.8377    0.8352        91\n",
      "weighted avg     0.8402    0.8352    0.8352        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_cle = np.argmax(SGD_model.predict(cle_X_test),axis = 1)\n",
    "cm_cle = confusion_matrix(Y_cle, cle_Y_test_binary)\n",
    "print(cm_cle)\n",
    "print(classification_report(Y_cle, cle_Y_test_binary,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc246b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 19, 22, 27, 28, 46, 53, 62, 63, 73, 74, 77, 81, 85, 86]\n"
     ]
    }
   ],
   "source": [
    "mismatch = [i for i, (a,b) in enumerate(zip(Y_cle, cle_Y_test_binary)) if a != b]\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbe636",
   "metadata": {},
   "source": [
    "## Long Beach, VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d4cc1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "[[ 3  2]\n",
      " [12 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2000    0.6000    0.3000         5\n",
      "           1     0.9556    0.7818    0.8600        55\n",
      "\n",
      "    accuracy                         0.7667        60\n",
      "   macro avg     0.5778    0.6909    0.5800        60\n",
      "weighted avg     0.8926    0.7667    0.8133        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_vir = np.argmax(SGD_model.predict(vir_X_test),axis = 1)\n",
    "cm_vir = confusion_matrix(Y_vir, vir_Y_test_binary)\n",
    "print(cm_vir)\n",
    "print(classification_report(Y_vir, vir_Y_test_binary,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8109d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6, 7, 8, 10, 19, 20, 23, 26, 35, 41, 48, 53, 58]\n"
     ]
    }
   ],
   "source": [
    "mismatch = [i for i, (a,b) in enumerate(zip(Y_vir, vir_Y_test_binary)) if a != b]\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d84807",
   "metadata": {},
   "source": [
    "## Hungary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c031520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "[[44  2]\n",
      " [11 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.9565    0.8713        46\n",
      "           1     0.9412    0.7442    0.8312        43\n",
      "\n",
      "    accuracy                         0.8539        89\n",
      "   macro avg     0.8706    0.8504    0.8512        89\n",
      "weighted avg     0.8682    0.8539    0.8519        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_hun = np.argmax(SGD_model.predict(hun_X_test),axis = 1)\n",
    "cm_hun = confusion_matrix(Y_hun, hun_Y_test_binary)\n",
    "print(cm_hun)\n",
    "print(classification_report(Y_hun, hun_Y_test_binary,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "235f1fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 12, 22, 35, 55, 61, 62, 67, 68, 70, 71, 83, 88]\n"
     ]
    }
   ],
   "source": [
    "mismatch = [i for i, (a,b) in enumerate(zip(Y_hun, hun_Y_test_binary)) if a != b]\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015703aa",
   "metadata": {},
   "source": [
    "## Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e837211",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "[[ 1  3]\n",
      " [ 2 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3333    0.2500    0.2857         4\n",
      "           1     0.9118    0.9394    0.9254        33\n",
      "\n",
      "    accuracy                         0.8649        37\n",
      "   macro avg     0.6225    0.5947    0.6055        37\n",
      "weighted avg     0.8492    0.8649    0.8562        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_swi = np.argmax(SGD_model.predict(swi_X_test),axis = 1)\n",
    "cm_swi = confusion_matrix(Y_swi, swi_Y_test_binary)\n",
    "print(cm_swi)\n",
    "print(classification_report(Y_swi, swi_Y_test_binary,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05678efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10, 12, 15, 36]\n"
     ]
    }
   ],
   "source": [
    "mismatch = [i for i, (a,b) in enumerate(zip(Y_swi, swi_Y_test_binary)) if a != b]\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bff79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6a3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748ba22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
