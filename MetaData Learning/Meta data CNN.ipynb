{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1ee0e",
   "metadata": {},
   "source": [
    "# CNN metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51dac736",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle = pd.read_csv('cle_metadata_cnn.csv')\n",
    "vir = pd.read_csv('vir_metadata_cnn.csv')\n",
    "hun = pd.read_csv('hun_metadata_cnn.csv')\n",
    "swi = pd.read_csv('swi_metadata_cnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.3</th>\n",
       "      <th>8.3</th>\n",
       "      <th>9.3</th>\n",
       "      <th>10.3</th>\n",
       "      <th>11.3</th>\n",
       "      <th>12.3</th>\n",
       "      <th>13.3</th>\n",
       "      <th>14.3</th>\n",
       "      <th>15.3</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.850346</td>\n",
       "      <td>0.700405</td>\n",
       "      <td>0.427932</td>\n",
       "      <td>0.631793</td>\n",
       "      <td>0.720650</td>\n",
       "      <td>0.805797</td>\n",
       "      <td>0.555187</td>\n",
       "      <td>0.908639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.858736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.336825</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900102</td>\n",
       "      <td>1.238794</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>1.067564</td>\n",
       "      <td>1.226179</td>\n",
       "      <td>0.716775</td>\n",
       "      <td>0.488568</td>\n",
       "      <td>0.723180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.948065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.372884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.425866</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202576</td>\n",
       "      <td>1.539479</td>\n",
       "      <td>0.914987</td>\n",
       "      <td>1.211709</td>\n",
       "      <td>1.484435</td>\n",
       "      <td>0.342889</td>\n",
       "      <td>1.055182</td>\n",
       "      <td>1.424387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.634343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.112418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.043138</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664326</td>\n",
       "      <td>1.246355</td>\n",
       "      <td>0.639915</td>\n",
       "      <td>0.900147</td>\n",
       "      <td>1.269826</td>\n",
       "      <td>0.557118</td>\n",
       "      <td>0.816253</td>\n",
       "      <td>1.045733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.868872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.317322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.268249</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961716</td>\n",
       "      <td>0.693969</td>\n",
       "      <td>0.462445</td>\n",
       "      <td>0.580937</td>\n",
       "      <td>0.851637</td>\n",
       "      <td>0.836276</td>\n",
       "      <td>0.611334</td>\n",
       "      <td>0.868884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.783576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.222539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.046181</td>\n",
       "      <td>0.079782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078642</td>\n",
       "      <td>0.192834</td>\n",
       "      <td>1.641056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.278238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.561664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.821322</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.831266</td>\n",
       "      <td>0.296626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375618</td>\n",
       "      <td>0.379790</td>\n",
       "      <td>1.366388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.111198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.465579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.593416</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.047585</td>\n",
       "      <td>0.057311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123829</td>\n",
       "      <td>0.080624</td>\n",
       "      <td>1.714231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.132200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.489336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.642818</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.216803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.804639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.032758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.430741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.525313</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.637371</td>\n",
       "      <td>0.261230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222113</td>\n",
       "      <td>0.304262</td>\n",
       "      <td>1.250580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.857294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.327937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.280599</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6  \\\n",
       "0    0.0  0.850346  0.700405  0.427932  0.631793  0.720650  0.805797   \n",
       "1    0.0  0.900102  1.238794  0.455062  1.067564  1.226179  0.716775   \n",
       "2    0.0  0.202576  1.539479  0.914987  1.211709  1.484435  0.342889   \n",
       "3    0.0  0.664326  1.246355  0.639915  0.900147  1.269826  0.557118   \n",
       "4    0.0  0.961716  0.693969  0.462445  0.580937  0.851637  0.836276   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "118  0.0  2.046181  0.079782  0.000000  0.078642  0.192834  1.641056   \n",
       "119  0.0  1.831266  0.296626  0.000000  0.375618  0.379790  1.366388   \n",
       "120  0.0  2.047585  0.057311  0.000000  0.123829  0.080624  1.714231   \n",
       "121  0.0  2.216803  0.000000  0.000000  0.000000  0.000000  1.804639   \n",
       "122  0.0  1.637371  0.261230  0.000000  0.222113  0.304262  1.250580   \n",
       "\n",
       "            7         8    9  ...       7.3  8.3  9.3      10.3  11.3  12.3  \\\n",
       "0    0.555187  0.908639  0.0  ...  1.858736  0.0  0.0  1.280513   0.0   0.0   \n",
       "1    0.488568  0.723180  0.0  ...  1.948065  0.0  0.0  1.372884   0.0   0.0   \n",
       "2    1.055182  1.424387  0.0  ...  1.634343  0.0  0.0  1.112418   0.0   0.0   \n",
       "3    0.816253  1.045733  0.0  ...  1.868872  0.0  0.0  1.317322   0.0   0.0   \n",
       "4    0.611334  0.868884  0.0  ...  1.783576  0.0  0.0  1.222539   0.0   0.0   \n",
       "..        ...       ...  ...  ...       ...  ...  ...       ...   ...   ...   \n",
       "118  0.000000  0.000000  0.0  ...  2.278238  0.0  0.0  1.561664   0.0   0.0   \n",
       "119  0.000000  0.000000  0.0  ...  2.111198  0.0  0.0  1.465579   0.0   0.0   \n",
       "120  0.000000  0.000000  0.0  ...  2.132200  0.0  0.0  1.489336   0.0   0.0   \n",
       "121  0.000000  0.000000  0.0  ...  2.032758  0.0  0.0  1.430741   0.0   0.0   \n",
       "122  0.000000  0.000000  0.0  ...  1.857294  0.0  0.0  1.327937   0.0   0.0   \n",
       "\n",
       "     13.3  14.3      15.3   num  \n",
       "0     0.0   0.0  2.336825  0.00  \n",
       "1     0.0   0.0  2.425866  0.00  \n",
       "2     0.0   0.0  2.043138  0.00  \n",
       "3     0.0   0.0  2.268249  0.00  \n",
       "4     0.0   0.0  2.169000  0.00  \n",
       "..    ...   ...       ...   ...  \n",
       "118   0.0   0.0  2.821322  0.75  \n",
       "119   0.0   0.0  2.593416  0.50  \n",
       "120   0.0   0.0  2.642818  1.00  \n",
       "121   0.0   0.0  2.525313  0.25  \n",
       "122   0.0   0.0  2.280599  0.25  \n",
       "\n",
       "[920 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([cle,vir,hun,swi])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train; X_test; Y_train_binary; Y_test_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e623e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c86ca29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.4556 - accuracy: 0.8409\n",
      "Epoch 2/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3599 - accuracy: 0.8539\n",
      "Epoch 3/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3470 - accuracy: 0.8604\n",
      "Epoch 4/1000\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3586 - accuracy: 0.8539\n",
      "Epoch 5/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3384 - accuracy: 0.8669\n",
      "Epoch 6/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3403 - accuracy: 0.8766\n",
      "Epoch 7/1000\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.3358 - accuracy: 0.8766\n",
      "Epoch 8/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3347 - accuracy: 0.8718\n",
      "Epoch 9/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3380 - accuracy: 0.8685\n",
      "Epoch 10/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3351 - accuracy: 0.8782\n",
      "Epoch 11/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3385 - accuracy: 0.8799\n",
      "Epoch 12/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3377 - accuracy: 0.8766\n",
      "Epoch 13/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3226 - accuracy: 0.8718\n",
      "Epoch 14/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3341 - accuracy: 0.8636\n",
      "Epoch 15/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3336 - accuracy: 0.8750\n",
      "Epoch 16/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3286 - accuracy: 0.8685\n",
      "Epoch 17/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3193 - accuracy: 0.8847\n",
      "Epoch 18/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3134 - accuracy: 0.8799\n",
      "Epoch 19/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3186 - accuracy: 0.8864\n",
      "Epoch 20/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3082 - accuracy: 0.8847\n",
      "Epoch 21/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3096 - accuracy: 0.8799\n",
      "Epoch 22/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3126 - accuracy: 0.8831\n",
      "Epoch 23/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3032 - accuracy: 0.8815\n",
      "Epoch 24/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3039 - accuracy: 0.8896\n",
      "Epoch 25/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3022 - accuracy: 0.8815\n",
      "Epoch 26/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2936 - accuracy: 0.8912\n",
      "Epoch 27/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2877 - accuracy: 0.8831\n",
      "Epoch 28/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2908 - accuracy: 0.8896\n",
      "Epoch 29/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2857 - accuracy: 0.8880\n",
      "Epoch 30/1000\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2986 - accuracy: 0.8880\n",
      "Epoch 31/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2850 - accuracy: 0.9042\n",
      "Epoch 32/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2848 - accuracy: 0.8961\n",
      "Epoch 33/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2852 - accuracy: 0.8896\n",
      "Epoch 34/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2778 - accuracy: 0.8945\n",
      "Epoch 35/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2664 - accuracy: 0.8961\n",
      "Epoch 36/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2737 - accuracy: 0.9026\n",
      "Epoch 37/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2558 - accuracy: 0.8945\n",
      "Epoch 38/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2802 - accuracy: 0.8831\n",
      "Epoch 39/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2637 - accuracy: 0.8896\n",
      "Epoch 40/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2526 - accuracy: 0.8929\n",
      "Epoch 41/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2494 - accuracy: 0.8977\n",
      "Epoch 42/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2571 - accuracy: 0.8912\n",
      "Epoch 43/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2597 - accuracy: 0.8880\n",
      "Epoch 44/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2422 - accuracy: 0.9042\n",
      "Epoch 45/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2391 - accuracy: 0.9123\n",
      "Epoch 46/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.2667 - accuracy: 0.8847\n",
      "Epoch 47/1000\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2405 - accuracy: 0.9075\n",
      "Epoch 48/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2121 - accuracy: 0.9156\n",
      "Epoch 49/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.2152 - accuracy: 0.9140\n",
      "Epoch 50/1000\n",
      "20/20 [==============================] - 1s 36ms/step - loss: 0.1983 - accuracy: 0.9205\n",
      "Epoch 51/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1988 - accuracy: 0.9123\n",
      "Epoch 52/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2092 - accuracy: 0.9156\n",
      "Epoch 53/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2115 - accuracy: 0.9188\n",
      "Epoch 54/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1962 - accuracy: 0.9156\n",
      "Epoch 55/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1936 - accuracy: 0.9302\n",
      "Epoch 56/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1831 - accuracy: 0.9237\n",
      "Epoch 57/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1955 - accuracy: 0.9205\n",
      "Epoch 58/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1951 - accuracy: 0.9269\n",
      "Epoch 59/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1789 - accuracy: 0.9253\n",
      "Epoch 60/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1767 - accuracy: 0.9221\n",
      "Epoch 61/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1813 - accuracy: 0.9156\n",
      "Epoch 62/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1708 - accuracy: 0.9318\n",
      "Epoch 63/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1519 - accuracy: 0.9367\n",
      "Epoch 64/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1754 - accuracy: 0.9351\n",
      "Epoch 65/1000\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.1603 - accuracy: 0.9334\n",
      "Epoch 66/1000\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1734 - accuracy: 0.9172\n",
      "Epoch 67/1000\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.1775 - accuracy: 0.9221\n",
      "Epoch 68/1000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.1584 - accuracy: 0.9334\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "[[100  29]\n",
      " [ 27 148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7752    0.7874    0.7813       127\n",
      "           1     0.8457    0.8362    0.8409       177\n",
      "\n",
      "    accuracy                         0.8158       304\n",
      "   macro avg     0.8105    0.8118    0.8111       304\n",
      "weighted avg     0.8163    0.8158    0.8160       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(64,1)))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f15bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c8ab4",
   "metadata": {},
   "source": [
    "# Test on Each Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55a9da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(path,model_name):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.iloc[:,:-1]\n",
    "    y= df.iloc[:,-1]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6715f4b",
   "metadata": {},
   "source": [
    "# Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00703c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "[[30  4]\n",
      " [22 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8824    0.5769    0.6977        52\n",
      "           1     0.6667    0.9167    0.7719        48\n",
      "\n",
      "    accuracy                         0.7400       100\n",
      "   macro avg     0.7745    0.7468    0.7348       100\n",
      "weighted avg     0.7788    0.7400    0.7333       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'cle_metadata_cnn.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_CNN.h5'\n",
    "Test(path,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547b756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6810ee8a",
   "metadata": {},
   "source": [
    "# Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91a69356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step\n",
      "[[ 6  1]\n",
      " [ 9 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.4000    0.5455        15\n",
      "           1     0.8475    0.9804    0.9091        51\n",
      "\n",
      "    accuracy                         0.8485        66\n",
      "   macro avg     0.8523    0.6902    0.7273        66\n",
      "weighted avg     0.8497    0.8485    0.8264        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'vir_metadata_cnn.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_CNN.h5'\n",
    "Test(path,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8a359",
   "metadata": {},
   "source": [
    "# Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d634d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "[[50  4]\n",
      " [10 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9259    0.8333    0.8772        60\n",
      "           1     0.7727    0.8947    0.8293        38\n",
      "\n",
      "    accuracy                         0.8571        98\n",
      "   macro avg     0.8493    0.8640    0.8532        98\n",
      "weighted avg     0.8665    0.8571    0.8586        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'hun_metadata_cnn.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_CNN.h5'\n",
    "Test(path,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf62723",
   "metadata": {},
   "source": [
    "# Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5dc46d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "[[ 1  2]\n",
      " [ 2 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3333    0.3333    0.3333         3\n",
      "           1     0.9474    0.9474    0.9474        38\n",
      "\n",
      "    accuracy                         0.9024        41\n",
      "   macro avg     0.6404    0.6404    0.6404        41\n",
      "weighted avg     0.9024    0.9024    0.9024        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'swi_metadata_cnn.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_CNN.h5'\n",
    "Test(path,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0813f",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052921c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fddd185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "20/20 [==============================] - 0s 1000us/step - loss: 0.4508 - accuracy: 0.7922\n",
      "Epoch 2/1000\n",
      "20/20 [==============================] - 0s 789us/step - loss: 0.3743 - accuracy: 0.8571\n",
      "Epoch 3/1000\n",
      "20/20 [==============================] - 0s 789us/step - loss: 0.3509 - accuracy: 0.8571\n",
      "Epoch 4/1000\n",
      "20/20 [==============================] - 0s 842us/step - loss: 0.3372 - accuracy: 0.8571\n",
      "Epoch 5/1000\n",
      "20/20 [==============================] - 0s 842us/step - loss: 0.3439 - accuracy: 0.8571\n",
      "Epoch 6/1000\n",
      "20/20 [==============================] - 0s 790us/step - loss: 0.3413 - accuracy: 0.8653\n",
      "Epoch 7/1000\n",
      "20/20 [==============================] - 0s 790us/step - loss: 0.3418 - accuracy: 0.8669\n",
      "Epoch 8/1000\n",
      "20/20 [==============================] - 0s 789us/step - loss: 0.3386 - accuracy: 0.8604\n",
      "Epoch 9/1000\n",
      "20/20 [==============================] - 0s 789us/step - loss: 0.3443 - accuracy: 0.8669\n",
      "10/10 [==============================] - 0s 667us/step\n",
      "[[ 97  15]\n",
      " [ 30 162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8661    0.7638    0.8117       127\n",
      "           1     0.8438    0.9153    0.8780       177\n",
      "\n",
      "    accuracy                         0.8520       304\n",
      "   macro avg     0.8549    0.8395    0.8449       304\n",
      "weighted avg     0.8531    0.8520    0.8503       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(64,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e39f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_DNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad40155",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "880e0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e78c2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "7/7 [==============================] - 1s 11ms/step - loss: 0.7239 - accuracy: 0.5419\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5772 - accuracy: 0.7291\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4849 - accuracy: 0.7783\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5141 - accuracy: 0.7685\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3981 - accuracy: 0.8522\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3741 - accuracy: 0.8719\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3338 - accuracy: 0.8867\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3448 - accuracy: 0.8818\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3360 - accuracy: 0.8768\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3401 - accuracy: 0.8768\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3390 - accuracy: 0.8719\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4101 - accuracy: 0.8276\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001ADEB901B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "[[39  4]\n",
      " [13 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9070    0.7500    0.8211        52\n",
      "           1     0.7719    0.9167    0.8381        48\n",
      "\n",
      "    accuracy                         0.8300       100\n",
      "   macro avg     0.8395    0.8333    0.8296       100\n",
      "weighted avg     0.8422    0.8300    0.8292       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(64, 1)))\n",
    "model.add(SimpleRNN(units=32, return_sequences=True))\n",
    "model.add(SimpleRNN(units=16))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fedaab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_RNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b38588",
   "metadata": {},
   "source": [
    "# Test on Each Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfb2deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(path,model_name):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.iloc[:,:-1]\n",
    "    y= df.iloc[:,-1]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269eff21",
   "metadata": {},
   "source": [
    "# Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fab7c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "[[39  4]\n",
      " [13 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9070    0.7500    0.8211        52\n",
      "           1     0.7719    0.9167    0.8381        48\n",
      "\n",
      "    accuracy                         0.8300       100\n",
      "   macro avg     0.8395    0.8333    0.8296       100\n",
      "weighted avg     0.8422    0.8300    0.8292       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'cle_metadata_cnn.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN.h5'\n",
    "Test(path,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b95104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c283ac1c",
   "metadata": {},
   "source": [
    "# Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43639914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "[[ 2  1]\n",
      " [13 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.1333    0.2222        15\n",
      "           1     0.7937    0.9804    0.8772        51\n",
      "\n",
      "    accuracy                         0.7879        66\n",
      "   macro avg     0.7302    0.5569    0.5497        66\n",
      "weighted avg     0.7648    0.7879    0.7283        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'vir_metadata_cnn.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN.h5'\n",
    "Test(path,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5601e",
   "metadata": {},
   "source": [
    "# Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e135b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "[[34  3]\n",
      " [26 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9189    0.5667    0.7010        60\n",
      "           1     0.5738    0.9211    0.7071        38\n",
      "\n",
      "    accuracy                         0.7041        98\n",
      "   macro avg     0.7463    0.7439    0.7041        98\n",
      "weighted avg     0.7851    0.7041    0.7034        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'hun_metadata_cnn.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN.h5'\n",
    "Test(path,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf97b2e",
   "metadata": {},
   "source": [
    "# Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d309ce5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "[[ 1  1]\n",
      " [ 2 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.3333    0.4000         3\n",
      "           1     0.9487    0.9737    0.9610        38\n",
      "\n",
      "    accuracy                         0.9268        41\n",
      "   macro avg     0.7244    0.6535    0.6805        41\n",
      "weighted avg     0.9159    0.9268    0.9200        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'swi_metadata_cnn.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN.h5'\n",
    "Test(path,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a31c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
