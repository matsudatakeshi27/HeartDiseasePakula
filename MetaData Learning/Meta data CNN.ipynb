{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51dac736",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle = pd.read_csv('../TrainTestData/cle_metadata.csv')\n",
    "vir = pd.read_csv('../TrainTestData/vir_metadata.csv')\n",
    "hun = pd.read_csv('../TrainTestData/hun_metadata.csv')\n",
    "swi = pd.read_csv('../TrainTestData/swi_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.3</th>\n",
       "      <th>8.3</th>\n",
       "      <th>9.3</th>\n",
       "      <th>10.3</th>\n",
       "      <th>11.3</th>\n",
       "      <th>12.3</th>\n",
       "      <th>13.3</th>\n",
       "      <th>14.3</th>\n",
       "      <th>15.3</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.099659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872684</td>\n",
       "      <td>1.073222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.189892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.457568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589020</td>\n",
       "      <td>0.882712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.598649</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.849904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620106</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.943316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.594235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.488225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637975</td>\n",
       "      <td>0.901482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643992</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.224025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119797</td>\n",
       "      <td>0.067982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.657312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.285271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.199812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546282</td>\n",
       "      <td>0.756742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.321362</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.738161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520788</td>\n",
       "      <td>0.593032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.272287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.677983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.394613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627924</td>\n",
       "      <td>0.883689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.631824</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.402882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570546</td>\n",
       "      <td>0.819004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.494263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.169592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586185</td>\n",
       "      <td>0.768512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.481180</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.352982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.839385</td>\n",
       "      <td>2.316214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.077897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.968976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851110</td>\n",
       "      <td>1.141455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.026502</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.655624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.390551</td>\n",
       "      <td>1.878792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.255075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.707302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670807</td>\n",
       "      <td>1.002500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.859282</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.161753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.826201</td>\n",
       "      <td>2.245803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.802060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740325</td>\n",
       "      <td>1.043203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.887837</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.102779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.974692</td>\n",
       "      <td>2.487005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.745667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.693194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.653663</td>\n",
       "      <td>1.047537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.765075</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.602246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.550044</td>\n",
       "      <td>1.915930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.562886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.203250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.498982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513196</td>\n",
       "      <td>0.959969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.646081</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2         3         4    5         6    7         8  \\\n",
       "0    1.099659  0.0  0.0  0.872684  1.073222  0.0  1.486944  0.0  2.189892   \n",
       "1    1.849904  0.0  0.0  0.620106  0.811350  0.0  1.943316  0.0  2.594235   \n",
       "2    2.224025  0.0  0.0  0.119797  0.067982  0.0  2.657312  0.0  3.285271   \n",
       "3    1.738161  0.0  0.0  0.520788  0.593032  0.0  2.272287  0.0  2.677983   \n",
       "4    1.402882  0.0  0.0  0.570546  0.819004  0.0  1.494263  0.0  2.169592   \n",
       "..        ...  ...  ...       ...       ...  ...       ...  ...       ...   \n",
       "118  0.352982  0.0  0.0  1.839385  2.316214  0.0  0.474900  0.0  1.077897   \n",
       "119  0.655624  0.0  0.0  1.390551  1.878792  0.0  0.452024  0.0  1.255075   \n",
       "120  0.161753  0.0  0.0  1.826201  2.245803  0.0  0.137622  0.0  0.954996   \n",
       "121  0.102779  0.0  0.0  1.974692  2.487005  0.0  0.091805  0.0  0.745667   \n",
       "122  0.602246  0.0  0.0  1.550044  1.915930  0.0  0.562886  0.0  1.203250   \n",
       "\n",
       "       9  ...  7.3       8.3  9.3  10.3      11.3      12.3  13.3  14.3  \\\n",
       "0    0.0  ...  0.0  1.457568  0.0   0.0  0.589020  0.882712   0.0   0.0   \n",
       "1    0.0  ...  0.0  1.488225  0.0   0.0  0.637975  0.901482   0.0   0.0   \n",
       "2    0.0  ...  0.0  1.199812  0.0   0.0  0.546282  0.756742   0.0   0.0   \n",
       "3    0.0  ...  0.0  1.394613  0.0   0.0  0.627924  0.883689   0.0   0.0   \n",
       "4    0.0  ...  0.0  1.280468  0.0   0.0  0.586185  0.768512   0.0   0.0   \n",
       "..   ...  ...  ...       ...  ...   ...       ...       ...   ...   ...   \n",
       "118  0.0  ...  0.0  1.968976  0.0   0.0  0.851110  1.141455   0.0   0.0   \n",
       "119  0.0  ...  0.0  1.707302  0.0   0.0  0.670807  1.002500   0.0   0.0   \n",
       "120  0.0  ...  0.0  1.802060  0.0   0.0  0.740325  1.043203   0.0   0.0   \n",
       "121  0.0  ...  0.0  1.693194  0.0   0.0  0.653663  1.047537   0.0   0.0   \n",
       "122  0.0  ...  0.0  1.498982  0.0   0.0  0.513196  0.959969   0.0   0.0   \n",
       "\n",
       "         15.3   num  \n",
       "0    1.598649  0.00  \n",
       "1    1.643992  0.00  \n",
       "2    1.321362  0.00  \n",
       "3    1.631824  0.00  \n",
       "4    1.481180  0.00  \n",
       "..        ...   ...  \n",
       "118  2.026502  0.75  \n",
       "119  1.859282  0.50  \n",
       "120  1.887837  1.00  \n",
       "121  1.765075  0.25  \n",
       "122  1.646081  0.25  \n",
       "\n",
       "[920 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([cle,vir,hun,swi])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c86ca29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "20/20 [==============================] - 2s 63ms/step - loss: 0.4596 - accuracy: 0.7890\n",
      "Epoch 2/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.3629 - accuracy: 0.8571\n",
      "Epoch 3/1000\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.3668 - accuracy: 0.8620\n",
      "Epoch 4/1000\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.3539 - accuracy: 0.8555\n",
      "Epoch 5/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.3425 - accuracy: 0.8620\n",
      "Epoch 6/1000\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.3583 - accuracy: 0.8636\n",
      "Epoch 7/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.3463 - accuracy: 0.8653\n",
      "Epoch 8/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.3332 - accuracy: 0.8701\n",
      "Epoch 9/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.3271 - accuracy: 0.8701\n",
      "Epoch 10/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.3332 - accuracy: 0.8636\n",
      "Epoch 11/1000\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.3235 - accuracy: 0.8750\n",
      "Epoch 12/1000\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.3347 - accuracy: 0.8701\n",
      "Epoch 13/1000\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.3240 - accuracy: 0.8799\n",
      "Epoch 14/1000\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.3307 - accuracy: 0.8734\n",
      "Epoch 15/1000\n",
      "20/20 [==============================] - 1s 65ms/step - loss: 0.3234 - accuracy: 0.8831\n",
      "Epoch 16/1000\n",
      "20/20 [==============================] - 1s 64ms/step - loss: 0.3327 - accuracy: 0.8815\n",
      "Epoch 17/1000\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.3150 - accuracy: 0.8864\n",
      "Epoch 18/1000\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.3150 - accuracy: 0.8831\n",
      "Epoch 19/1000\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.3142 - accuracy: 0.8782\n",
      "Epoch 20/1000\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.3159 - accuracy: 0.8782\n",
      "Epoch 21/1000\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.3232 - accuracy: 0.8815\n",
      "Epoch 22/1000\n",
      "20/20 [==============================] - 1s 71ms/step - loss: 0.3061 - accuracy: 0.8831\n",
      "Epoch 23/1000\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.3015 - accuracy: 0.8880\n",
      "Epoch 24/1000\n",
      "20/20 [==============================] - 1s 70ms/step - loss: 0.3164 - accuracy: 0.8880\n",
      "Epoch 25/1000\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 0.3097 - accuracy: 0.8864\n",
      "Epoch 26/1000\n",
      "20/20 [==============================] - 1s 66ms/step - loss: 0.3059 - accuracy: 0.8831\n",
      "Epoch 27/1000\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 0.2986 - accuracy: 0.8977\n",
      "Epoch 28/1000\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.3002 - accuracy: 0.8912\n",
      "Epoch 29/1000\n",
      "20/20 [==============================] - 1s 70ms/step - loss: 0.3108 - accuracy: 0.8815\n",
      "Epoch 30/1000\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.2999 - accuracy: 0.8880\n",
      "Epoch 31/1000\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.3066 - accuracy: 0.8831\n",
      "Epoch 32/1000\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.2942 - accuracy: 0.8896\n",
      "Epoch 33/1000\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.2847 - accuracy: 0.8961\n",
      "Epoch 34/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.2929 - accuracy: 0.8880\n",
      "Epoch 35/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2803 - accuracy: 0.8945\n",
      "Epoch 36/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.2817 - accuracy: 0.8994\n",
      "Epoch 37/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2863 - accuracy: 0.8912\n",
      "Epoch 38/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2699 - accuracy: 0.8977\n",
      "Epoch 39/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2768 - accuracy: 0.8896\n",
      "Epoch 40/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2566 - accuracy: 0.8961\n",
      "Epoch 41/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2691 - accuracy: 0.8929\n",
      "Epoch 42/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2530 - accuracy: 0.8961\n",
      "Epoch 43/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2774 - accuracy: 0.8847\n",
      "Epoch 44/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2623 - accuracy: 0.8961\n",
      "Epoch 45/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.2508 - accuracy: 0.8994\n",
      "Epoch 46/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2623 - accuracy: 0.9026\n",
      "Epoch 47/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2510 - accuracy: 0.9010\n",
      "Epoch 48/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2431 - accuracy: 0.9010\n",
      "Epoch 49/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2362 - accuracy: 0.9107\n",
      "Epoch 50/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2338 - accuracy: 0.9058\n",
      "Epoch 51/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.2122 - accuracy: 0.9156\n",
      "Epoch 52/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2152 - accuracy: 0.9156\n",
      "Epoch 53/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.2120 - accuracy: 0.9042\n",
      "Epoch 54/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.1994 - accuracy: 0.9253\n",
      "Epoch 55/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.1866 - accuracy: 0.9172\n",
      "Epoch 56/1000\n",
      "20/20 [==============================] - 1s 63ms/step - loss: 0.2033 - accuracy: 0.9140\n",
      "Epoch 57/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1988 - accuracy: 0.9140\n",
      "Epoch 58/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.1859 - accuracy: 0.9286\n",
      "Epoch 59/1000\n",
      "20/20 [==============================] - 1s 62ms/step - loss: 0.1822 - accuracy: 0.9286\n",
      "Epoch 60/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1789 - accuracy: 0.9237\n",
      "Epoch 61/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1719 - accuracy: 0.9205\n",
      "Epoch 62/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1691 - accuracy: 0.9318\n",
      "Epoch 63/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1620 - accuracy: 0.9399\n",
      "Epoch 64/1000\n",
      "20/20 [==============================] - 1s 60ms/step - loss: 0.1498 - accuracy: 0.9351\n",
      "Epoch 65/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1526 - accuracy: 0.9286\n",
      "Epoch 66/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1534 - accuracy: 0.9351\n",
      "Epoch 67/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1601 - accuracy: 0.9399\n",
      "Epoch 68/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1633 - accuracy: 0.9286\n",
      "Epoch 69/1000\n",
      "20/20 [==============================] - 1s 61ms/step - loss: 0.1620 - accuracy: 0.9237\n",
      "10/10 [==============================] - 0s 11ms/step\n",
      "[[ 99  23]\n",
      " [ 28 154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80       127\n",
      "           1       0.85      0.87      0.86       177\n",
      "\n",
      "    accuracy                           0.83       304\n",
      "   macro avg       0.83      0.82      0.83       304\n",
      "weighted avg       0.83      0.83      0.83       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(64,1)))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f15bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/Meta_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c8ab4",
   "metadata": {},
   "source": [
    "# Test on Each Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a9da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6715f4b",
   "metadata": {},
   "source": [
    "# Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00703c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step\n",
      "[[41  3]\n",
      " [ 7 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89        48\n",
      "           1       0.85      0.93      0.89        43\n",
      "\n",
      "    accuracy                           0.89        91\n",
      "   macro avg       0.89      0.89      0.89        91\n",
      "weighted avg       0.89      0.89      0.89        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/cle_metadata_train.csv'\n",
    "path_test = '../TrainTestData/cle_metadata_test.csv'\n",
    "model = '../Models/Meta_Only/Meta_CNN.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547b756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6810ee8a",
   "metadata": {},
   "source": [
    "# Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a69356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 14ms/step\n",
      "[[ 8  2]\n",
      " [ 7 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.53      0.64        15\n",
      "           1       0.86      0.96      0.91        45\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.83      0.74      0.77        60\n",
      "weighted avg       0.85      0.85      0.84        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/vir_metadata_train.csv'\n",
    "path_test = '../TrainTestData/vir_metadata_test.csv'\n",
    "model = '../Models/Meta_Only/Meta_CNN.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8a359",
   "metadata": {},
   "source": [
    "# Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d634d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step\n",
      "[[50  3]\n",
      " [ 5 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        55\n",
      "           1       0.86      0.91      0.89        34\n",
      "\n",
      "    accuracy                           0.91        89\n",
      "   macro avg       0.90      0.91      0.91        89\n",
      "weighted avg       0.91      0.91      0.91        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/hun_metadata_train.csv'\n",
    "path_test = '../TrainTestData/hun_metadata_test.csv'\n",
    "model = '../Models/Meta_Only/Meta_CNN.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf62723",
   "metadata": {},
   "source": [
    "# Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5dc46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000201F309AE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "[[ 2  1]\n",
      " [ 1 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.97      0.97      0.97        34\n",
      "\n",
      "    accuracy                           0.95        37\n",
      "   macro avg       0.82      0.82      0.82        37\n",
      "weighted avg       0.95      0.95      0.95        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/swi_metadata_train.csv'\n",
    "path_test = '../TrainTestData/swi_metadata_test.csv'\n",
    "model = '../Models/Meta_Only/Meta_CNN.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacc1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
