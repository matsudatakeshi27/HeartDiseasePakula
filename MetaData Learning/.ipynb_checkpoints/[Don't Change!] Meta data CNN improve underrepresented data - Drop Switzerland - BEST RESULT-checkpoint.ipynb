{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1ee0e",
   "metadata": {},
   "source": [
    "# CNN metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3360ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_train=pd.read_csv('cle_metadata_cnn_train.csv')\n",
    "cle_test=pd.read_csv('cle_metadata_cnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0b8fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train=pd.read_csv('vir_metadata_cnn_train.csv' )\n",
    "vir_test=pd.read_csv('vir_metadata_cnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e92518ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train=pd.read_csv('hun_metadata_cnn_train.csv' )\n",
    "hun_test=pd.read_csv('hun_metadata_cnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fe3741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_train=pd.read_csv('swi_metadata_cnn_train.csv' )\n",
    "swi_test=pd.read_csv('swi_metadata_cnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([cle_train,vir_train,hun_train])\n",
    "Test = pd.concat([cle_test,vir_test,hun_test,swi_test,swi_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.iloc[:,:-1]\n",
    "X_test = Test.iloc[:,:-1]\n",
    "\n",
    "y_train = Train.iloc[:,-1]\n",
    "y_test = Test.iloc[:,-1]\n",
    "\n",
    "Y_train_binary = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c43269e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.248868</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084931</td>\n",
       "      <td>0.027487</td>\n",
       "      <td>1.848607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.113567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.431419</td>\n",
       "      <td>0.549506</td>\n",
       "      <td>0.177540</td>\n",
       "      <td>0.514307</td>\n",
       "      <td>0.604842</td>\n",
       "      <td>1.118270</td>\n",
       "      <td>0.155366</td>\n",
       "      <td>0.400950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.108881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.652945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.620916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635330</td>\n",
       "      <td>1.127964</td>\n",
       "      <td>0.663026</td>\n",
       "      <td>0.960354</td>\n",
       "      <td>1.166600</td>\n",
       "      <td>0.497467</td>\n",
       "      <td>0.660284</td>\n",
       "      <td>1.020273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.274957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.057440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.256941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.831003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.058112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.749359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.849345</td>\n",
       "      <td>0.338811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213237</td>\n",
       "      <td>0.424558</td>\n",
       "      <td>1.518912</td>\n",
       "      <td>0.102218</td>\n",
       "      <td>0.287279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.246813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.168874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916041</td>\n",
       "      <td>0.946292</td>\n",
       "      <td>0.374512</td>\n",
       "      <td>0.752015</td>\n",
       "      <td>0.958136</td>\n",
       "      <td>0.728709</td>\n",
       "      <td>0.355389</td>\n",
       "      <td>0.588221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.096703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806900</td>\n",
       "      <td>0.684368</td>\n",
       "      <td>0.188297</td>\n",
       "      <td>0.424260</td>\n",
       "      <td>0.761084</td>\n",
       "      <td>0.565412</td>\n",
       "      <td>0.236611</td>\n",
       "      <td>0.359720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.065655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.734521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.603619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.300780</td>\n",
       "      <td>0.537362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419477</td>\n",
       "      <td>0.634206</td>\n",
       "      <td>1.070987</td>\n",
       "      <td>0.054865</td>\n",
       "      <td>0.139900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.722686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.528803</td>\n",
       "      <td>0.300625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252635</td>\n",
       "      <td>0.322260</td>\n",
       "      <td>1.262992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.139185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.809298</td>\n",
       "      <td>0.949249</td>\n",
       "      <td>0.304412</td>\n",
       "      <td>0.850724</td>\n",
       "      <td>1.054647</td>\n",
       "      <td>0.719883</td>\n",
       "      <td>0.530515</td>\n",
       "      <td>0.740164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.253392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.886487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6  \\\n",
       "0    0.0  2.248868  0.031966  0.000000  0.084931  0.027487  1.848607   \n",
       "1    0.0  1.431419  0.549506  0.177540  0.514307  0.604842  1.118270   \n",
       "2    0.0  0.635330  1.127964  0.663026  0.960354  1.166600  0.497467   \n",
       "3    0.0  2.256941  0.000000  0.000000  0.000000  0.000000  1.831003   \n",
       "4    0.0  1.849345  0.338811  0.000000  0.213237  0.424558  1.518912   \n",
       "..   ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.0  0.916041  0.946292  0.374512  0.752015  0.958136  0.728709   \n",
       "196  0.0  0.806900  0.684368  0.188297  0.424260  0.761084  0.565412   \n",
       "197  0.0  1.300780  0.537362  0.000000  0.419477  0.634206  1.070987   \n",
       "198  0.0  1.528803  0.300625  0.000000  0.252635  0.322260  1.262992   \n",
       "199  0.0  0.809298  0.949249  0.304412  0.850724  1.054647  0.719883   \n",
       "\n",
       "            7         8    9  ...  6.2       7.2  8.2  9.2  10.2  11.2  12.2  \\\n",
       "0    0.000000  0.000000  0.0  ...  0.0  0.458321  0.0  0.0   0.0   0.0   0.0   \n",
       "1    0.155366  0.400950  0.0  ...  0.0  1.108881  0.0  0.0   0.0   0.0   0.0   \n",
       "2    0.660284  1.020273  0.0  ...  0.0  2.274957  0.0  0.0   0.0   0.0   0.0   \n",
       "3    0.000000  0.000000  0.0  ...  0.0  1.058112  0.0  0.0   0.0   0.0   0.0   \n",
       "4    0.102218  0.287279  0.0  ...  0.0  1.246813  0.0  0.0   0.0   0.0   0.0   \n",
       "..        ...       ...  ...  ...  ...       ...  ...  ...   ...   ...   ...   \n",
       "195  0.355389  0.588221  0.0  ...  0.0  0.364294  0.0  0.0   0.0   0.0   0.0   \n",
       "196  0.236611  0.359720  0.0  ...  0.0  1.065655  0.0  0.0   0.0   0.0   0.0   \n",
       "197  0.054865  0.139900  0.0  ...  0.0  0.655143  0.0  0.0   0.0   0.0   0.0   \n",
       "198  0.000000  0.000000  0.0  ...  0.0  0.000000  0.0  0.0   0.0   0.0   0.0   \n",
       "199  0.530515  0.740164  0.0  ...  0.0  1.253392  0.0  0.0   0.0   0.0   0.0   \n",
       "\n",
       "         13.2  14.2      15.2  \n",
       "0    0.327989   0.0  1.113567  \n",
       "1    0.652945   0.0  1.620916  \n",
       "2    1.418039   0.0  3.057440  \n",
       "3    0.647171   0.0  1.749359  \n",
       "4    0.808062   0.0  2.168874  \n",
       "..        ...   ...       ...  \n",
       "195  0.168329   0.0  1.096703  \n",
       "196  0.734521   0.0  1.603619  \n",
       "197  0.310825   0.0  1.722686  \n",
       "198  0.000000   0.0  1.139185  \n",
       "199  0.775983   0.0  2.886487  \n",
       "\n",
       "[548 rows x 48 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.iloc[:,:-16]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db3d3c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.576204</td>\n",
       "      <td>0.425418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268724</td>\n",
       "      <td>0.449675</td>\n",
       "      <td>1.255515</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>0.127063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.399341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.327298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.096074</td>\n",
       "      <td>0.112876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.053330</td>\n",
       "      <td>1.652721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410527</td>\n",
       "      <td>1.482395</td>\n",
       "      <td>1.029471</td>\n",
       "      <td>1.204768</td>\n",
       "      <td>1.621189</td>\n",
       "      <td>0.422033</td>\n",
       "      <td>1.139812</td>\n",
       "      <td>1.480421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.289236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.460618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.235174</td>\n",
       "      <td>0.074740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079568</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>1.834668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.012708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243156</td>\n",
       "      <td>1.304830</td>\n",
       "      <td>0.914779</td>\n",
       "      <td>1.077529</td>\n",
       "      <td>1.312706</td>\n",
       "      <td>0.370080</td>\n",
       "      <td>0.972016</td>\n",
       "      <td>1.398930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.782764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.950225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.161178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.739848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.258408</td>\n",
       "      <td>0.550577</td>\n",
       "      <td>0.167127</td>\n",
       "      <td>0.385352</td>\n",
       "      <td>0.657832</td>\n",
       "      <td>0.890879</td>\n",
       "      <td>0.085123</td>\n",
       "      <td>0.314842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.044203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.601484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.513029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.320644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.715816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.834675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.742145</td>\n",
       "      <td>0.349108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337999</td>\n",
       "      <td>0.408991</td>\n",
       "      <td>1.426055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.415703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.917221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6         7  \\\n",
       "0   0.0  1.576204  0.425418  0.000000  0.268724  0.449675  1.255515  0.017467   \n",
       "1   0.0  2.096074  0.112876  0.000000  0.143072  0.053330  1.652721  0.000000   \n",
       "2   0.0  0.410527  1.482395  1.029471  1.204768  1.621189  0.422033  1.139812   \n",
       "3   0.0  2.235174  0.074740  0.000000  0.079568  0.072115  1.834668  0.000000   \n",
       "4   0.0  0.243156  1.304830  0.914779  1.077529  1.312706  0.370080  0.972016   \n",
       "..  ...       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.0  2.161178  0.000000  0.000000  0.000000  0.000000  1.739848  0.000000   \n",
       "78  0.0  1.258408  0.550577  0.167127  0.385352  0.657832  0.890879  0.085123   \n",
       "79  0.0  1.513029  0.000000  0.000000  0.005490  0.000000  1.320644  0.000000   \n",
       "80  0.0  1.742145  0.349108  0.000000  0.337999  0.408991  1.426055  0.000000   \n",
       "81  0.0  2.415703  0.000000  0.000000  0.000000  0.000000  1.917221  0.000000   \n",
       "\n",
       "           8    9  ...  6.2       7.2  8.2  9.2  10.2  11.2  12.2      13.2  \\\n",
       "0   0.127063  0.0  ...  0.0  1.399341  0.0  0.0   0.0   0.0   0.0  0.503240   \n",
       "1   0.000000  0.0  ...  0.0  0.000000  0.0  0.0   0.0   0.0   0.0  0.000000   \n",
       "2   1.480421  0.0  ...  0.0  2.289236  0.0  0.0   0.0   0.0   0.0  1.418965   \n",
       "3   0.000000  0.0  ...  0.0  0.355788  0.0  0.0   0.0   0.0   0.0  0.271699   \n",
       "4   1.398930  0.0  ...  0.0  1.782764  0.0  0.0   0.0   0.0   0.0  0.986294   \n",
       "..       ...  ...  ...  ...       ...  ...  ...   ...   ...   ...       ...   \n",
       "77  0.000000  0.0  ...  0.0  0.000000  0.0  0.0   0.0   0.0   0.0  0.000000   \n",
       "78  0.314842  0.0  ...  0.0  1.044203  0.0  0.0   0.0   0.0   0.0  0.700594   \n",
       "79  0.000000  0.0  ...  0.0  0.921914  0.0  0.0   0.0   0.0   0.0  0.715816   \n",
       "80  0.000000  0.0  ...  0.0  0.000000  0.0  0.0   0.0   0.0   0.0  0.000000   \n",
       "81  0.000000  0.0  ...  0.0  0.000000  0.0  0.0   0.0   0.0   0.0  0.000000   \n",
       "\n",
       "    14.2      15.2  \n",
       "0    0.0  2.327298  \n",
       "1    0.0  0.000000  \n",
       "2    0.0  3.460618  \n",
       "3    0.0  1.012708  \n",
       "4    0.0  2.950225  \n",
       "..   ...       ...  \n",
       "77   0.0  0.014986  \n",
       "78   0.0  1.601484  \n",
       "79   0.0  1.834675  \n",
       "80   0.0  0.518541  \n",
       "81   0.0  0.000000  \n",
       "\n",
       "[372 rows x 48 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.iloc[:,:-16]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3016ecb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cle_train_temp = cle_train.iloc[:,:-17]\n",
    "cle_train_Y = cle_train.iloc[:,-1]\n",
    "cle_train = pd.concat([cle_train_temp, cle_train_Y], axis=1)\n",
    "cle_train.to_csv('cle_metadata_cnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b0fd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train_temp = vir_train.iloc[:,:-17]\n",
    "vir_train_Y = vir_train.iloc[:,-1]\n",
    "vir_train = pd.concat([vir_train_temp, vir_train_Y], axis=1)\n",
    "vir_train.to_csv('vir_metadata_cnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ad66556",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train_temp = hun_train.iloc[:,:-17]\n",
    "hun_train_Y = hun_train.iloc[:,-1]\n",
    "hun_train = pd.concat([hun_train_temp, hun_train_Y], axis=1)\n",
    "hun_train.to_csv('hun_metadata_cnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04e852ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_test_temp = cle_test.iloc[:,:-17]\n",
    "cle_test_Y = cle_test.iloc[:,-1]\n",
    "cle_test = pd.concat([cle_test_temp, cle_test_Y], axis=1)\n",
    "cle_test.to_csv('cle_metadata_cnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9041c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_test_temp = vir_test.iloc[:,:-17]\n",
    "vir_test_Y = vir_test.iloc[:,-1]\n",
    "vir_test = pd.concat([vir_test_temp, vir_test_Y], axis=1)\n",
    "vir_test.to_csv('vir_metadata_cnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4764f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_test_temp = hun_test.iloc[:,:-17]\n",
    "hun_test_Y = hun_test.iloc[:,-1]\n",
    "hun_test = pd.concat([hun_test_temp, hun_test_Y], axis=1)\n",
    "hun_test.to_csv('hun_metadata_cnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4349043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.3</th>\n",
       "      <th>8.3</th>\n",
       "      <th>9.3</th>\n",
       "      <th>10.3</th>\n",
       "      <th>11.3</th>\n",
       "      <th>12.3</th>\n",
       "      <th>13.3</th>\n",
       "      <th>14.3</th>\n",
       "      <th>15.3</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.713393</td>\n",
       "      <td>0.376718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355642</td>\n",
       "      <td>0.453022</td>\n",
       "      <td>1.407642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.485162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.619324</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.376615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.931468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.998104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.403400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.477068</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.287115</td>\n",
       "      <td>0.365467</td>\n",
       "      <td>0.041732</td>\n",
       "      <td>0.262797</td>\n",
       "      <td>0.520611</td>\n",
       "      <td>1.159972</td>\n",
       "      <td>0.252943</td>\n",
       "      <td>0.260906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.813308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.296173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.147527</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.165693</td>\n",
       "      <td>0.851051</td>\n",
       "      <td>0.205578</td>\n",
       "      <td>0.562909</td>\n",
       "      <td>0.746119</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>0.182490</td>\n",
       "      <td>0.362199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.165876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.541997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.677604</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.216803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.804639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.032758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.430741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.525313</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725975</td>\n",
       "      <td>1.056439</td>\n",
       "      <td>0.539673</td>\n",
       "      <td>0.888720</td>\n",
       "      <td>1.078301</td>\n",
       "      <td>0.635860</td>\n",
       "      <td>0.664964</td>\n",
       "      <td>0.895163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.815131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.245138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.320023</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.644590</td>\n",
       "      <td>0.363792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281488</td>\n",
       "      <td>0.438347</td>\n",
       "      <td>1.317108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.912887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.343234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.408693</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.956689</td>\n",
       "      <td>0.221265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127522</td>\n",
       "      <td>0.112805</td>\n",
       "      <td>1.626014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.167436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.516895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.674914</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.981093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.640855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.761576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.262628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.171647</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.907162</td>\n",
       "      <td>0.156136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277707</td>\n",
       "      <td>0.235683</td>\n",
       "      <td>1.423825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.915955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.363857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.327504</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6         7  \\\n",
       "0   0.0  1.713393  0.376718  0.000000  0.355642  0.453022  1.407642  0.000000   \n",
       "1   0.0  2.376615  0.000000  0.000000  0.000000  0.000000  1.931468  0.000000   \n",
       "2   0.0  1.287115  0.365467  0.041732  0.262797  0.520611  1.159972  0.252943   \n",
       "3   0.0  1.165693  0.851051  0.205578  0.562909  0.746119  0.995797  0.182490   \n",
       "4   0.0  2.216803  0.000000  0.000000  0.000000  0.000000  1.804639  0.000000   \n",
       "..  ...       ...       ...       ...       ...       ...       ...       ...   \n",
       "36  0.0  0.725975  1.056439  0.539673  0.888720  1.078301  0.635860  0.664964   \n",
       "37  0.0  1.644590  0.363792  0.000000  0.281488  0.438347  1.317108  0.000000   \n",
       "38  0.0  1.956689  0.221265  0.000000  0.127522  0.112805  1.626014  0.000000   \n",
       "39  0.0  1.981093  0.000000  0.000000  0.000000  0.000000  1.640855  0.000000   \n",
       "40  0.0  1.907162  0.156136  0.000000  0.277707  0.235683  1.423825  0.000000   \n",
       "\n",
       "           8    9  ...       7.3  8.3  9.3      10.3  11.3  12.3  13.3  14.3  \\\n",
       "0   0.069308  0.0  ...  2.120787  0.0  0.0  1.485162   0.0   0.0   0.0   0.0   \n",
       "1   0.000000  0.0  ...  1.998104  0.0  0.0  1.403400   0.0   0.0   0.0   0.0   \n",
       "2   0.260906  0.0  ...  1.813308  0.0  0.0  1.296173   0.0   0.0   0.0   0.0   \n",
       "3   0.362199  0.0  ...  2.165876  0.0  0.0  1.541997   0.0   0.0   0.0   0.0   \n",
       "4   0.000000  0.0  ...  2.032758  0.0  0.0  1.430741   0.0   0.0   0.0   0.0   \n",
       "..       ...  ...  ...       ...  ...  ...       ...   ...   ...   ...   ...   \n",
       "36  0.895163  0.0  ...  1.815131  0.0  0.0  1.245138   0.0   0.0   0.0   0.0   \n",
       "37  0.000000  0.0  ...  1.912887  0.0  0.0  1.343234   0.0   0.0   0.0   0.0   \n",
       "38  0.000000  0.0  ...  2.167436  0.0  0.0  1.516895   0.0   0.0   0.0   0.0   \n",
       "39  0.000000  0.0  ...  1.761576  0.0  0.0  1.262628   0.0   0.0   0.0   0.0   \n",
       "40  0.000000  0.0  ...  1.915955  0.0  0.0  1.363857   0.0   0.0   0.0   0.0   \n",
       "\n",
       "        15.3   num  \n",
       "0   2.619324  0.75  \n",
       "1   2.477068  0.75  \n",
       "2   2.147527  0.50  \n",
       "3   2.677604  0.25  \n",
       "4   2.525313  0.25  \n",
       "..       ...   ...  \n",
       "36  2.320023  0.25  \n",
       "37  2.408693  0.25  \n",
       "38  2.674914  0.75  \n",
       "39  2.171647  0.25  \n",
       "40  2.327504  0.75  \n",
       "\n",
       "[123 rows x 65 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swi_test_new = pd.concat([swi_train, swi_test])\n",
    "swi_test_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bd79e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_test_temp = swi_test_new.iloc[:,:-17]\n",
    "swi_test_Y = swi_test_new.iloc[:,-1]\n",
    "swi_test = pd.concat([swi_test_temp, swi_test_Y], axis=1)\n",
    "swi_test.to_csv('swi_metadata_cnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55a9da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for deep learning testing\n",
    "def Test(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "    \n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e623e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c86ca29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 2s 44ms/step - loss: 0.4835 - accuracy: 0.7920\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.4201 - accuracy: 0.8394\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.4310 - accuracy: 0.8248\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.4310 - accuracy: 0.8285\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.4214 - accuracy: 0.8449\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.4086 - accuracy: 0.8394\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.4147 - accuracy: 0.8321\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.4177 - accuracy: 0.8285\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.4034 - accuracy: 0.8394\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.4027 - accuracy: 0.8303\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3842 - accuracy: 0.8522\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.3954 - accuracy: 0.8467\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3897 - accuracy: 0.8412\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3846 - accuracy: 0.8522\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.4007 - accuracy: 0.8412\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3787 - accuracy: 0.8431\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.3789 - accuracy: 0.8522\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3792 - accuracy: 0.8485\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3807 - accuracy: 0.8485\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3733 - accuracy: 0.8540\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.3720 - accuracy: 0.8613\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.3602 - accuracy: 0.8577\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3545 - accuracy: 0.8613\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3995 - accuracy: 0.8175\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.3931 - accuracy: 0.8485\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3709 - accuracy: 0.8540\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.3519 - accuracy: 0.8650\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.3443 - accuracy: 0.8631\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.3465 - accuracy: 0.8504\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.3651 - accuracy: 0.8504\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.3494 - accuracy: 0.8595\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.4002 - accuracy: 0.8376\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3520 - accuracy: 0.8558\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "[[101  22]\n",
      " [ 22 227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8211    0.8211    0.8211       123\n",
      "           1     0.9116    0.9116    0.9116       249\n",
      "\n",
      "    accuracy                         0.8817       372\n",
      "   macro avg     0.8664    0.8664    0.8664       372\n",
      "weighted avg     0.8817    0.8817    0.8817       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(48,1)))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f15bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_CNN_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bf045",
   "metadata": {},
   "source": [
    "# Test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bfc8384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "[[37  4]\n",
      " [ 9 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9024    0.8043    0.8506        46\n",
      "           1     0.8269    0.9149    0.8687        47\n",
      "\n",
      "    accuracy                         0.8602        93\n",
      "   macro avg     0.8647    0.8596    0.8596        93\n",
      "weighted avg     0.8643    0.8602    0.8597        93\n",
      "\n",
      "[18, 25, 44, 47, 49, 50, 58, 59, 62, 69, 72, 79, 89]\n",
      "==================\n",
      "vir test\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "[[ 5  2]\n",
      " [ 6 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.4545    0.5556        11\n",
      "           1     0.8909    0.9608    0.9245        51\n",
      "\n",
      "    accuracy                         0.8710        62\n",
      "   macro avg     0.8026    0.7077    0.7400        62\n",
      "weighted avg     0.8596    0.8710    0.8591        62\n",
      "\n",
      "[6, 7, 17, 20, 23, 32, 53, 54]\n",
      "==================\n",
      "hun test\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "[[50  1]\n",
      " [ 8 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9804    0.8621    0.9174        58\n",
      "           1     0.8140    0.9722    0.8861        36\n",
      "\n",
      "    accuracy                         0.9043        94\n",
      "   macro avg     0.8972    0.9171    0.9018        94\n",
      "weighted avg     0.9166    0.9043    0.9054        94\n",
      "\n",
      "[7, 12, 34, 54, 60, 65, 66, 68, 69]\n",
      "==================\n",
      "swi test\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "[[  3   5]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3750    0.3750    0.3750         8\n",
      "           1     0.9565    0.9565    0.9565       115\n",
      "\n",
      "    accuracy                         0.9187       123\n",
      "   macro avg     0.6658    0.6658    0.6658       123\n",
      "weighted avg     0.9187    0.9187    0.9187       123\n",
      "\n",
      "[7, 8, 44, 77, 82, 92, 94, 97, 110, 118]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0813f",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fddd185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7847\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8394\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8431\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8467\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8431\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8449\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8358\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8449\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8358\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8467\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8467\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8540\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8449\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8449\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8504\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8412\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8540\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8540\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8394\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8449\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8449\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8522\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "[[102  14]\n",
      " [ 21 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8793    0.8293    0.8536       123\n",
      "           1     0.9180    0.9438    0.9307       249\n",
      "\n",
      "    accuracy                         0.9059       372\n",
      "   macro avg     0.8986    0.8865    0.8921       372\n",
      "weighted avg     0.9052    0.9059    0.9052       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(48,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e39f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_DNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a844",
   "metadata": {},
   "source": [
    "# test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53f9946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[[44  5]\n",
      " [ 2 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8980    0.9565    0.9263        46\n",
      "           1     0.9545    0.8936    0.9231        47\n",
      "\n",
      "    accuracy                         0.9247        93\n",
      "   macro avg     0.9263    0.9251    0.9247        93\n",
      "weighted avg     0.9266    0.9247    0.9247        93\n",
      "\n",
      "[17, 18, 58, 59, 69, 72, 89]\n",
      "==================\n",
      "vir test\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[[ 4  1]\n",
      " [ 7 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.3636    0.5000        11\n",
      "           1     0.8772    0.9804    0.9259        51\n",
      "\n",
      "    accuracy                         0.8710        62\n",
      "   macro avg     0.8386    0.6720    0.7130        62\n",
      "weighted avg     0.8635    0.8710    0.8504        62\n",
      "\n",
      "[6, 7, 17, 20, 23, 32, 49, 54]\n",
      "==================\n",
      "hun test\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[[51  0]\n",
      " [ 7 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8793    0.9358        58\n",
      "           1     0.8372    1.0000    0.9114        36\n",
      "\n",
      "    accuracy                         0.9255        94\n",
      "   macro avg     0.9186    0.9397    0.9236        94\n",
      "weighted avg     0.9377    0.9255    0.9264        94\n",
      "\n",
      "[7, 12, 34, 54, 65, 68, 69]\n",
      "==================\n",
      "swi test\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "[[  3   8]\n",
      " [  5 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2727    0.3750    0.3158         8\n",
      "           1     0.9554    0.9304    0.9427       115\n",
      "\n",
      "    accuracy                         0.8943       123\n",
      "   macro avg     0.6140    0.6527    0.6293       123\n",
      "weighted avg     0.9110    0.8943    0.9020       123\n",
      "\n",
      "[7, 8, 33, 44, 52, 77, 82, 92, 94, 97, 106, 110, 118]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12522ce3",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "880e0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e78c2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 3s 18ms/step - loss: 0.5653 - accuracy: 0.7427\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4559 - accuracy: 0.7865\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4227 - accuracy: 0.8084\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4078 - accuracy: 0.8321\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.8212\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4093 - accuracy: 0.8303\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4026 - accuracy: 0.8321\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4044 - accuracy: 0.8339\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4372 - accuracy: 0.8157\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4142 - accuracy: 0.8230\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3940 - accuracy: 0.8394\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3915 - accuracy: 0.8358\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4008 - accuracy: 0.8431\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3895 - accuracy: 0.8376\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3988 - accuracy: 0.8394\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4132 - accuracy: 0.8321\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3977 - accuracy: 0.8339\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3839 - accuracy: 0.8467\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4016 - accuracy: 0.8394\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3833 - accuracy: 0.8394\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3797 - accuracy: 0.8540\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3739 - accuracy: 0.8485\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3890 - accuracy: 0.8248\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3828 - accuracy: 0.8358\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3808 - accuracy: 0.8558\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3809 - accuracy: 0.8449\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3817 - accuracy: 0.8431\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "[[101  24]\n",
      " [ 22 225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8080    0.8211    0.8145       123\n",
      "           1     0.9109    0.9036    0.9073       249\n",
      "\n",
      "    accuracy                         0.8763       372\n",
      "   macro avg     0.8595    0.8624    0.8609       372\n",
      "weighted avg     0.8769    0.8763    0.8766       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(48, 1)))\n",
    "model.add(SimpleRNN(units=32, return_sequences=True))\n",
    "model.add(SimpleRNN(units=16))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fedaab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_RNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69fae7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[[40  5]\n",
      " [ 6 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.8696    0.8791        46\n",
      "           1     0.8750    0.8936    0.8842        47\n",
      "\n",
      "    accuracy                         0.8817        93\n",
      "   macro avg     0.8819    0.8816    0.8817        93\n",
      "weighted avg     0.8819    0.8817    0.8817        93\n",
      "\n",
      "[0, 19, 25, 44, 49, 58, 59, 69, 72, 79, 89]\n",
      "==================\n",
      "vir test\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "[[ 7  3]\n",
      " [ 4 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7000    0.6364    0.6667        11\n",
      "           1     0.9231    0.9412    0.9320        51\n",
      "\n",
      "    accuracy                         0.8871        62\n",
      "   macro avg     0.8115    0.7888    0.7994        62\n",
      "weighted avg     0.8835    0.8871    0.8850        62\n",
      "\n",
      "[6, 7, 17, 20, 23, 25, 53]\n",
      "==================\n",
      "hun test\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[[51  0]\n",
      " [ 7 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8793    0.9358        58\n",
      "           1     0.8372    1.0000    0.9114        36\n",
      "\n",
      "    accuracy                         0.9255        94\n",
      "   macro avg     0.9186    0.9397    0.9236        94\n",
      "weighted avg     0.9377    0.9255    0.9264        94\n",
      "\n",
      "[7, 12, 34, 54, 60, 69, 75]\n",
      "==================\n",
      "swi test\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "[[ 3 16]\n",
      " [ 5 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1579    0.3750    0.2222         8\n",
      "           1     0.9519    0.8609    0.9041       115\n",
      "\n",
      "    accuracy                         0.8293       123\n",
      "   macro avg     0.5549    0.6179    0.5632       123\n",
      "weighted avg     0.9003    0.8293    0.8598       123\n",
      "\n",
      "[7, 8, 14, 20, 28, 33, 36, 39, 44, 47, 55, 60, 64, 77, 79, 82, 92, 94, 97, 110, 118]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812110c",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bde29",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61dc493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2175bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is:\n",
      "[[ 88  54]\n",
      " [ 35 195]]\n",
      "Accuracy is : 0.760752688172043\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.66       123\n",
      "           1       0.85      0.78      0.81       249\n",
      "\n",
      "    accuracy                           0.76       372\n",
      "   macro avg       0.73      0.75      0.74       372\n",
      "weighted avg       0.77      0.76      0.76       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_train, Y_train_binary)\n",
    "Y_predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(Y_predictions, Y_test_binary)\n",
    "print(\"Confusion Matrix is:\")\n",
    "print(cm)\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "print(\"Accuracy is : \" + str(accuracy(cm)))\n",
    "    \n",
    "print(\"Report\")\n",
    "print(classification_report(Y_test_binary, Y_predictions))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b7d529c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/Meta_only/CNNMeta_dt.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save clf model\n",
    "from joblib import dump, load\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_dt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08cf24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Decision tree, and random forest testing\n",
    "def Test_DT(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = load(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "475fef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "[[38 13]\n",
      " [ 8 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7451    0.8261    0.7835        46\n",
      "           1     0.8095    0.7234    0.7640        47\n",
      "\n",
      "    accuracy                         0.7742        93\n",
      "   macro avg     0.7773    0.7747    0.7738        93\n",
      "weighted avg     0.7777    0.7742    0.7737        93\n",
      "\n",
      "[4, 9, 15, 17, 19, 22, 25, 33, 34, 38, 41, 44, 47, 52, 59, 69, 70, 72, 76, 78, 89]\n",
      "==================\n",
      "vir test\n",
      "[[ 7  5]\n",
      " [ 4 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5833    0.6364    0.6087        11\n",
      "           1     0.9200    0.9020    0.9109        51\n",
      "\n",
      "    accuracy                         0.8548        62\n",
      "   macro avg     0.7517    0.7692    0.7598        62\n",
      "weighted avg     0.8603    0.8548    0.8573        62\n",
      "\n",
      "[4, 7, 17, 20, 31, 32, 53, 58, 60]\n",
      "==================\n",
      "hun test\n",
      "[[41  5]\n",
      " [17 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8913    0.7069    0.7885        58\n",
      "           1     0.6458    0.8611    0.7381        36\n",
      "\n",
      "    accuracy                         0.7660        94\n",
      "   macro avg     0.7686    0.7840    0.7633        94\n",
      "weighted avg     0.7973    0.7660    0.7692        94\n",
      "\n",
      "[6, 7, 12, 20, 21, 25, 29, 32, 34, 38, 53, 54, 57, 62, 68, 71, 75, 79, 81, 83, 90, 93]\n",
      "==================\n",
      "swi test\n",
      "[[ 2 31]\n",
      " [ 6 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0606    0.2500    0.0976         8\n",
      "           1     0.9333    0.7304    0.8195       115\n",
      "\n",
      "    accuracy                         0.6992       123\n",
      "   macro avg     0.4970    0.4902    0.4585       123\n",
      "weighted avg     0.8766    0.6992    0.7726       123\n",
      "\n",
      "[0, 7, 10, 13, 14, 21, 24, 30, 33, 34, 35, 36, 37, 38, 39, 44, 51, 52, 65, 67, 77, 78, 79, 82, 83, 89, 91, 93, 94, 97, 102, 104, 107, 110, 111, 112, 118]\n"
     ]
    }
   ],
   "source": [
    "#test on each dataset for decision tree\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f058a8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7dee5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e9459fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101  15]\n",
      " [ 22 234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8707    0.8211    0.8452       123\n",
      "           1     0.9141    0.9398    0.9267       249\n",
      "\n",
      "    accuracy                         0.9005       372\n",
      "   macro avg     0.8924    0.8804    0.8860       372\n",
      "weighted avg     0.8997    0.9005    0.8998       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c54a50ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/Meta_only/CNNMeta_rf_9005.joblib']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(classifier, '../Models/Meta_only/CNNMeta_rf_9005.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49633d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "[[42  6]\n",
      " [ 4 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.9130    0.8936        46\n",
      "           1     0.9111    0.8723    0.8913        47\n",
      "\n",
      "    accuracy                         0.8925        93\n",
      "   macro avg     0.8931    0.8927    0.8925        93\n",
      "weighted avg     0.8932    0.8925    0.8924        93\n",
      "\n",
      "[17, 18, 32, 49, 59, 69, 72, 76, 79, 89]\n",
      "==================\n",
      "vir test\n",
      "[[ 6  4]\n",
      " [ 5 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6000    0.5455    0.5714        11\n",
      "           1     0.9038    0.9216    0.9126        51\n",
      "\n",
      "    accuracy                         0.8548        62\n",
      "   macro avg     0.7519    0.7335    0.7420        62\n",
      "weighted avg     0.8499    0.8548    0.8521        62\n",
      "\n",
      "[4, 6, 7, 17, 20, 23, 32, 39, 53]\n",
      "==================\n",
      "hun test\n",
      "[[50  2]\n",
      " [ 8 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.8621    0.9091        58\n",
      "           1     0.8095    0.9444    0.8718        36\n",
      "\n",
      "    accuracy                         0.8936        94\n",
      "   macro avg     0.8855    0.9033    0.8904        94\n",
      "weighted avg     0.9033    0.8936    0.8948        94\n",
      "\n",
      "[7, 12, 16, 34, 53, 54, 60, 62, 68, 69]\n",
      "==================\n",
      "swi test\n",
      "[[  3   3]\n",
      " [  5 112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.3750    0.4286         8\n",
      "           1     0.9573    0.9739    0.9655       115\n",
      "\n",
      "    accuracy                         0.9350       123\n",
      "   macro avg     0.7286    0.6745    0.6970       123\n",
      "weighted avg     0.9275    0.9350    0.9306       123\n",
      "\n",
      "[7, 33, 44, 77, 82, 94, 97, 118]\n"
     ]
    }
   ],
   "source": [
    "#test on each dataset for Random Forest\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511e046",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5efc17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcb18996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100  23]\n",
      " [ 15 234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8696    0.8130    0.8403       123\n",
      "           1     0.9105    0.9398    0.9249       249\n",
      "\n",
      "    accuracy                         0.8978       372\n",
      "   macro avg     0.8900    0.8764    0.8826       372\n",
      "weighted avg     0.8970    0.8978    0.8969       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train_binary.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(Y_test_binary, y_pred))\n",
    "print(classification_report(Y_test_binary, y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d339f40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/Meta_only/CNNMeta_svm_8978.pkl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(svc, \"../Models/Meta_only/CNNMeta_svm_8978.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "295a07bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "[[41  4]\n",
      " [ 5 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9111    0.8913    0.9011        46\n",
      "           1     0.8958    0.9149    0.9053        47\n",
      "\n",
      "    accuracy                         0.9032        93\n",
      "   macro avg     0.9035    0.9031    0.9032        93\n",
      "weighted avg     0.9034    0.9032    0.9032        93\n",
      "\n",
      "[18, 25, 49, 58, 59, 69, 72, 79, 89]\n",
      "==================\n",
      "vir test\n",
      "[[ 5  2]\n",
      " [ 6 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.4545    0.5556        11\n",
      "           1     0.8909    0.9608    0.9245        51\n",
      "\n",
      "    accuracy                         0.8710        62\n",
      "   macro avg     0.8026    0.7077    0.7400        62\n",
      "weighted avg     0.8596    0.8710    0.8591        62\n",
      "\n",
      "[4, 6, 7, 17, 20, 23, 32, 54]\n",
      "==================\n",
      "hun test\n",
      "[[51  1]\n",
      " [ 7 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9808    0.8793    0.9273        58\n",
      "           1     0.8333    0.9722    0.8974        36\n",
      "\n",
      "    accuracy                         0.9149        94\n",
      "   macro avg     0.9071    0.9258    0.9124        94\n",
      "weighted avg     0.9243    0.9149    0.9158        94\n",
      "\n",
      "[7, 12, 34, 54, 60, 66, 68, 69]\n",
      "==================\n",
      "swi test\n",
      "[[  3   8]\n",
      " [  5 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2727    0.3750    0.3158         8\n",
      "           1     0.9554    0.9304    0.9427       115\n",
      "\n",
      "    accuracy                         0.8943       123\n",
      "   macro avg     0.6140    0.6527    0.6293       123\n",
      "weighted avg     0.9110    0.8943    0.9020       123\n",
      "\n",
      "[7, 8, 33, 39, 44, 64, 77, 82, 92, 94, 97, 110, 118]\n"
     ]
    }
   ],
   "source": [
    "#test on each dataset for SVM\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26593df9",
   "metadata": {},
   "source": [
    "# Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4a7abee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103  26]\n",
      " [ 20 223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7984    0.8374    0.8175       123\n",
      "           1     0.9177    0.8956    0.9065       249\n",
      "\n",
      "    accuracy                         0.8763       372\n",
      "   macro avg     0.8581    0.8665    0.8620       372\n",
      "weighted avg     0.8783    0.8763    0.8771       372\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Models/Meta_only/CNNMeta_NB_dropswi.joblib']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits = 4))\n",
    "\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_NB_dropswi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41fa94ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "[[38 13]\n",
      " [ 8 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7451    0.8261    0.7835        46\n",
      "           1     0.8095    0.7234    0.7640        47\n",
      "\n",
      "    accuracy                         0.7742        93\n",
      "   macro avg     0.7773    0.7747    0.7738        93\n",
      "weighted avg     0.7777    0.7742    0.7737        93\n",
      "\n",
      "[4, 9, 15, 17, 19, 22, 25, 33, 34, 38, 41, 44, 47, 52, 59, 69, 70, 72, 76, 78, 89]\n",
      "==================\n",
      "vir test\n",
      "[[ 7  5]\n",
      " [ 4 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5833    0.6364    0.6087        11\n",
      "           1     0.9200    0.9020    0.9109        51\n",
      "\n",
      "    accuracy                         0.8548        62\n",
      "   macro avg     0.7517    0.7692    0.7598        62\n",
      "weighted avg     0.8603    0.8548    0.8573        62\n",
      "\n",
      "[4, 7, 17, 20, 31, 32, 53, 58, 60]\n",
      "==================\n",
      "hun test\n",
      "[[41  5]\n",
      " [17 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8913    0.7069    0.7885        58\n",
      "           1     0.6458    0.8611    0.7381        36\n",
      "\n",
      "    accuracy                         0.7660        94\n",
      "   macro avg     0.7686    0.7840    0.7633        94\n",
      "weighted avg     0.7973    0.7660    0.7692        94\n",
      "\n",
      "[6, 7, 12, 20, 21, 25, 29, 32, 34, 38, 53, 54, 57, 62, 68, 71, 75, 79, 81, 83, 90, 93]\n",
      "==================\n",
      "swi test\n",
      "[[ 2 31]\n",
      " [ 6 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0606    0.2500    0.0976         8\n",
      "           1     0.9333    0.7304    0.8195       115\n",
      "\n",
      "    accuracy                         0.6992       123\n",
      "   macro avg     0.4970    0.4902    0.4585       123\n",
      "weighted avg     0.8766    0.6992    0.7726       123\n",
      "\n",
      "[0, 7, 10, 13, 14, 21, 24, 30, 33, 34, 35, 36, 37, 38, 39, 44, 51, 52, 65, 67, 77, 78, 79, 82, 83, 89, 91, 93, 94, 97, 102, 104, 107, 110, 111, 112, 118]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2670c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD:MetaData Learning/Meta data CNN improve underrepresented data - Drop Switzerland - BEST RESULT.ipynb
   "version": "3.9.12"
=======
   "version": "3.9.16"
>>>>>>> 21a611729e2bbb4c4fa528c375b5b6e0c5014494:MetaData Learning/.ipynb_checkpoints/[Don't Change!] Meta data CNN improve underrepresented data - Drop Switzerland - BEST RESULT-checkpoint.ipynb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
