{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1ee0e",
   "metadata": {},
   "source": [
    "# DNN metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3360ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_train=pd.read_csv('cle_metadata_dnn_train.csv')\n",
    "cle_test=pd.read_csv('cle_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca440deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482027</td>\n",
       "      <td>0.499887</td>\n",
       "      <td>0.530806</td>\n",
       "      <td>0.538419</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.513956</td>\n",
       "      <td>0.498010</td>\n",
       "      <td>0.488720</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549547</td>\n",
       "      <td>0.518709</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.519562</td>\n",
       "      <td>0.484019</td>\n",
       "      <td>0.472015</td>\n",
       "      <td>0.508887</td>\n",
       "      <td>0.467478</td>\n",
       "      <td>0.486530</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454859</td>\n",
       "      <td>0.529616</td>\n",
       "      <td>0.526296</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.496266</td>\n",
       "      <td>0.510415</td>\n",
       "      <td>0.484137</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>0.496896</td>\n",
       "      <td>0.540834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488366</td>\n",
       "      <td>0.493662</td>\n",
       "      <td>0.497254</td>\n",
       "      <td>0.565816</td>\n",
       "      <td>0.497960</td>\n",
       "      <td>0.456738</td>\n",
       "      <td>0.500947</td>\n",
       "      <td>0.496931</td>\n",
       "      <td>0.517806</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463892</td>\n",
       "      <td>0.528533</td>\n",
       "      <td>0.529637</td>\n",
       "      <td>0.528451</td>\n",
       "      <td>0.506440</td>\n",
       "      <td>0.525559</td>\n",
       "      <td>0.475964</td>\n",
       "      <td>0.484750</td>\n",
       "      <td>0.524651</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499960</td>\n",
       "      <td>0.477971</td>\n",
       "      <td>0.530497</td>\n",
       "      <td>0.613168</td>\n",
       "      <td>0.473111</td>\n",
       "      <td>0.434871</td>\n",
       "      <td>0.508940</td>\n",
       "      <td>0.505146</td>\n",
       "      <td>0.497114</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487112</td>\n",
       "      <td>0.502789</td>\n",
       "      <td>0.547796</td>\n",
       "      <td>0.545979</td>\n",
       "      <td>0.500581</td>\n",
       "      <td>0.501580</td>\n",
       "      <td>0.497734</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.481571</td>\n",
       "      <td>0.520887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523350</td>\n",
       "      <td>0.508465</td>\n",
       "      <td>0.497361</td>\n",
       "      <td>0.530505</td>\n",
       "      <td>0.484081</td>\n",
       "      <td>0.486503</td>\n",
       "      <td>0.484897</td>\n",
       "      <td>0.458825</td>\n",
       "      <td>0.480811</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.487966</td>\n",
       "      <td>0.502613</td>\n",
       "      <td>0.530262</td>\n",
       "      <td>0.509978</td>\n",
       "      <td>0.498579</td>\n",
       "      <td>0.490217</td>\n",
       "      <td>0.480382</td>\n",
       "      <td>0.510005</td>\n",
       "      <td>0.498182</td>\n",
       "      <td>0.530342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513097</td>\n",
       "      <td>0.488849</td>\n",
       "      <td>0.503623</td>\n",
       "      <td>0.556923</td>\n",
       "      <td>0.495072</td>\n",
       "      <td>0.435286</td>\n",
       "      <td>0.503057</td>\n",
       "      <td>0.478725</td>\n",
       "      <td>0.497577</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.493020</td>\n",
       "      <td>0.482958</td>\n",
       "      <td>0.534978</td>\n",
       "      <td>0.542933</td>\n",
       "      <td>0.489376</td>\n",
       "      <td>0.496569</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.493101</td>\n",
       "      <td>0.489888</td>\n",
       "      <td>0.513542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510409</td>\n",
       "      <td>0.519828</td>\n",
       "      <td>0.500363</td>\n",
       "      <td>0.510090</td>\n",
       "      <td>0.489043</td>\n",
       "      <td>0.493199</td>\n",
       "      <td>0.470336</td>\n",
       "      <td>0.465046</td>\n",
       "      <td>0.477644</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.447746</td>\n",
       "      <td>0.534116</td>\n",
       "      <td>0.547868</td>\n",
       "      <td>0.504369</td>\n",
       "      <td>0.501500</td>\n",
       "      <td>0.521493</td>\n",
       "      <td>0.457021</td>\n",
       "      <td>0.478695</td>\n",
       "      <td>0.505849</td>\n",
       "      <td>0.533882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508161</td>\n",
       "      <td>0.478098</td>\n",
       "      <td>0.497551</td>\n",
       "      <td>0.563326</td>\n",
       "      <td>0.457870</td>\n",
       "      <td>0.472338</td>\n",
       "      <td>0.500009</td>\n",
       "      <td>0.453265</td>\n",
       "      <td>0.491967</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.461085</td>\n",
       "      <td>0.513194</td>\n",
       "      <td>0.556101</td>\n",
       "      <td>0.520571</td>\n",
       "      <td>0.488009</td>\n",
       "      <td>0.496696</td>\n",
       "      <td>0.499040</td>\n",
       "      <td>0.496998</td>\n",
       "      <td>0.511369</td>\n",
       "      <td>0.505719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520391</td>\n",
       "      <td>0.470493</td>\n",
       "      <td>0.485813</td>\n",
       "      <td>0.538397</td>\n",
       "      <td>0.473648</td>\n",
       "      <td>0.447220</td>\n",
       "      <td>0.458381</td>\n",
       "      <td>0.477883</td>\n",
       "      <td>0.458942</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.435150</td>\n",
       "      <td>0.531696</td>\n",
       "      <td>0.551221</td>\n",
       "      <td>0.537312</td>\n",
       "      <td>0.449337</td>\n",
       "      <td>0.508741</td>\n",
       "      <td>0.485030</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>0.512589</td>\n",
       "      <td>0.578558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563267</td>\n",
       "      <td>0.502186</td>\n",
       "      <td>0.499708</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>0.470146</td>\n",
       "      <td>0.474205</td>\n",
       "      <td>0.494384</td>\n",
       "      <td>0.452636</td>\n",
       "      <td>0.478806</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.425796</td>\n",
       "      <td>0.540947</td>\n",
       "      <td>0.552049</td>\n",
       "      <td>0.503721</td>\n",
       "      <td>0.500834</td>\n",
       "      <td>0.513154</td>\n",
       "      <td>0.481899</td>\n",
       "      <td>0.449743</td>\n",
       "      <td>0.531079</td>\n",
       "      <td>0.559754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542338</td>\n",
       "      <td>0.487668</td>\n",
       "      <td>0.476486</td>\n",
       "      <td>0.558433</td>\n",
       "      <td>0.427833</td>\n",
       "      <td>0.481618</td>\n",
       "      <td>0.515322</td>\n",
       "      <td>0.449693</td>\n",
       "      <td>0.472414</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.482027  0.499887  0.530806  0.538419  0.491713  0.513956  0.498010   \n",
       "1    0.454859  0.529616  0.526296  0.552197  0.496266  0.510415  0.484137   \n",
       "2    0.463892  0.528533  0.529637  0.528451  0.506440  0.525559  0.475964   \n",
       "3    0.487112  0.502789  0.547796  0.545979  0.500581  0.501580  0.497734   \n",
       "4    0.487966  0.502613  0.530262  0.509978  0.498579  0.490217  0.480382   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "205  0.493020  0.482958  0.534978  0.542933  0.489376  0.496569  0.504175   \n",
       "206  0.447746  0.534116  0.547868  0.504369  0.501500  0.521493  0.457021   \n",
       "207  0.461085  0.513194  0.556101  0.520571  0.488009  0.496696  0.499040   \n",
       "208  0.435150  0.531696  0.551221  0.537312  0.449337  0.508741  0.485030   \n",
       "209  0.425796  0.540947  0.552049  0.503721  0.500834  0.513154  0.481899   \n",
       "\n",
       "            7         8         9  ...       7.2       8.2       9.2  \\\n",
       "0    0.488720  0.489319  0.541717  ...  0.549547  0.518709  0.493687   \n",
       "1    0.507131  0.496896  0.540834  ...  0.488366  0.493662  0.497254   \n",
       "2    0.484750  0.524651  0.529517  ...  0.499960  0.477971  0.530497   \n",
       "3    0.493490  0.481571  0.520887  ...  0.523350  0.508465  0.497361   \n",
       "4    0.510005  0.498182  0.530342  ...  0.513097  0.488849  0.503623   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "205  0.493101  0.489888  0.513542  ...  0.510409  0.519828  0.500363   \n",
       "206  0.478695  0.505849  0.533882  ...  0.508161  0.478098  0.497551   \n",
       "207  0.496998  0.511369  0.505719  ...  0.520391  0.470493  0.485813   \n",
       "208  0.466011  0.512589  0.578558  ...  0.563267  0.502186  0.499708   \n",
       "209  0.449743  0.531079  0.559754  ...  0.542338  0.487668  0.476486   \n",
       "\n",
       "         10.2      11.2      12.2      13.2      14.2      15.2   num  \n",
       "0    0.519562  0.484019  0.472015  0.508887  0.467478  0.486530  0.25  \n",
       "1    0.565816  0.497960  0.456738  0.500947  0.496931  0.517806  0.25  \n",
       "2    0.613168  0.473111  0.434871  0.508940  0.505146  0.497114  0.00  \n",
       "3    0.530505  0.484081  0.486503  0.484897  0.458825  0.480811  0.50  \n",
       "4    0.556923  0.495072  0.435286  0.503057  0.478725  0.497577  0.25  \n",
       "..        ...       ...       ...       ...       ...       ...   ...  \n",
       "205  0.510090  0.489043  0.493199  0.470336  0.465046  0.477644  0.00  \n",
       "206  0.563326  0.457870  0.472338  0.500009  0.453265  0.491967  0.25  \n",
       "207  0.538397  0.473648  0.447220  0.458381  0.477883  0.458942  0.00  \n",
       "208  0.526077  0.470146  0.474205  0.494384  0.452636  0.478806  0.00  \n",
       "209  0.558433  0.427833  0.481618  0.515322  0.449693  0.472414  0.00  \n",
       "\n",
       "[210 rows x 49 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cle_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0b8fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train=pd.read_csv('vir_metadata_dnn_train.csv' )\n",
    "vir_test=pd.read_csv('vir_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e92518ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train=pd.read_csv('hun_metadata_dnn_train.csv' )\n",
    "hun_test=pd.read_csv('hun_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fe3741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_train=pd.read_csv('swi_metadata_dnn_train.csv' )\n",
    "swi_test=pd.read_csv('swi_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([cle_train,vir_train,hun_train])\n",
    "Test = pd.concat([cle_test,vir_test,hun_test,swi_test,swi_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.iloc[:,:-1]\n",
    "X_test = Test.iloc[:,:-1]\n",
    "\n",
    "y_train = Train.iloc[:,-1]\n",
    "y_test = Test.iloc[:,-1]\n",
    "\n",
    "Y_train_binary = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c43269e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.1</th>\n",
       "      <th>7.1</th>\n",
       "      <th>8.1</th>\n",
       "      <th>9.1</th>\n",
       "      <th>10.1</th>\n",
       "      <th>11.1</th>\n",
       "      <th>12.1</th>\n",
       "      <th>13.1</th>\n",
       "      <th>14.1</th>\n",
       "      <th>15.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482027</td>\n",
       "      <td>0.499887</td>\n",
       "      <td>0.530806</td>\n",
       "      <td>0.538419</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.513956</td>\n",
       "      <td>0.498010</td>\n",
       "      <td>0.488720</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475880</td>\n",
       "      <td>0.555252</td>\n",
       "      <td>0.544245</td>\n",
       "      <td>0.526145</td>\n",
       "      <td>0.516278</td>\n",
       "      <td>0.467451</td>\n",
       "      <td>0.477457</td>\n",
       "      <td>0.483086</td>\n",
       "      <td>0.468292</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454859</td>\n",
       "      <td>0.529616</td>\n",
       "      <td>0.526296</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.496266</td>\n",
       "      <td>0.510415</td>\n",
       "      <td>0.484137</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>0.496896</td>\n",
       "      <td>0.540834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523732</td>\n",
       "      <td>0.530778</td>\n",
       "      <td>0.542353</td>\n",
       "      <td>0.556844</td>\n",
       "      <td>0.497958</td>\n",
       "      <td>0.437701</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.451085</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.469252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463892</td>\n",
       "      <td>0.528533</td>\n",
       "      <td>0.529637</td>\n",
       "      <td>0.528451</td>\n",
       "      <td>0.506440</td>\n",
       "      <td>0.525559</td>\n",
       "      <td>0.475964</td>\n",
       "      <td>0.484750</td>\n",
       "      <td>0.524651</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519640</td>\n",
       "      <td>0.518561</td>\n",
       "      <td>0.539729</td>\n",
       "      <td>0.535549</td>\n",
       "      <td>0.496975</td>\n",
       "      <td>0.470960</td>\n",
       "      <td>0.462096</td>\n",
       "      <td>0.447260</td>\n",
       "      <td>0.461095</td>\n",
       "      <td>0.472696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487112</td>\n",
       "      <td>0.502789</td>\n",
       "      <td>0.547796</td>\n",
       "      <td>0.545979</td>\n",
       "      <td>0.500581</td>\n",
       "      <td>0.501580</td>\n",
       "      <td>0.497734</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.481571</td>\n",
       "      <td>0.520887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466942</td>\n",
       "      <td>0.552811</td>\n",
       "      <td>0.548186</td>\n",
       "      <td>0.553026</td>\n",
       "      <td>0.522264</td>\n",
       "      <td>0.453179</td>\n",
       "      <td>0.481235</td>\n",
       "      <td>0.505287</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.459717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.487966</td>\n",
       "      <td>0.502613</td>\n",
       "      <td>0.530262</td>\n",
       "      <td>0.509978</td>\n",
       "      <td>0.498579</td>\n",
       "      <td>0.490217</td>\n",
       "      <td>0.480382</td>\n",
       "      <td>0.510005</td>\n",
       "      <td>0.498182</td>\n",
       "      <td>0.530342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492378</td>\n",
       "      <td>0.533848</td>\n",
       "      <td>0.548217</td>\n",
       "      <td>0.514605</td>\n",
       "      <td>0.499236</td>\n",
       "      <td>0.463374</td>\n",
       "      <td>0.505422</td>\n",
       "      <td>0.508046</td>\n",
       "      <td>0.443116</td>\n",
       "      <td>0.491599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.483704</td>\n",
       "      <td>0.504237</td>\n",
       "      <td>0.479324</td>\n",
       "      <td>0.476369</td>\n",
       "      <td>0.498507</td>\n",
       "      <td>0.506080</td>\n",
       "      <td>0.533774</td>\n",
       "      <td>0.483517</td>\n",
       "      <td>0.510733</td>\n",
       "      <td>0.496863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511606</td>\n",
       "      <td>0.541578</td>\n",
       "      <td>0.490495</td>\n",
       "      <td>0.556881</td>\n",
       "      <td>0.511731</td>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.535328</td>\n",
       "      <td>0.532756</td>\n",
       "      <td>0.498870</td>\n",
       "      <td>0.512796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.490108</td>\n",
       "      <td>0.492367</td>\n",
       "      <td>0.488563</td>\n",
       "      <td>0.487793</td>\n",
       "      <td>0.495198</td>\n",
       "      <td>0.502775</td>\n",
       "      <td>0.517487</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.509056</td>\n",
       "      <td>0.507079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528129</td>\n",
       "      <td>0.505098</td>\n",
       "      <td>0.503886</td>\n",
       "      <td>0.571339</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.511508</td>\n",
       "      <td>0.525113</td>\n",
       "      <td>0.547921</td>\n",
       "      <td>0.503548</td>\n",
       "      <td>0.486414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.483685</td>\n",
       "      <td>0.498613</td>\n",
       "      <td>0.478604</td>\n",
       "      <td>0.487754</td>\n",
       "      <td>0.510728</td>\n",
       "      <td>0.487946</td>\n",
       "      <td>0.529723</td>\n",
       "      <td>0.493159</td>\n",
       "      <td>0.498613</td>\n",
       "      <td>0.495365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511690</td>\n",
       "      <td>0.523007</td>\n",
       "      <td>0.476761</td>\n",
       "      <td>0.563506</td>\n",
       "      <td>0.509990</td>\n",
       "      <td>0.505383</td>\n",
       "      <td>0.518405</td>\n",
       "      <td>0.533959</td>\n",
       "      <td>0.522450</td>\n",
       "      <td>0.490983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.476345</td>\n",
       "      <td>0.496224</td>\n",
       "      <td>0.485959</td>\n",
       "      <td>0.488809</td>\n",
       "      <td>0.503595</td>\n",
       "      <td>0.518979</td>\n",
       "      <td>0.520347</td>\n",
       "      <td>0.491363</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>0.511617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507772</td>\n",
       "      <td>0.522522</td>\n",
       "      <td>0.488939</td>\n",
       "      <td>0.532099</td>\n",
       "      <td>0.503282</td>\n",
       "      <td>0.500778</td>\n",
       "      <td>0.539109</td>\n",
       "      <td>0.538316</td>\n",
       "      <td>0.507205</td>\n",
       "      <td>0.485018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.490297</td>\n",
       "      <td>0.497950</td>\n",
       "      <td>0.473245</td>\n",
       "      <td>0.498749</td>\n",
       "      <td>0.507454</td>\n",
       "      <td>0.481953</td>\n",
       "      <td>0.528355</td>\n",
       "      <td>0.495543</td>\n",
       "      <td>0.491902</td>\n",
       "      <td>0.507735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502204</td>\n",
       "      <td>0.511834</td>\n",
       "      <td>0.493218</td>\n",
       "      <td>0.533682</td>\n",
       "      <td>0.513200</td>\n",
       "      <td>0.499402</td>\n",
       "      <td>0.522400</td>\n",
       "      <td>0.528614</td>\n",
       "      <td>0.497501</td>\n",
       "      <td>0.503214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.482027  0.499887  0.530806  0.538419  0.491713  0.513956  0.498010   \n",
       "1    0.454859  0.529616  0.526296  0.552197  0.496266  0.510415  0.484137   \n",
       "2    0.463892  0.528533  0.529637  0.528451  0.506440  0.525559  0.475964   \n",
       "3    0.487112  0.502789  0.547796  0.545979  0.500581  0.501580  0.497734   \n",
       "4    0.487966  0.502613  0.530262  0.509978  0.498579  0.490217  0.480382   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.483704  0.504237  0.479324  0.476369  0.498507  0.506080  0.533774   \n",
       "196  0.490108  0.492367  0.488563  0.487793  0.495198  0.502775  0.517487   \n",
       "197  0.483685  0.498613  0.478604  0.487754  0.510728  0.487946  0.529723   \n",
       "198  0.476345  0.496224  0.485959  0.488809  0.503595  0.518979  0.520347   \n",
       "199  0.490297  0.497950  0.473245  0.498749  0.507454  0.481953  0.528355   \n",
       "\n",
       "            7         8         9  ...       6.1       7.1       8.1  \\\n",
       "0    0.488720  0.489319  0.541717  ...  0.475880  0.555252  0.544245   \n",
       "1    0.507131  0.496896  0.540834  ...  0.523732  0.530778  0.542353   \n",
       "2    0.484750  0.524651  0.529517  ...  0.519640  0.518561  0.539729   \n",
       "3    0.493490  0.481571  0.520887  ...  0.466942  0.552811  0.548186   \n",
       "4    0.510005  0.498182  0.530342  ...  0.492378  0.533848  0.548217   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "195  0.483517  0.510733  0.496863  ...  0.511606  0.541578  0.490495   \n",
       "196  0.500597  0.509056  0.507079  ...  0.528129  0.505098  0.503886   \n",
       "197  0.493159  0.498613  0.495365  ...  0.511690  0.523007  0.476761   \n",
       "198  0.491363  0.499720  0.511617  ...  0.507772  0.522522  0.488939   \n",
       "199  0.495543  0.491902  0.507735  ...  0.502204  0.511834  0.493218   \n",
       "\n",
       "          9.1      10.1      11.1      12.1      13.1      14.1      15.1  \n",
       "0    0.526145  0.516278  0.467451  0.477457  0.483086  0.468292  0.498927  \n",
       "1    0.556844  0.497958  0.437701  0.464100  0.451085  0.413007  0.469252  \n",
       "2    0.535549  0.496975  0.470960  0.462096  0.447260  0.461095  0.472696  \n",
       "3    0.553026  0.522264  0.453179  0.481235  0.505287  0.419722  0.459717  \n",
       "4    0.514605  0.499236  0.463374  0.505422  0.508046  0.443116  0.491599  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "195  0.556881  0.511731  0.500793  0.535328  0.532756  0.498870  0.512796  \n",
       "196  0.571339  0.499505  0.511508  0.525113  0.547921  0.503548  0.486414  \n",
       "197  0.563506  0.509990  0.505383  0.518405  0.533959  0.522450  0.490983  \n",
       "198  0.532099  0.503282  0.500778  0.539109  0.538316  0.507205  0.485018  \n",
       "199  0.533682  0.513200  0.499402  0.522400  0.528614  0.497501  0.503214  \n",
       "\n",
       "[548 rows x 32 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.iloc[:,:-16]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db3d3c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428787</td>\n",
       "      <td>0.525325</td>\n",
       "      <td>0.542139</td>\n",
       "      <td>0.478648</td>\n",
       "      <td>0.506824</td>\n",
       "      <td>0.490862</td>\n",
       "      <td>0.482278</td>\n",
       "      <td>0.505213</td>\n",
       "      <td>0.516506</td>\n",
       "      <td>0.520210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469042</td>\n",
       "      <td>0.494732</td>\n",
       "      <td>0.483015</td>\n",
       "      <td>0.492952</td>\n",
       "      <td>0.539282</td>\n",
       "      <td>0.433638</td>\n",
       "      <td>0.487028</td>\n",
       "      <td>0.496327</td>\n",
       "      <td>0.451854</td>\n",
       "      <td>0.460499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444054</td>\n",
       "      <td>0.518033</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.527710</td>\n",
       "      <td>0.511543</td>\n",
       "      <td>0.505929</td>\n",
       "      <td>0.505096</td>\n",
       "      <td>0.473268</td>\n",
       "      <td>0.500194</td>\n",
       "      <td>0.563858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462495</td>\n",
       "      <td>0.520767</td>\n",
       "      <td>0.514996</td>\n",
       "      <td>0.479704</td>\n",
       "      <td>0.547857</td>\n",
       "      <td>0.469282</td>\n",
       "      <td>0.477678</td>\n",
       "      <td>0.534086</td>\n",
       "      <td>0.459659</td>\n",
       "      <td>0.482997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.464015</td>\n",
       "      <td>0.547513</td>\n",
       "      <td>0.534929</td>\n",
       "      <td>0.515994</td>\n",
       "      <td>0.526294</td>\n",
       "      <td>0.519013</td>\n",
       "      <td>0.493227</td>\n",
       "      <td>0.487353</td>\n",
       "      <td>0.533328</td>\n",
       "      <td>0.515880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485028</td>\n",
       "      <td>0.492818</td>\n",
       "      <td>0.466966</td>\n",
       "      <td>0.514667</td>\n",
       "      <td>0.588129</td>\n",
       "      <td>0.480854</td>\n",
       "      <td>0.432877</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.507247</td>\n",
       "      <td>0.502260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464099</td>\n",
       "      <td>0.502493</td>\n",
       "      <td>0.530403</td>\n",
       "      <td>0.543423</td>\n",
       "      <td>0.488266</td>\n",
       "      <td>0.506906</td>\n",
       "      <td>0.496008</td>\n",
       "      <td>0.470768</td>\n",
       "      <td>0.488893</td>\n",
       "      <td>0.567098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449605</td>\n",
       "      <td>0.551441</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>0.478567</td>\n",
       "      <td>0.537422</td>\n",
       "      <td>0.471184</td>\n",
       "      <td>0.465805</td>\n",
       "      <td>0.508096</td>\n",
       "      <td>0.466514</td>\n",
       "      <td>0.465507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451514</td>\n",
       "      <td>0.539376</td>\n",
       "      <td>0.544900</td>\n",
       "      <td>0.502148</td>\n",
       "      <td>0.503703</td>\n",
       "      <td>0.533397</td>\n",
       "      <td>0.448659</td>\n",
       "      <td>0.478863</td>\n",
       "      <td>0.508552</td>\n",
       "      <td>0.546285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482086</td>\n",
       "      <td>0.511703</td>\n",
       "      <td>0.477694</td>\n",
       "      <td>0.494675</td>\n",
       "      <td>0.542177</td>\n",
       "      <td>0.473592</td>\n",
       "      <td>0.467832</td>\n",
       "      <td>0.478610</td>\n",
       "      <td>0.443659</td>\n",
       "      <td>0.481261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.499596</td>\n",
       "      <td>0.503362</td>\n",
       "      <td>0.522893</td>\n",
       "      <td>0.496161</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>0.461692</td>\n",
       "      <td>0.509040</td>\n",
       "      <td>0.502430</td>\n",
       "      <td>0.476613</td>\n",
       "      <td>0.537732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515923</td>\n",
       "      <td>0.500189</td>\n",
       "      <td>0.543489</td>\n",
       "      <td>0.511016</td>\n",
       "      <td>0.494478</td>\n",
       "      <td>0.466297</td>\n",
       "      <td>0.458757</td>\n",
       "      <td>0.538558</td>\n",
       "      <td>0.475912</td>\n",
       "      <td>0.485755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.497214</td>\n",
       "      <td>0.491898</td>\n",
       "      <td>0.538590</td>\n",
       "      <td>0.533611</td>\n",
       "      <td>0.515420</td>\n",
       "      <td>0.481304</td>\n",
       "      <td>0.514259</td>\n",
       "      <td>0.486543</td>\n",
       "      <td>0.492588</td>\n",
       "      <td>0.514609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538429</td>\n",
       "      <td>0.494881</td>\n",
       "      <td>0.531248</td>\n",
       "      <td>0.523854</td>\n",
       "      <td>0.466190</td>\n",
       "      <td>0.529339</td>\n",
       "      <td>0.471890</td>\n",
       "      <td>0.531397</td>\n",
       "      <td>0.437475</td>\n",
       "      <td>0.486962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.517050</td>\n",
       "      <td>0.514450</td>\n",
       "      <td>0.509608</td>\n",
       "      <td>0.503844</td>\n",
       "      <td>0.533506</td>\n",
       "      <td>0.505198</td>\n",
       "      <td>0.480254</td>\n",
       "      <td>0.489807</td>\n",
       "      <td>0.471894</td>\n",
       "      <td>0.506556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523795</td>\n",
       "      <td>0.467489</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.530422</td>\n",
       "      <td>0.487560</td>\n",
       "      <td>0.493201</td>\n",
       "      <td>0.484776</td>\n",
       "      <td>0.545881</td>\n",
       "      <td>0.466940</td>\n",
       "      <td>0.477744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.525592</td>\n",
       "      <td>0.497026</td>\n",
       "      <td>0.542631</td>\n",
       "      <td>0.507730</td>\n",
       "      <td>0.521060</td>\n",
       "      <td>0.475272</td>\n",
       "      <td>0.506918</td>\n",
       "      <td>0.474250</td>\n",
       "      <td>0.486505</td>\n",
       "      <td>0.510403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519751</td>\n",
       "      <td>0.510182</td>\n",
       "      <td>0.530916</td>\n",
       "      <td>0.509050</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.491346</td>\n",
       "      <td>0.493666</td>\n",
       "      <td>0.532326</td>\n",
       "      <td>0.481168</td>\n",
       "      <td>0.488967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.521995</td>\n",
       "      <td>0.499324</td>\n",
       "      <td>0.531584</td>\n",
       "      <td>0.508733</td>\n",
       "      <td>0.551871</td>\n",
       "      <td>0.488382</td>\n",
       "      <td>0.494927</td>\n",
       "      <td>0.486490</td>\n",
       "      <td>0.486524</td>\n",
       "      <td>0.511331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525063</td>\n",
       "      <td>0.488777</td>\n",
       "      <td>0.522951</td>\n",
       "      <td>0.528720</td>\n",
       "      <td>0.499248</td>\n",
       "      <td>0.509396</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>0.546639</td>\n",
       "      <td>0.460442</td>\n",
       "      <td>0.474039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.428787  0.525325  0.542139  0.478648  0.506824  0.490862  0.482278   \n",
       "1   0.444054  0.518033  0.532847  0.527710  0.511543  0.505929  0.505096   \n",
       "2   0.464015  0.547513  0.534929  0.515994  0.526294  0.519013  0.493227   \n",
       "3   0.464099  0.502493  0.530403  0.543423  0.488266  0.506906  0.496008   \n",
       "4   0.451514  0.539376  0.544900  0.502148  0.503703  0.533397  0.448659   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.499596  0.503362  0.522893  0.496161  0.543045  0.461692  0.509040   \n",
       "78  0.497214  0.491898  0.538590  0.533611  0.515420  0.481304  0.514259   \n",
       "79  0.517050  0.514450  0.509608  0.503844  0.533506  0.505198  0.480254   \n",
       "80  0.525592  0.497026  0.542631  0.507730  0.521060  0.475272  0.506918   \n",
       "81  0.521995  0.499324  0.531584  0.508733  0.551871  0.488382  0.494927   \n",
       "\n",
       "           7         8         9  ...       6.2       7.2       8.2       9.2  \\\n",
       "0   0.505213  0.516506  0.520210  ...  0.469042  0.494732  0.483015  0.492952   \n",
       "1   0.473268  0.500194  0.563858  ...  0.462495  0.520767  0.514996  0.479704   \n",
       "2   0.487353  0.533328  0.515880  ...  0.485028  0.492818  0.466966  0.514667   \n",
       "3   0.470768  0.488893  0.567098  ...  0.449605  0.551441  0.525775  0.478567   \n",
       "4   0.478863  0.508552  0.546285  ...  0.482086  0.511703  0.477694  0.494675   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "77  0.502430  0.476613  0.537732  ...  0.515923  0.500189  0.543489  0.511016   \n",
       "78  0.486543  0.492588  0.514609  ...  0.538429  0.494881  0.531248  0.523854   \n",
       "79  0.489807  0.471894  0.506556  ...  0.523795  0.467489  0.512300  0.530422   \n",
       "80  0.474250  0.486505  0.510403  ...  0.519751  0.510182  0.530916  0.509050   \n",
       "81  0.486490  0.486524  0.511331  ...  0.525063  0.488777  0.522951  0.528720   \n",
       "\n",
       "        10.2      11.2      12.2      13.2      14.2      15.2  \n",
       "0   0.539282  0.433638  0.487028  0.496327  0.451854  0.460499  \n",
       "1   0.547857  0.469282  0.477678  0.534086  0.459659  0.482997  \n",
       "2   0.588129  0.480854  0.432877  0.501815  0.507247  0.502260  \n",
       "3   0.537422  0.471184  0.465805  0.508096  0.466514  0.465507  \n",
       "4   0.542177  0.473592  0.467832  0.478610  0.443659  0.481261  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "77  0.494478  0.466297  0.458757  0.538558  0.475912  0.485755  \n",
       "78  0.466190  0.529339  0.471890  0.531397  0.437475  0.486962  \n",
       "79  0.487560  0.493201  0.484776  0.545881  0.466940  0.477744  \n",
       "80  0.477800  0.491346  0.493666  0.532326  0.481168  0.488967  \n",
       "81  0.499248  0.509396  0.497447  0.546639  0.460442  0.474039  \n",
       "\n",
       "[536 rows x 48 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.iloc[:,:-16]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3016ecb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cle_train_temp = cle_train.iloc[:,:-17]\n",
    "cle_train_Y = cle_train.iloc[:,-1]\n",
    "cle_train = pd.concat([cle_train_temp, cle_train_Y], axis=1)\n",
    "#cle_train.to_csv('cle_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f759ec55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.1</th>\n",
       "      <th>7.1</th>\n",
       "      <th>8.1</th>\n",
       "      <th>9.1</th>\n",
       "      <th>10.1</th>\n",
       "      <th>11.1</th>\n",
       "      <th>12.1</th>\n",
       "      <th>13.1</th>\n",
       "      <th>14.1</th>\n",
       "      <th>15.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482027</td>\n",
       "      <td>0.499887</td>\n",
       "      <td>0.530806</td>\n",
       "      <td>0.538419</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.513956</td>\n",
       "      <td>0.498010</td>\n",
       "      <td>0.488720</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475880</td>\n",
       "      <td>0.555252</td>\n",
       "      <td>0.544245</td>\n",
       "      <td>0.526145</td>\n",
       "      <td>0.516278</td>\n",
       "      <td>0.467451</td>\n",
       "      <td>0.477457</td>\n",
       "      <td>0.483086</td>\n",
       "      <td>0.468292</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454859</td>\n",
       "      <td>0.529616</td>\n",
       "      <td>0.526296</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.496266</td>\n",
       "      <td>0.510415</td>\n",
       "      <td>0.484137</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>0.496896</td>\n",
       "      <td>0.540834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523732</td>\n",
       "      <td>0.530778</td>\n",
       "      <td>0.542353</td>\n",
       "      <td>0.556844</td>\n",
       "      <td>0.497958</td>\n",
       "      <td>0.437701</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.451085</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.469252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463892</td>\n",
       "      <td>0.528533</td>\n",
       "      <td>0.529637</td>\n",
       "      <td>0.528451</td>\n",
       "      <td>0.506440</td>\n",
       "      <td>0.525559</td>\n",
       "      <td>0.475964</td>\n",
       "      <td>0.484750</td>\n",
       "      <td>0.524651</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519640</td>\n",
       "      <td>0.518561</td>\n",
       "      <td>0.539729</td>\n",
       "      <td>0.535549</td>\n",
       "      <td>0.496975</td>\n",
       "      <td>0.470960</td>\n",
       "      <td>0.462096</td>\n",
       "      <td>0.447260</td>\n",
       "      <td>0.461095</td>\n",
       "      <td>0.472696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487112</td>\n",
       "      <td>0.502789</td>\n",
       "      <td>0.547796</td>\n",
       "      <td>0.545979</td>\n",
       "      <td>0.500581</td>\n",
       "      <td>0.501580</td>\n",
       "      <td>0.497734</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.481571</td>\n",
       "      <td>0.520887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466942</td>\n",
       "      <td>0.552811</td>\n",
       "      <td>0.548186</td>\n",
       "      <td>0.553026</td>\n",
       "      <td>0.522264</td>\n",
       "      <td>0.453179</td>\n",
       "      <td>0.481235</td>\n",
       "      <td>0.505287</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.459717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.487966</td>\n",
       "      <td>0.502613</td>\n",
       "      <td>0.530262</td>\n",
       "      <td>0.509978</td>\n",
       "      <td>0.498579</td>\n",
       "      <td>0.490217</td>\n",
       "      <td>0.480382</td>\n",
       "      <td>0.510005</td>\n",
       "      <td>0.498182</td>\n",
       "      <td>0.530342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492378</td>\n",
       "      <td>0.533848</td>\n",
       "      <td>0.548217</td>\n",
       "      <td>0.514605</td>\n",
       "      <td>0.499236</td>\n",
       "      <td>0.463374</td>\n",
       "      <td>0.505422</td>\n",
       "      <td>0.508046</td>\n",
       "      <td>0.443116</td>\n",
       "      <td>0.491599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.493020</td>\n",
       "      <td>0.482958</td>\n",
       "      <td>0.534978</td>\n",
       "      <td>0.542933</td>\n",
       "      <td>0.489376</td>\n",
       "      <td>0.496569</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.493101</td>\n",
       "      <td>0.489888</td>\n",
       "      <td>0.513542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465223</td>\n",
       "      <td>0.535988</td>\n",
       "      <td>0.527734</td>\n",
       "      <td>0.550042</td>\n",
       "      <td>0.536676</td>\n",
       "      <td>0.468299</td>\n",
       "      <td>0.486209</td>\n",
       "      <td>0.521948</td>\n",
       "      <td>0.447481</td>\n",
       "      <td>0.470974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.447746</td>\n",
       "      <td>0.534116</td>\n",
       "      <td>0.547868</td>\n",
       "      <td>0.504369</td>\n",
       "      <td>0.501500</td>\n",
       "      <td>0.521493</td>\n",
       "      <td>0.457021</td>\n",
       "      <td>0.478695</td>\n",
       "      <td>0.505849</td>\n",
       "      <td>0.533882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490777</td>\n",
       "      <td>0.514747</td>\n",
       "      <td>0.528929</td>\n",
       "      <td>0.542481</td>\n",
       "      <td>0.503048</td>\n",
       "      <td>0.502252</td>\n",
       "      <td>0.476694</td>\n",
       "      <td>0.462755</td>\n",
       "      <td>0.473249</td>\n",
       "      <td>0.459428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.461085</td>\n",
       "      <td>0.513194</td>\n",
       "      <td>0.556101</td>\n",
       "      <td>0.520571</td>\n",
       "      <td>0.488009</td>\n",
       "      <td>0.496696</td>\n",
       "      <td>0.499040</td>\n",
       "      <td>0.496998</td>\n",
       "      <td>0.511369</td>\n",
       "      <td>0.505719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484868</td>\n",
       "      <td>0.512840</td>\n",
       "      <td>0.557801</td>\n",
       "      <td>0.539247</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.482878</td>\n",
       "      <td>0.476414</td>\n",
       "      <td>0.497650</td>\n",
       "      <td>0.495408</td>\n",
       "      <td>0.469354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.435150</td>\n",
       "      <td>0.531696</td>\n",
       "      <td>0.551221</td>\n",
       "      <td>0.537312</td>\n",
       "      <td>0.449337</td>\n",
       "      <td>0.508741</td>\n",
       "      <td>0.485030</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>0.512589</td>\n",
       "      <td>0.578558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511133</td>\n",
       "      <td>0.507535</td>\n",
       "      <td>0.536167</td>\n",
       "      <td>0.520207</td>\n",
       "      <td>0.520177</td>\n",
       "      <td>0.488848</td>\n",
       "      <td>0.494699</td>\n",
       "      <td>0.452526</td>\n",
       "      <td>0.518261</td>\n",
       "      <td>0.502953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.425796</td>\n",
       "      <td>0.540947</td>\n",
       "      <td>0.552049</td>\n",
       "      <td>0.503721</td>\n",
       "      <td>0.500834</td>\n",
       "      <td>0.513154</td>\n",
       "      <td>0.481899</td>\n",
       "      <td>0.449743</td>\n",
       "      <td>0.531079</td>\n",
       "      <td>0.559754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496832</td>\n",
       "      <td>0.508715</td>\n",
       "      <td>0.523222</td>\n",
       "      <td>0.522516</td>\n",
       "      <td>0.488133</td>\n",
       "      <td>0.476173</td>\n",
       "      <td>0.500147</td>\n",
       "      <td>0.486746</td>\n",
       "      <td>0.500542</td>\n",
       "      <td>0.482209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.482027  0.499887  0.530806  0.538419  0.491713  0.513956  0.498010   \n",
       "1    0.454859  0.529616  0.526296  0.552197  0.496266  0.510415  0.484137   \n",
       "2    0.463892  0.528533  0.529637  0.528451  0.506440  0.525559  0.475964   \n",
       "3    0.487112  0.502789  0.547796  0.545979  0.500581  0.501580  0.497734   \n",
       "4    0.487966  0.502613  0.530262  0.509978  0.498579  0.490217  0.480382   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "205  0.493020  0.482958  0.534978  0.542933  0.489376  0.496569  0.504175   \n",
       "206  0.447746  0.534116  0.547868  0.504369  0.501500  0.521493  0.457021   \n",
       "207  0.461085  0.513194  0.556101  0.520571  0.488009  0.496696  0.499040   \n",
       "208  0.435150  0.531696  0.551221  0.537312  0.449337  0.508741  0.485030   \n",
       "209  0.425796  0.540947  0.552049  0.503721  0.500834  0.513154  0.481899   \n",
       "\n",
       "            7         8         9  ...       6.1       7.1       8.1  \\\n",
       "0    0.488720  0.489319  0.541717  ...  0.475880  0.555252  0.544245   \n",
       "1    0.507131  0.496896  0.540834  ...  0.523732  0.530778  0.542353   \n",
       "2    0.484750  0.524651  0.529517  ...  0.519640  0.518561  0.539729   \n",
       "3    0.493490  0.481571  0.520887  ...  0.466942  0.552811  0.548186   \n",
       "4    0.510005  0.498182  0.530342  ...  0.492378  0.533848  0.548217   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "205  0.493101  0.489888  0.513542  ...  0.465223  0.535988  0.527734   \n",
       "206  0.478695  0.505849  0.533882  ...  0.490777  0.514747  0.528929   \n",
       "207  0.496998  0.511369  0.505719  ...  0.484868  0.512840  0.557801   \n",
       "208  0.466011  0.512589  0.578558  ...  0.511133  0.507535  0.536167   \n",
       "209  0.449743  0.531079  0.559754  ...  0.496832  0.508715  0.523222   \n",
       "\n",
       "          9.1      10.1      11.1      12.1      13.1      14.1      15.1  \n",
       "0    0.526145  0.516278  0.467451  0.477457  0.483086  0.468292  0.498927  \n",
       "1    0.556844  0.497958  0.437701  0.464100  0.451085  0.413007  0.469252  \n",
       "2    0.535549  0.496975  0.470960  0.462096  0.447260  0.461095  0.472696  \n",
       "3    0.553026  0.522264  0.453179  0.481235  0.505287  0.419722  0.459717  \n",
       "4    0.514605  0.499236  0.463374  0.505422  0.508046  0.443116  0.491599  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "205  0.550042  0.536676  0.468299  0.486209  0.521948  0.447481  0.470974  \n",
       "206  0.542481  0.503048  0.502252  0.476694  0.462755  0.473249  0.459428  \n",
       "207  0.539247  0.511494  0.482878  0.476414  0.497650  0.495408  0.469354  \n",
       "208  0.520207  0.520177  0.488848  0.494699  0.452526  0.518261  0.502953  \n",
       "209  0.522516  0.488133  0.476173  0.500147  0.486746  0.500542  0.482209  \n",
       "\n",
       "[210 rows x 32 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cle_train_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b0fd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train_temp = vir_train.iloc[:,:-17]\n",
    "vir_train_Y = vir_train.iloc[:,-1]\n",
    "vir_train = pd.concat([vir_train_temp, vir_train_Y], axis=1)\n",
    "#vir_train.to_csv('vir_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ad66556",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train_temp = hun_train.iloc[:,:-17]\n",
    "hun_train_Y = hun_train.iloc[:,-1]\n",
    "hun_train = pd.concat([hun_train_temp, hun_train_Y], axis=1)\n",
    "#hun_train.to_csv('hun_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04e852ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_test_temp = cle_test.iloc[:,:-17]\n",
    "cle_test_Y = cle_test.iloc[:,-1]\n",
    "cle_test = pd.concat([cle_test_temp, cle_test_Y], axis=1)\n",
    "#cle_test.to_csv('cle_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9041c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_test_temp = vir_test.iloc[:,:-17]\n",
    "vir_test_Y = vir_test.iloc[:,-1]\n",
    "vir_test = pd.concat([vir_test_temp, vir_test_Y], axis=1)\n",
    "#vir_test.to_csv('vir_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4764f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_test_temp = hun_test.iloc[:,:-17]\n",
    "hun_test_Y = hun_test.iloc[:,-1]\n",
    "hun_test = pd.concat([hun_test_temp, hun_test_Y], axis=1)\n",
    "#hun_test.to_csv('hun_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4349043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.3</th>\n",
       "      <th>8.3</th>\n",
       "      <th>9.3</th>\n",
       "      <th>10.3</th>\n",
       "      <th>11.3</th>\n",
       "      <th>12.3</th>\n",
       "      <th>13.3</th>\n",
       "      <th>14.3</th>\n",
       "      <th>15.3</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.522762</td>\n",
       "      <td>0.504038</td>\n",
       "      <td>0.527250</td>\n",
       "      <td>0.498387</td>\n",
       "      <td>0.565987</td>\n",
       "      <td>0.509586</td>\n",
       "      <td>0.479623</td>\n",
       "      <td>0.509473</td>\n",
       "      <td>0.480492</td>\n",
       "      <td>0.534721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537556</td>\n",
       "      <td>0.453480</td>\n",
       "      <td>0.577583</td>\n",
       "      <td>0.446029</td>\n",
       "      <td>0.485879</td>\n",
       "      <td>0.386280</td>\n",
       "      <td>0.497379</td>\n",
       "      <td>0.454557</td>\n",
       "      <td>0.509074</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512266</td>\n",
       "      <td>0.496535</td>\n",
       "      <td>0.537593</td>\n",
       "      <td>0.512366</td>\n",
       "      <td>0.549310</td>\n",
       "      <td>0.491441</td>\n",
       "      <td>0.498024</td>\n",
       "      <td>0.484337</td>\n",
       "      <td>0.487093</td>\n",
       "      <td>0.521420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519116</td>\n",
       "      <td>0.457791</td>\n",
       "      <td>0.554603</td>\n",
       "      <td>0.459480</td>\n",
       "      <td>0.484268</td>\n",
       "      <td>0.438276</td>\n",
       "      <td>0.499722</td>\n",
       "      <td>0.489912</td>\n",
       "      <td>0.514547</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529690</td>\n",
       "      <td>0.491952</td>\n",
       "      <td>0.524946</td>\n",
       "      <td>0.485390</td>\n",
       "      <td>0.539485</td>\n",
       "      <td>0.485555</td>\n",
       "      <td>0.503719</td>\n",
       "      <td>0.480027</td>\n",
       "      <td>0.475724</td>\n",
       "      <td>0.530794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544467</td>\n",
       "      <td>0.473762</td>\n",
       "      <td>0.562892</td>\n",
       "      <td>0.473715</td>\n",
       "      <td>0.511834</td>\n",
       "      <td>0.417594</td>\n",
       "      <td>0.485931</td>\n",
       "      <td>0.456725</td>\n",
       "      <td>0.503743</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.515700</td>\n",
       "      <td>0.495323</td>\n",
       "      <td>0.521070</td>\n",
       "      <td>0.486139</td>\n",
       "      <td>0.526061</td>\n",
       "      <td>0.464749</td>\n",
       "      <td>0.493206</td>\n",
       "      <td>0.486621</td>\n",
       "      <td>0.492749</td>\n",
       "      <td>0.515017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515474</td>\n",
       "      <td>0.460602</td>\n",
       "      <td>0.541977</td>\n",
       "      <td>0.508290</td>\n",
       "      <td>0.469738</td>\n",
       "      <td>0.478705</td>\n",
       "      <td>0.516899</td>\n",
       "      <td>0.476888</td>\n",
       "      <td>0.537910</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.504315</td>\n",
       "      <td>0.504432</td>\n",
       "      <td>0.526749</td>\n",
       "      <td>0.493828</td>\n",
       "      <td>0.539291</td>\n",
       "      <td>0.465600</td>\n",
       "      <td>0.504622</td>\n",
       "      <td>0.498895</td>\n",
       "      <td>0.482281</td>\n",
       "      <td>0.543537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527635</td>\n",
       "      <td>0.454373</td>\n",
       "      <td>0.578429</td>\n",
       "      <td>0.465488</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0.381890</td>\n",
       "      <td>0.476488</td>\n",
       "      <td>0.486014</td>\n",
       "      <td>0.542625</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.521899</td>\n",
       "      <td>0.506514</td>\n",
       "      <td>0.491817</td>\n",
       "      <td>0.525493</td>\n",
       "      <td>0.516104</td>\n",
       "      <td>0.489461</td>\n",
       "      <td>0.497187</td>\n",
       "      <td>0.504617</td>\n",
       "      <td>0.488040</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.493402</td>\n",
       "      <td>0.513794</td>\n",
       "      <td>0.503867</td>\n",
       "      <td>0.505538</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>0.468497</td>\n",
       "      <td>0.501576</td>\n",
       "      <td>0.509287</td>\n",
       "      <td>0.484469</td>\n",
       "      <td>0.535978</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.497897</td>\n",
       "      <td>0.508730</td>\n",
       "      <td>0.510682</td>\n",
       "      <td>0.498494</td>\n",
       "      <td>0.547744</td>\n",
       "      <td>0.476758</td>\n",
       "      <td>0.501776</td>\n",
       "      <td>0.500636</td>\n",
       "      <td>0.481379</td>\n",
       "      <td>0.542525</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.506661</td>\n",
       "      <td>0.498455</td>\n",
       "      <td>0.525077</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.547720</td>\n",
       "      <td>0.491332</td>\n",
       "      <td>0.483464</td>\n",
       "      <td>0.487521</td>\n",
       "      <td>0.464264</td>\n",
       "      <td>0.503385</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.517776</td>\n",
       "      <td>0.477103</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>0.512531</td>\n",
       "      <td>0.520010</td>\n",
       "      <td>0.488564</td>\n",
       "      <td>0.503612</td>\n",
       "      <td>0.492379</td>\n",
       "      <td>0.505658</td>\n",
       "      <td>0.513014</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.522762  0.504038  0.527250  0.498387  0.565987  0.509586  0.479623   \n",
       "1    0.512266  0.496535  0.537593  0.512366  0.549310  0.491441  0.498024   \n",
       "2    0.529690  0.491952  0.524946  0.485390  0.539485  0.485555  0.503719   \n",
       "3    0.515700  0.495323  0.521070  0.486139  0.526061  0.464749  0.493206   \n",
       "4    0.504315  0.504432  0.526749  0.493828  0.539291  0.465600  0.504622   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "200  0.521899  0.506514  0.491817  0.525493  0.516104  0.489461  0.497187   \n",
       "201  0.493402  0.513794  0.503867  0.505538  0.537071  0.468497  0.501576   \n",
       "202  0.497897  0.508730  0.510682  0.498494  0.547744  0.476758  0.501776   \n",
       "203  0.506661  0.498455  0.525077  0.517549  0.547720  0.491332  0.483464   \n",
       "204  0.517776  0.477103  0.549429  0.512531  0.520010  0.488564  0.503612   \n",
       "\n",
       "            7         8         9  ...       7.3       8.3       9.3  \\\n",
       "0    0.509473  0.480492  0.534721  ...  0.537556  0.453480  0.577583   \n",
       "1    0.484337  0.487093  0.521420  ...  0.519116  0.457791  0.554603   \n",
       "2    0.480027  0.475724  0.530794  ...  0.544467  0.473762  0.562892   \n",
       "3    0.486621  0.492749  0.515017  ...  0.515474  0.460602  0.541977   \n",
       "4    0.498895  0.482281  0.543537  ...  0.527635  0.454373  0.578429   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "200  0.504617  0.488040  0.539020  ...       NaN       NaN       NaN   \n",
       "201  0.509287  0.484469  0.535978  ...       NaN       NaN       NaN   \n",
       "202  0.500636  0.481379  0.542525  ...       NaN       NaN       NaN   \n",
       "203  0.487521  0.464264  0.503385  ...       NaN       NaN       NaN   \n",
       "204  0.492379  0.505658  0.513014  ...       NaN       NaN       NaN   \n",
       "\n",
       "         10.3      11.3      12.3      13.3      14.3      15.3   num  \n",
       "0    0.446029  0.485879  0.386280  0.497379  0.454557  0.509074  0.75  \n",
       "1    0.459480  0.484268  0.438276  0.499722  0.489912  0.514547  0.75  \n",
       "2    0.473715  0.511834  0.417594  0.485931  0.456725  0.503743  0.50  \n",
       "3    0.508290  0.469738  0.478705  0.516899  0.476888  0.537910  0.25  \n",
       "4    0.465488  0.502486  0.381890  0.476488  0.486014  0.542625  0.25  \n",
       "..        ...       ...       ...       ...       ...       ...   ...  \n",
       "200       NaN       NaN       NaN       NaN       NaN       NaN  0.25  \n",
       "201       NaN       NaN       NaN       NaN       NaN       NaN  0.25  \n",
       "202       NaN       NaN       NaN       NaN       NaN       NaN  0.75  \n",
       "203       NaN       NaN       NaN       NaN       NaN       NaN  0.25  \n",
       "204       NaN       NaN       NaN       NaN       NaN       NaN  0.75  \n",
       "\n",
       "[287 rows x 65 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swi_test_new = pd.concat([swi_train, swi_test])\n",
    "swi_test_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bd79e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_test_temp = swi_test_new.iloc[:,:-17]\n",
    "swi_test_Y = swi_test_new.iloc[:,-1]\n",
    "swi_test = pd.concat([swi_test_temp, swi_test_Y], axis=1)\n",
    "#swi_test.to_csv('swi_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e0b654e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.1</th>\n",
       "      <th>8.1</th>\n",
       "      <th>9.1</th>\n",
       "      <th>10.1</th>\n",
       "      <th>11.1</th>\n",
       "      <th>12.1</th>\n",
       "      <th>13.1</th>\n",
       "      <th>14.1</th>\n",
       "      <th>15.1</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482027</td>\n",
       "      <td>0.499887</td>\n",
       "      <td>0.530806</td>\n",
       "      <td>0.538419</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.513956</td>\n",
       "      <td>0.498010</td>\n",
       "      <td>0.488720</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555252</td>\n",
       "      <td>0.544245</td>\n",
       "      <td>0.526145</td>\n",
       "      <td>0.516278</td>\n",
       "      <td>0.467451</td>\n",
       "      <td>0.477457</td>\n",
       "      <td>0.483086</td>\n",
       "      <td>0.468292</td>\n",
       "      <td>0.498927</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454859</td>\n",
       "      <td>0.529616</td>\n",
       "      <td>0.526296</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.496266</td>\n",
       "      <td>0.510415</td>\n",
       "      <td>0.484137</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>0.496896</td>\n",
       "      <td>0.540834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530778</td>\n",
       "      <td>0.542353</td>\n",
       "      <td>0.556844</td>\n",
       "      <td>0.497958</td>\n",
       "      <td>0.437701</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.451085</td>\n",
       "      <td>0.413007</td>\n",
       "      <td>0.469252</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463892</td>\n",
       "      <td>0.528533</td>\n",
       "      <td>0.529637</td>\n",
       "      <td>0.528451</td>\n",
       "      <td>0.506440</td>\n",
       "      <td>0.525559</td>\n",
       "      <td>0.475964</td>\n",
       "      <td>0.484750</td>\n",
       "      <td>0.524651</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518561</td>\n",
       "      <td>0.539729</td>\n",
       "      <td>0.535549</td>\n",
       "      <td>0.496975</td>\n",
       "      <td>0.470960</td>\n",
       "      <td>0.462096</td>\n",
       "      <td>0.447260</td>\n",
       "      <td>0.461095</td>\n",
       "      <td>0.472696</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487112</td>\n",
       "      <td>0.502789</td>\n",
       "      <td>0.547796</td>\n",
       "      <td>0.545979</td>\n",
       "      <td>0.500581</td>\n",
       "      <td>0.501580</td>\n",
       "      <td>0.497734</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.481571</td>\n",
       "      <td>0.520887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552811</td>\n",
       "      <td>0.548186</td>\n",
       "      <td>0.553026</td>\n",
       "      <td>0.522264</td>\n",
       "      <td>0.453179</td>\n",
       "      <td>0.481235</td>\n",
       "      <td>0.505287</td>\n",
       "      <td>0.419722</td>\n",
       "      <td>0.459717</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.487966</td>\n",
       "      <td>0.502613</td>\n",
       "      <td>0.530262</td>\n",
       "      <td>0.509978</td>\n",
       "      <td>0.498579</td>\n",
       "      <td>0.490217</td>\n",
       "      <td>0.480382</td>\n",
       "      <td>0.510005</td>\n",
       "      <td>0.498182</td>\n",
       "      <td>0.530342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533848</td>\n",
       "      <td>0.548217</td>\n",
       "      <td>0.514605</td>\n",
       "      <td>0.499236</td>\n",
       "      <td>0.463374</td>\n",
       "      <td>0.505422</td>\n",
       "      <td>0.508046</td>\n",
       "      <td>0.443116</td>\n",
       "      <td>0.491599</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.493020</td>\n",
       "      <td>0.482958</td>\n",
       "      <td>0.534978</td>\n",
       "      <td>0.542933</td>\n",
       "      <td>0.489376</td>\n",
       "      <td>0.496569</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.493101</td>\n",
       "      <td>0.489888</td>\n",
       "      <td>0.513542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535988</td>\n",
       "      <td>0.527734</td>\n",
       "      <td>0.550042</td>\n",
       "      <td>0.536676</td>\n",
       "      <td>0.468299</td>\n",
       "      <td>0.486209</td>\n",
       "      <td>0.521948</td>\n",
       "      <td>0.447481</td>\n",
       "      <td>0.470974</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.447746</td>\n",
       "      <td>0.534116</td>\n",
       "      <td>0.547868</td>\n",
       "      <td>0.504369</td>\n",
       "      <td>0.501500</td>\n",
       "      <td>0.521493</td>\n",
       "      <td>0.457021</td>\n",
       "      <td>0.478695</td>\n",
       "      <td>0.505849</td>\n",
       "      <td>0.533882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514747</td>\n",
       "      <td>0.528929</td>\n",
       "      <td>0.542481</td>\n",
       "      <td>0.503048</td>\n",
       "      <td>0.502252</td>\n",
       "      <td>0.476694</td>\n",
       "      <td>0.462755</td>\n",
       "      <td>0.473249</td>\n",
       "      <td>0.459428</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.461085</td>\n",
       "      <td>0.513194</td>\n",
       "      <td>0.556101</td>\n",
       "      <td>0.520571</td>\n",
       "      <td>0.488009</td>\n",
       "      <td>0.496696</td>\n",
       "      <td>0.499040</td>\n",
       "      <td>0.496998</td>\n",
       "      <td>0.511369</td>\n",
       "      <td>0.505719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512840</td>\n",
       "      <td>0.557801</td>\n",
       "      <td>0.539247</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.482878</td>\n",
       "      <td>0.476414</td>\n",
       "      <td>0.497650</td>\n",
       "      <td>0.495408</td>\n",
       "      <td>0.469354</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.435150</td>\n",
       "      <td>0.531696</td>\n",
       "      <td>0.551221</td>\n",
       "      <td>0.537312</td>\n",
       "      <td>0.449337</td>\n",
       "      <td>0.508741</td>\n",
       "      <td>0.485030</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>0.512589</td>\n",
       "      <td>0.578558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507535</td>\n",
       "      <td>0.536167</td>\n",
       "      <td>0.520207</td>\n",
       "      <td>0.520177</td>\n",
       "      <td>0.488848</td>\n",
       "      <td>0.494699</td>\n",
       "      <td>0.452526</td>\n",
       "      <td>0.518261</td>\n",
       "      <td>0.502953</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.425796</td>\n",
       "      <td>0.540947</td>\n",
       "      <td>0.552049</td>\n",
       "      <td>0.503721</td>\n",
       "      <td>0.500834</td>\n",
       "      <td>0.513154</td>\n",
       "      <td>0.481899</td>\n",
       "      <td>0.449743</td>\n",
       "      <td>0.531079</td>\n",
       "      <td>0.559754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508715</td>\n",
       "      <td>0.523222</td>\n",
       "      <td>0.522516</td>\n",
       "      <td>0.488133</td>\n",
       "      <td>0.476173</td>\n",
       "      <td>0.500147</td>\n",
       "      <td>0.486746</td>\n",
       "      <td>0.500542</td>\n",
       "      <td>0.482209</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.482027  0.499887  0.530806  0.538419  0.491713  0.513956  0.498010   \n",
       "1    0.454859  0.529616  0.526296  0.552197  0.496266  0.510415  0.484137   \n",
       "2    0.463892  0.528533  0.529637  0.528451  0.506440  0.525559  0.475964   \n",
       "3    0.487112  0.502789  0.547796  0.545979  0.500581  0.501580  0.497734   \n",
       "4    0.487966  0.502613  0.530262  0.509978  0.498579  0.490217  0.480382   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "205  0.493020  0.482958  0.534978  0.542933  0.489376  0.496569  0.504175   \n",
       "206  0.447746  0.534116  0.547868  0.504369  0.501500  0.521493  0.457021   \n",
       "207  0.461085  0.513194  0.556101  0.520571  0.488009  0.496696  0.499040   \n",
       "208  0.435150  0.531696  0.551221  0.537312  0.449337  0.508741  0.485030   \n",
       "209  0.425796  0.540947  0.552049  0.503721  0.500834  0.513154  0.481899   \n",
       "\n",
       "            7         8         9  ...       7.1       8.1       9.1  \\\n",
       "0    0.488720  0.489319  0.541717  ...  0.555252  0.544245  0.526145   \n",
       "1    0.507131  0.496896  0.540834  ...  0.530778  0.542353  0.556844   \n",
       "2    0.484750  0.524651  0.529517  ...  0.518561  0.539729  0.535549   \n",
       "3    0.493490  0.481571  0.520887  ...  0.552811  0.548186  0.553026   \n",
       "4    0.510005  0.498182  0.530342  ...  0.533848  0.548217  0.514605   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "205  0.493101  0.489888  0.513542  ...  0.535988  0.527734  0.550042   \n",
       "206  0.478695  0.505849  0.533882  ...  0.514747  0.528929  0.542481   \n",
       "207  0.496998  0.511369  0.505719  ...  0.512840  0.557801  0.539247   \n",
       "208  0.466011  0.512589  0.578558  ...  0.507535  0.536167  0.520207   \n",
       "209  0.449743  0.531079  0.559754  ...  0.508715  0.523222  0.522516   \n",
       "\n",
       "         10.1      11.1      12.1      13.1      14.1      15.1   num  \n",
       "0    0.516278  0.467451  0.477457  0.483086  0.468292  0.498927  0.25  \n",
       "1    0.497958  0.437701  0.464100  0.451085  0.413007  0.469252  0.25  \n",
       "2    0.496975  0.470960  0.462096  0.447260  0.461095  0.472696  0.00  \n",
       "3    0.522264  0.453179  0.481235  0.505287  0.419722  0.459717  0.50  \n",
       "4    0.499236  0.463374  0.505422  0.508046  0.443116  0.491599  0.25  \n",
       "..        ...       ...       ...       ...       ...       ...   ...  \n",
       "205  0.536676  0.468299  0.486209  0.521948  0.447481  0.470974  0.00  \n",
       "206  0.503048  0.502252  0.476694  0.462755  0.473249  0.459428  0.25  \n",
       "207  0.511494  0.482878  0.476414  0.497650  0.495408  0.469354  0.00  \n",
       "208  0.520177  0.488848  0.494699  0.452526  0.518261  0.502953  0.00  \n",
       "209  0.488133  0.476173  0.500147  0.486746  0.500542  0.482209  0.00  \n",
       "\n",
       "[210 rows x 33 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cle_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55a9da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for deep learning testing\n",
    "def Test(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "    \n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e623e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86ca29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(48,1)))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/DNNMeta_CNN_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bf045",
   "metadata": {},
   "source": [
    "# Test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_dnn_train.csv'\n",
    "path_test = 'cle_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_dnn_train.csv'\n",
    "path_test = 'vir_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_dnn_train.csv'\n",
    "path_test = 'hun_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_dnn_train.csv'\n",
    "path_test = 'swi_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ee9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779d148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = \n",
    "X_test = \n",
    "Y_train_binary = \n",
    "Y_test_binary = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0813f",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fddd185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 1s 3ms/step - loss: 0.6998 - accuracy: 0.5055\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.4927\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7015 - accuracy: 0.4927\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5018\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5255\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5292\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5547\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.5584\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5401\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5091\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5255\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5931\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5785\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5766\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6442\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.5985\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.5985\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6186\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.6168\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5511\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6405\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6241\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6642\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6058\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6259\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6679\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6533\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6734\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6752\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6788\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6715\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6405\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6825\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7062\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6186\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5401\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6442\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6679\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6916\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 48), found shape=(None, 64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train_binary, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,callbacks\u001b[38;5;241m=\u001b[39m[callback])\n\u001b[1;32m---> 13\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(Y_pred, Y_test_binary)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filex5gwwhzy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\wangt\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 48), found shape=(None, 64)\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(48,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_DNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a844",
   "metadata": {},
   "source": [
    "# test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12522ce3",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "880e0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e78c2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 4s 31ms/step - loss: 0.6837 - accuracy: 0.5511\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6725 - accuracy: 0.5566\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.6516 - accuracy: 0.6004\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.6282 - accuracy: 0.6697\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.7023 - accuracy: 0.5347\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6890 - accuracy: 0.5328\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6684 - accuracy: 0.5949\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.6395 - accuracy: 0.6606\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5876 - accuracy: 0.7153\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5735 - accuracy: 0.6971\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5532 - accuracy: 0.6934\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5332 - accuracy: 0.7427\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.5512 - accuracy: 0.7226\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.4935 - accuracy: 0.7719\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.4789 - accuracy: 0.7792\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5473 - accuracy: 0.7591\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.5308 - accuracy: 0.7591\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.5130 - accuracy: 0.7664\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5140 - accuracy: 0.7573\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5298 - accuracy: 0.7409\n",
      "[[ 98 224]\n",
      " [ 30 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3043    0.7656    0.4356       128\n",
      "           1     0.7727    0.3129    0.4454       326\n",
      "\n",
      "    accuracy                         0.4405       454\n",
      "   macro avg     0.5385    0.5393    0.4405       454\n",
      "weighted avg     0.6407    0.4405    0.4426       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(48, 1)))\n",
    "model.add(SimpleRNN(units=32, return_sequences=True))\n",
    "model.add(SimpleRNN(units=16))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedaab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_RNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fae7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812110c",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bde29",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61dc493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2175bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is:\n",
      "[[ 82  43]\n",
      " [ 46 283]]\n",
      "Accuracy is : 0.8039647577092511\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65       128\n",
      "           1       0.86      0.87      0.86       326\n",
      "\n",
      "    accuracy                           0.80       454\n",
      "   macro avg       0.76      0.75      0.76       454\n",
      "weighted avg       0.80      0.80      0.80       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_train, Y_train_binary)\n",
    "Y_predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(Y_predictions, Y_test_binary)\n",
    "print(\"Confusion Matrix is:\")\n",
    "print(cm)\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "print(\"Accuracy is : \" + str(accuracy(cm)))\n",
    "    \n",
    "print(\"Report\")\n",
    "print(classification_report(Y_test_binary, Y_predictions))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d529c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save clf model\n",
    "from joblib import dump, load\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_dt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08cf24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Decision tree, and random forest testing\n",
    "def Test_DT(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = load(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for decision tree\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f058a8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dee5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e9459fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103 185]\n",
      " [ 25 141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3576    0.8047    0.4952       128\n",
      "           1     0.8494    0.4325    0.5732       326\n",
      "\n",
      "    accuracy                         0.5374       454\n",
      "   macro avg     0.6035    0.6186    0.5342       454\n",
      "weighted avg     0.7108    0.5374    0.5512       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(classifier, '../Models/Meta_only/CNNMeta_rf_9005.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49633d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for Random Forest\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511e046",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb18996",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train_binary.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(Y_test_binary, y_pred))\n",
    "print(classification_report(Y_test_binary, y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svc, \"../Models/Meta_only/CNNMeta_svm_8978.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for SVM\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26593df9",
   "metadata": {},
   "source": [
    "# Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits = 4))\n",
    "\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_NB_dropswi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2670c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
