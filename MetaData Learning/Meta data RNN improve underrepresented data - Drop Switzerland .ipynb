{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1ee0e",
   "metadata": {},
   "source": [
    "# CNN metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3360ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_train=pd.read_csv('cle_metadata_rnn_train.csv')\n",
    "cle_test=pd.read_csv('cle_metadata_rnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b8fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train=pd.read_csv('vir_metadata_rnn_train.csv' )\n",
    "vir_test=pd.read_csv('vir_metadata_rnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92518ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train=pd.read_csv('hun_metadata_rnn_train.csv' )\n",
    "hun_test=pd.read_csv('hun_metadata_rnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe3741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_train=pd.read_csv('swi_metadata_rnn_train.csv' )\n",
    "swi_test=pd.read_csv('swi_metadata_rnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([cle_train,vir_train,hun_train])\n",
    "Test = pd.concat([cle_test,vir_test,hun_test,swi_test,swi_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.iloc[:,:-1]\n",
    "X_test = Test.iloc[:,:-1]\n",
    "\n",
    "y_train = Train.iloc[:,-1]\n",
    "y_test = Test.iloc[:,-1]\n",
    "\n",
    "Y_train_binary = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43269e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.340760</td>\n",
       "      <td>0.487900</td>\n",
       "      <td>0.612871</td>\n",
       "      <td>0.436759</td>\n",
       "      <td>0.526660</td>\n",
       "      <td>0.479218</td>\n",
       "      <td>0.720962</td>\n",
       "      <td>0.436540</td>\n",
       "      <td>0.407657</td>\n",
       "      <td>0.592391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374927</td>\n",
       "      <td>0.368879</td>\n",
       "      <td>0.585520</td>\n",
       "      <td>0.548301</td>\n",
       "      <td>0.521280</td>\n",
       "      <td>0.389572</td>\n",
       "      <td>0.324228</td>\n",
       "      <td>0.230953</td>\n",
       "      <td>0.491484</td>\n",
       "      <td>0.281527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.297737</td>\n",
       "      <td>0.609399</td>\n",
       "      <td>0.685022</td>\n",
       "      <td>0.390012</td>\n",
       "      <td>0.413881</td>\n",
       "      <td>0.412132</td>\n",
       "      <td>0.613540</td>\n",
       "      <td>0.267853</td>\n",
       "      <td>0.557113</td>\n",
       "      <td>0.737520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437792</td>\n",
       "      <td>0.361421</td>\n",
       "      <td>0.498104</td>\n",
       "      <td>0.511952</td>\n",
       "      <td>0.553327</td>\n",
       "      <td>0.441596</td>\n",
       "      <td>0.387916</td>\n",
       "      <td>0.273499</td>\n",
       "      <td>0.425464</td>\n",
       "      <td>0.271027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.253104</td>\n",
       "      <td>0.615953</td>\n",
       "      <td>0.671807</td>\n",
       "      <td>0.511258</td>\n",
       "      <td>0.520002</td>\n",
       "      <td>0.410881</td>\n",
       "      <td>0.645860</td>\n",
       "      <td>0.305135</td>\n",
       "      <td>0.581857</td>\n",
       "      <td>0.713344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412748</td>\n",
       "      <td>0.412591</td>\n",
       "      <td>0.446045</td>\n",
       "      <td>0.513884</td>\n",
       "      <td>0.555546</td>\n",
       "      <td>0.442008</td>\n",
       "      <td>0.467973</td>\n",
       "      <td>0.307008</td>\n",
       "      <td>0.493194</td>\n",
       "      <td>0.259648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328991</td>\n",
       "      <td>0.574650</td>\n",
       "      <td>0.604049</td>\n",
       "      <td>0.358715</td>\n",
       "      <td>0.608555</td>\n",
       "      <td>0.461843</td>\n",
       "      <td>0.672255</td>\n",
       "      <td>0.444438</td>\n",
       "      <td>0.533643</td>\n",
       "      <td>0.654812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345829</td>\n",
       "      <td>0.315530</td>\n",
       "      <td>0.613956</td>\n",
       "      <td>0.540895</td>\n",
       "      <td>0.522999</td>\n",
       "      <td>0.414430</td>\n",
       "      <td>0.274560</td>\n",
       "      <td>0.239929</td>\n",
       "      <td>0.433457</td>\n",
       "      <td>0.305221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.385332</td>\n",
       "      <td>0.618744</td>\n",
       "      <td>0.452088</td>\n",
       "      <td>0.463268</td>\n",
       "      <td>0.672097</td>\n",
       "      <td>0.432593</td>\n",
       "      <td>0.549330</td>\n",
       "      <td>0.464415</td>\n",
       "      <td>0.654181</td>\n",
       "      <td>0.591616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411836</td>\n",
       "      <td>0.370949</td>\n",
       "      <td>0.400231</td>\n",
       "      <td>0.538693</td>\n",
       "      <td>0.491434</td>\n",
       "      <td>0.503750</td>\n",
       "      <td>0.302947</td>\n",
       "      <td>0.249541</td>\n",
       "      <td>0.433775</td>\n",
       "      <td>0.294660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.339409</td>\n",
       "      <td>0.558035</td>\n",
       "      <td>0.257953</td>\n",
       "      <td>0.318239</td>\n",
       "      <td>0.379783</td>\n",
       "      <td>0.598093</td>\n",
       "      <td>0.619935</td>\n",
       "      <td>0.308391</td>\n",
       "      <td>0.388721</td>\n",
       "      <td>0.557802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451080</td>\n",
       "      <td>0.463271</td>\n",
       "      <td>0.427888</td>\n",
       "      <td>0.398204</td>\n",
       "      <td>0.578371</td>\n",
       "      <td>0.419423</td>\n",
       "      <td>0.489791</td>\n",
       "      <td>0.561335</td>\n",
       "      <td>0.307842</td>\n",
       "      <td>0.479495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.420442</td>\n",
       "      <td>0.481506</td>\n",
       "      <td>0.177521</td>\n",
       "      <td>0.492286</td>\n",
       "      <td>0.377492</td>\n",
       "      <td>0.679658</td>\n",
       "      <td>0.416711</td>\n",
       "      <td>0.237822</td>\n",
       "      <td>0.333888</td>\n",
       "      <td>0.483541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401163</td>\n",
       "      <td>0.467945</td>\n",
       "      <td>0.446788</td>\n",
       "      <td>0.380411</td>\n",
       "      <td>0.584302</td>\n",
       "      <td>0.456640</td>\n",
       "      <td>0.449737</td>\n",
       "      <td>0.596066</td>\n",
       "      <td>0.226348</td>\n",
       "      <td>0.611213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.513070</td>\n",
       "      <td>0.497011</td>\n",
       "      <td>0.324947</td>\n",
       "      <td>0.677927</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.674969</td>\n",
       "      <td>0.250162</td>\n",
       "      <td>0.398171</td>\n",
       "      <td>0.487661</td>\n",
       "      <td>0.557615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575916</td>\n",
       "      <td>0.523433</td>\n",
       "      <td>0.485088</td>\n",
       "      <td>0.544598</td>\n",
       "      <td>0.463815</td>\n",
       "      <td>0.562527</td>\n",
       "      <td>0.391307</td>\n",
       "      <td>0.551289</td>\n",
       "      <td>0.209695</td>\n",
       "      <td>0.337740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.560600</td>\n",
       "      <td>0.523055</td>\n",
       "      <td>0.483911</td>\n",
       "      <td>0.692399</td>\n",
       "      <td>0.362762</td>\n",
       "      <td>0.507424</td>\n",
       "      <td>0.333098</td>\n",
       "      <td>0.380661</td>\n",
       "      <td>0.311507</td>\n",
       "      <td>0.616838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538191</td>\n",
       "      <td>0.544019</td>\n",
       "      <td>0.497151</td>\n",
       "      <td>0.648589</td>\n",
       "      <td>0.422161</td>\n",
       "      <td>0.584743</td>\n",
       "      <td>0.459314</td>\n",
       "      <td>0.503090</td>\n",
       "      <td>0.232661</td>\n",
       "      <td>0.264214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.566970</td>\n",
       "      <td>0.502197</td>\n",
       "      <td>0.420686</td>\n",
       "      <td>0.619997</td>\n",
       "      <td>0.381977</td>\n",
       "      <td>0.508727</td>\n",
       "      <td>0.326801</td>\n",
       "      <td>0.363952</td>\n",
       "      <td>0.429766</td>\n",
       "      <td>0.561933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689632</td>\n",
       "      <td>0.547575</td>\n",
       "      <td>0.481885</td>\n",
       "      <td>0.632070</td>\n",
       "      <td>0.263566</td>\n",
       "      <td>0.569576</td>\n",
       "      <td>0.383654</td>\n",
       "      <td>0.539597</td>\n",
       "      <td>0.278412</td>\n",
       "      <td>0.217632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.340760  0.487900  0.612871  0.436759  0.526660  0.479218  0.720962   \n",
       "1    0.297737  0.609399  0.685022  0.390012  0.413881  0.412132  0.613540   \n",
       "2    0.253104  0.615953  0.671807  0.511258  0.520002  0.410881  0.645860   \n",
       "3    0.328991  0.574650  0.604049  0.358715  0.608555  0.461843  0.672255   \n",
       "4    0.385332  0.618744  0.452088  0.463268  0.672097  0.432593  0.549330   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.339409  0.558035  0.257953  0.318239  0.379783  0.598093  0.619935   \n",
       "196  0.420442  0.481506  0.177521  0.492286  0.377492  0.679658  0.416711   \n",
       "197  0.513070  0.497011  0.324947  0.677927  0.474300  0.674969  0.250162   \n",
       "198  0.560600  0.523055  0.483911  0.692399  0.362762  0.507424  0.333098   \n",
       "199  0.566970  0.502197  0.420686  0.619997  0.381977  0.508727  0.326801   \n",
       "\n",
       "            7         8         9  ...       6.2       7.2       8.2  \\\n",
       "0    0.436540  0.407657  0.592391  ...  0.374927  0.368879  0.585520   \n",
       "1    0.267853  0.557113  0.737520  ...  0.437792  0.361421  0.498104   \n",
       "2    0.305135  0.581857  0.713344  ...  0.412748  0.412591  0.446045   \n",
       "3    0.444438  0.533643  0.654812  ...  0.345829  0.315530  0.613956   \n",
       "4    0.464415  0.654181  0.591616  ...  0.411836  0.370949  0.400231   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "195  0.308391  0.388721  0.557802  ...  0.451080  0.463271  0.427888   \n",
       "196  0.237822  0.333888  0.483541  ...  0.401163  0.467945  0.446788   \n",
       "197  0.398171  0.487661  0.557615  ...  0.575916  0.523433  0.485088   \n",
       "198  0.380661  0.311507  0.616838  ...  0.538191  0.544019  0.497151   \n",
       "199  0.363952  0.429766  0.561933  ...  0.689632  0.547575  0.481885   \n",
       "\n",
       "          9.2      10.2      11.2      12.2      13.2      14.2      15.2  \n",
       "0    0.548301  0.521280  0.389572  0.324228  0.230953  0.491484  0.281527  \n",
       "1    0.511952  0.553327  0.441596  0.387916  0.273499  0.425464  0.271027  \n",
       "2    0.513884  0.555546  0.442008  0.467973  0.307008  0.493194  0.259648  \n",
       "3    0.540895  0.522999  0.414430  0.274560  0.239929  0.433457  0.305221  \n",
       "4    0.538693  0.491434  0.503750  0.302947  0.249541  0.433775  0.294660  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "195  0.398204  0.578371  0.419423  0.489791  0.561335  0.307842  0.479495  \n",
       "196  0.380411  0.584302  0.456640  0.449737  0.596066  0.226348  0.611213  \n",
       "197  0.544598  0.463815  0.562527  0.391307  0.551289  0.209695  0.337740  \n",
       "198  0.648589  0.422161  0.584743  0.459314  0.503090  0.232661  0.264214  \n",
       "199  0.632070  0.263566  0.569576  0.383654  0.539597  0.278412  0.217632  \n",
       "\n",
       "[548 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.iloc[:,:-16]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3d3c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.293729</td>\n",
       "      <td>0.627477</td>\n",
       "      <td>0.526115</td>\n",
       "      <td>0.438907</td>\n",
       "      <td>0.638679</td>\n",
       "      <td>0.428233</td>\n",
       "      <td>0.487701</td>\n",
       "      <td>0.418628</td>\n",
       "      <td>0.632747</td>\n",
       "      <td>0.546150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356309</td>\n",
       "      <td>0.409993</td>\n",
       "      <td>0.498881</td>\n",
       "      <td>0.522675</td>\n",
       "      <td>0.564499</td>\n",
       "      <td>0.483933</td>\n",
       "      <td>0.358412</td>\n",
       "      <td>0.277381</td>\n",
       "      <td>0.447570</td>\n",
       "      <td>0.304200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.320054</td>\n",
       "      <td>0.519304</td>\n",
       "      <td>0.611243</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>0.500610</td>\n",
       "      <td>0.447715</td>\n",
       "      <td>0.682454</td>\n",
       "      <td>0.379712</td>\n",
       "      <td>0.434606</td>\n",
       "      <td>0.661573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387747</td>\n",
       "      <td>0.370770</td>\n",
       "      <td>0.546051</td>\n",
       "      <td>0.589093</td>\n",
       "      <td>0.563025</td>\n",
       "      <td>0.416531</td>\n",
       "      <td>0.309537</td>\n",
       "      <td>0.244754</td>\n",
       "      <td>0.488107</td>\n",
       "      <td>0.302487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.186162</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>0.551800</td>\n",
       "      <td>0.481192</td>\n",
       "      <td>0.550654</td>\n",
       "      <td>0.343080</td>\n",
       "      <td>0.545997</td>\n",
       "      <td>0.292986</td>\n",
       "      <td>0.577275</td>\n",
       "      <td>0.719382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362506</td>\n",
       "      <td>0.472912</td>\n",
       "      <td>0.380852</td>\n",
       "      <td>0.423283</td>\n",
       "      <td>0.526330</td>\n",
       "      <td>0.433946</td>\n",
       "      <td>0.373257</td>\n",
       "      <td>0.310308</td>\n",
       "      <td>0.377175</td>\n",
       "      <td>0.327444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342631</td>\n",
       "      <td>0.540192</td>\n",
       "      <td>0.565230</td>\n",
       "      <td>0.378897</td>\n",
       "      <td>0.547730</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.738252</td>\n",
       "      <td>0.393265</td>\n",
       "      <td>0.475793</td>\n",
       "      <td>0.566919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337585</td>\n",
       "      <td>0.340781</td>\n",
       "      <td>0.601751</td>\n",
       "      <td>0.537776</td>\n",
       "      <td>0.490526</td>\n",
       "      <td>0.401568</td>\n",
       "      <td>0.325775</td>\n",
       "      <td>0.229961</td>\n",
       "      <td>0.531719</td>\n",
       "      <td>0.251820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.658236</td>\n",
       "      <td>0.485795</td>\n",
       "      <td>0.469096</td>\n",
       "      <td>0.494993</td>\n",
       "      <td>0.306525</td>\n",
       "      <td>0.447890</td>\n",
       "      <td>0.257140</td>\n",
       "      <td>0.544094</td>\n",
       "      <td>0.731443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410208</td>\n",
       "      <td>0.505617</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.493895</td>\n",
       "      <td>0.559228</td>\n",
       "      <td>0.576092</td>\n",
       "      <td>0.491070</td>\n",
       "      <td>0.387742</td>\n",
       "      <td>0.303094</td>\n",
       "      <td>0.404555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.811979</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>0.477257</td>\n",
       "      <td>0.721589</td>\n",
       "      <td>0.766146</td>\n",
       "      <td>0.594920</td>\n",
       "      <td>0.575080</td>\n",
       "      <td>0.485718</td>\n",
       "      <td>0.607156</td>\n",
       "      <td>0.486673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607945</td>\n",
       "      <td>0.282076</td>\n",
       "      <td>0.352502</td>\n",
       "      <td>0.306273</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>0.421206</td>\n",
       "      <td>0.445894</td>\n",
       "      <td>0.351136</td>\n",
       "      <td>0.698048</td>\n",
       "      <td>0.548143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.642327</td>\n",
       "      <td>0.631567</td>\n",
       "      <td>0.459703</td>\n",
       "      <td>0.564522</td>\n",
       "      <td>0.617820</td>\n",
       "      <td>0.553694</td>\n",
       "      <td>0.466363</td>\n",
       "      <td>0.545977</td>\n",
       "      <td>0.647660</td>\n",
       "      <td>0.529072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607786</td>\n",
       "      <td>0.330605</td>\n",
       "      <td>0.321269</td>\n",
       "      <td>0.224711</td>\n",
       "      <td>0.391932</td>\n",
       "      <td>0.318150</td>\n",
       "      <td>0.571609</td>\n",
       "      <td>0.298220</td>\n",
       "      <td>0.666262</td>\n",
       "      <td>0.645772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.788072</td>\n",
       "      <td>0.553832</td>\n",
       "      <td>0.477969</td>\n",
       "      <td>0.666801</td>\n",
       "      <td>0.759219</td>\n",
       "      <td>0.636976</td>\n",
       "      <td>0.515849</td>\n",
       "      <td>0.551768</td>\n",
       "      <td>0.662098</td>\n",
       "      <td>0.530938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629856</td>\n",
       "      <td>0.338659</td>\n",
       "      <td>0.298441</td>\n",
       "      <td>0.327477</td>\n",
       "      <td>0.207824</td>\n",
       "      <td>0.461076</td>\n",
       "      <td>0.476232</td>\n",
       "      <td>0.470051</td>\n",
       "      <td>0.728933</td>\n",
       "      <td>0.506881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.777790</td>\n",
       "      <td>0.527051</td>\n",
       "      <td>0.445324</td>\n",
       "      <td>0.664927</td>\n",
       "      <td>0.776204</td>\n",
       "      <td>0.635988</td>\n",
       "      <td>0.572343</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.574139</td>\n",
       "      <td>0.506169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542415</td>\n",
       "      <td>0.319269</td>\n",
       "      <td>0.271290</td>\n",
       "      <td>0.300264</td>\n",
       "      <td>0.314978</td>\n",
       "      <td>0.487840</td>\n",
       "      <td>0.478168</td>\n",
       "      <td>0.385513</td>\n",
       "      <td>0.620938</td>\n",
       "      <td>0.578300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.745860</td>\n",
       "      <td>0.631236</td>\n",
       "      <td>0.514625</td>\n",
       "      <td>0.734407</td>\n",
       "      <td>0.697883</td>\n",
       "      <td>0.571744</td>\n",
       "      <td>0.525459</td>\n",
       "      <td>0.499531</td>\n",
       "      <td>0.664431</td>\n",
       "      <td>0.485709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639217</td>\n",
       "      <td>0.300555</td>\n",
       "      <td>0.299842</td>\n",
       "      <td>0.282024</td>\n",
       "      <td>0.230102</td>\n",
       "      <td>0.403596</td>\n",
       "      <td>0.475483</td>\n",
       "      <td>0.442517</td>\n",
       "      <td>0.704997</td>\n",
       "      <td>0.554428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.293729  0.627477  0.526115  0.438907  0.638679  0.428233  0.487701   \n",
       "1   0.320054  0.519304  0.611243  0.427906  0.500610  0.447715  0.682454   \n",
       "2   0.186162  0.670216  0.551800  0.481192  0.550654  0.343080  0.545997   \n",
       "3   0.342631  0.540192  0.565230  0.378897  0.547730  0.470122  0.738252   \n",
       "4   0.225800  0.658236  0.485795  0.469096  0.494993  0.306525  0.447890   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.811979  0.528964  0.477257  0.721589  0.766146  0.594920  0.575080   \n",
       "78  0.642327  0.631567  0.459703  0.564522  0.617820  0.553694  0.466363   \n",
       "79  0.788072  0.553832  0.477969  0.666801  0.759219  0.636976  0.515849   \n",
       "80  0.777790  0.527051  0.445324  0.664927  0.776204  0.635988  0.572343   \n",
       "81  0.745860  0.631236  0.514625  0.734407  0.697883  0.571744  0.525459   \n",
       "\n",
       "           7         8         9  ...       6.2       7.2       8.2       9.2  \\\n",
       "0   0.418628  0.632747  0.546150  ...  0.356309  0.409993  0.498881  0.522675   \n",
       "1   0.379712  0.434606  0.661573  ...  0.387747  0.370770  0.546051  0.589093   \n",
       "2   0.292986  0.577275  0.719382  ...  0.362506  0.472912  0.380852  0.423283   \n",
       "3   0.393265  0.475793  0.566919  ...  0.337585  0.340781  0.601751  0.537776   \n",
       "4   0.257140  0.544094  0.731443  ...  0.410208  0.505617  0.353265  0.493895   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "77  0.485718  0.607156  0.486673  ...  0.607945  0.282076  0.352502  0.306273   \n",
       "78  0.545977  0.647660  0.529072  ...  0.607786  0.330605  0.321269  0.224711   \n",
       "79  0.551768  0.662098  0.530938  ...  0.629856  0.338659  0.298441  0.327477   \n",
       "80  0.569432  0.574139  0.506169  ...  0.542415  0.319269  0.271290  0.300264   \n",
       "81  0.499531  0.664431  0.485709  ...  0.639217  0.300555  0.299842  0.282024   \n",
       "\n",
       "        10.2      11.2      12.2      13.2      14.2      15.2  \n",
       "0   0.564499  0.483933  0.358412  0.277381  0.447570  0.304200  \n",
       "1   0.563025  0.416531  0.309537  0.244754  0.488107  0.302487  \n",
       "2   0.526330  0.433946  0.373257  0.310308  0.377175  0.327444  \n",
       "3   0.490526  0.401568  0.325775  0.229961  0.531719  0.251820  \n",
       "4   0.559228  0.576092  0.491070  0.387742  0.303094  0.404555  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "77  0.248539  0.421206  0.445894  0.351136  0.698048  0.548143  \n",
       "78  0.391932  0.318150  0.571609  0.298220  0.666262  0.645772  \n",
       "79  0.207824  0.461076  0.476232  0.470051  0.728933  0.506881  \n",
       "80  0.314978  0.487840  0.478168  0.385513  0.620938  0.578300  \n",
       "81  0.230102  0.403596  0.475483  0.442517  0.704997  0.554428  \n",
       "\n",
       "[372 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.iloc[:,:-16]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3016ecb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cle_train_temp = cle_train.iloc[:,:-17]\n",
    "cle_train_Y = cle_train.iloc[:,-1]\n",
    "cle_train = pd.concat([cle_train_temp, cle_train_Y], axis=1)\n",
    "cle_train.to_csv('cle_metadata_rnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b0fd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train_temp = vir_train.iloc[:,:-17]\n",
    "vir_train_Y = vir_train.iloc[:,-1]\n",
    "vir_train = pd.concat([vir_train_temp, vir_train_Y], axis=1)\n",
    "vir_train.to_csv('vir_metadata_rnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad66556",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train_temp = hun_train.iloc[:,:-17]\n",
    "hun_train_Y = hun_train.iloc[:,-1]\n",
    "hun_train = pd.concat([hun_train_temp, hun_train_Y], axis=1)\n",
    "hun_train.to_csv('hun_metadata_rnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e852ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_test_temp = cle_test.iloc[:,:-17]\n",
    "cle_test_Y = cle_test.iloc[:,-1]\n",
    "cle_test = pd.concat([cle_test_temp, cle_test_Y], axis=1)\n",
    "cle_test.to_csv('cle_metadata_rnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9041c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_test_temp = vir_test.iloc[:,:-17]\n",
    "vir_test_Y = vir_test.iloc[:,-1]\n",
    "vir_test = pd.concat([vir_test_temp, vir_test_Y], axis=1)\n",
    "vir_test.to_csv('vir_metadata_rnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4764f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_test_temp = hun_test.iloc[:,:-17]\n",
    "hun_test_Y = hun_test.iloc[:,-1]\n",
    "hun_test = pd.concat([hun_test_temp, hun_test_Y], axis=1)\n",
    "hun_test.to_csv('hun_metadata_rnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4349043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.3</th>\n",
       "      <th>8.3</th>\n",
       "      <th>9.3</th>\n",
       "      <th>10.3</th>\n",
       "      <th>11.3</th>\n",
       "      <th>12.3</th>\n",
       "      <th>13.3</th>\n",
       "      <th>14.3</th>\n",
       "      <th>15.3</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.843553</td>\n",
       "      <td>0.625444</td>\n",
       "      <td>0.555617</td>\n",
       "      <td>0.760166</td>\n",
       "      <td>0.765526</td>\n",
       "      <td>0.596982</td>\n",
       "      <td>0.530243</td>\n",
       "      <td>0.402120</td>\n",
       "      <td>0.651977</td>\n",
       "      <td>0.514481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335399</td>\n",
       "      <td>0.423963</td>\n",
       "      <td>0.414680</td>\n",
       "      <td>0.411113</td>\n",
       "      <td>0.356875</td>\n",
       "      <td>0.589239</td>\n",
       "      <td>0.453639</td>\n",
       "      <td>0.364173</td>\n",
       "      <td>0.671544</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.859244</td>\n",
       "      <td>0.567619</td>\n",
       "      <td>0.547963</td>\n",
       "      <td>0.713528</td>\n",
       "      <td>0.747644</td>\n",
       "      <td>0.608982</td>\n",
       "      <td>0.519941</td>\n",
       "      <td>0.431107</td>\n",
       "      <td>0.577883</td>\n",
       "      <td>0.488516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348661</td>\n",
       "      <td>0.562291</td>\n",
       "      <td>0.436564</td>\n",
       "      <td>0.310992</td>\n",
       "      <td>0.336308</td>\n",
       "      <td>0.473487</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>0.331380</td>\n",
       "      <td>0.644962</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.780039</td>\n",
       "      <td>0.697458</td>\n",
       "      <td>0.389511</td>\n",
       "      <td>0.597518</td>\n",
       "      <td>0.771891</td>\n",
       "      <td>0.571629</td>\n",
       "      <td>0.488341</td>\n",
       "      <td>0.486743</td>\n",
       "      <td>0.583345</td>\n",
       "      <td>0.527227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475333</td>\n",
       "      <td>0.490168</td>\n",
       "      <td>0.445705</td>\n",
       "      <td>0.661218</td>\n",
       "      <td>0.534539</td>\n",
       "      <td>0.667475</td>\n",
       "      <td>0.329092</td>\n",
       "      <td>0.603276</td>\n",
       "      <td>0.497078</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.713523</td>\n",
       "      <td>0.607888</td>\n",
       "      <td>0.483635</td>\n",
       "      <td>0.694529</td>\n",
       "      <td>0.806823</td>\n",
       "      <td>0.612920</td>\n",
       "      <td>0.660157</td>\n",
       "      <td>0.640414</td>\n",
       "      <td>0.640178</td>\n",
       "      <td>0.572145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475699</td>\n",
       "      <td>0.624069</td>\n",
       "      <td>0.442532</td>\n",
       "      <td>0.440203</td>\n",
       "      <td>0.509695</td>\n",
       "      <td>0.357667</td>\n",
       "      <td>0.390793</td>\n",
       "      <td>0.520910</td>\n",
       "      <td>0.665331</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.850672</td>\n",
       "      <td>0.522852</td>\n",
       "      <td>0.504845</td>\n",
       "      <td>0.707535</td>\n",
       "      <td>0.770107</td>\n",
       "      <td>0.603788</td>\n",
       "      <td>0.553652</td>\n",
       "      <td>0.456883</td>\n",
       "      <td>0.595856</td>\n",
       "      <td>0.495372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496580</td>\n",
       "      <td>0.552390</td>\n",
       "      <td>0.502629</td>\n",
       "      <td>0.433395</td>\n",
       "      <td>0.426027</td>\n",
       "      <td>0.632972</td>\n",
       "      <td>0.384774</td>\n",
       "      <td>0.414650</td>\n",
       "      <td>0.560253</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.744582</td>\n",
       "      <td>0.536951</td>\n",
       "      <td>0.559382</td>\n",
       "      <td>0.815555</td>\n",
       "      <td>0.734042</td>\n",
       "      <td>0.535882</td>\n",
       "      <td>0.612130</td>\n",
       "      <td>0.526636</td>\n",
       "      <td>0.729768</td>\n",
       "      <td>0.497337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513009</td>\n",
       "      <td>0.608218</td>\n",
       "      <td>0.707544</td>\n",
       "      <td>0.544682</td>\n",
       "      <td>0.521964</td>\n",
       "      <td>0.579941</td>\n",
       "      <td>0.385669</td>\n",
       "      <td>0.648660</td>\n",
       "      <td>0.460335</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.832064</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.526122</td>\n",
       "      <td>0.714009</td>\n",
       "      <td>0.752858</td>\n",
       "      <td>0.577719</td>\n",
       "      <td>0.559788</td>\n",
       "      <td>0.471312</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0.481386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501527</td>\n",
       "      <td>0.496052</td>\n",
       "      <td>0.501094</td>\n",
       "      <td>0.480891</td>\n",
       "      <td>0.444719</td>\n",
       "      <td>0.616671</td>\n",
       "      <td>0.458290</td>\n",
       "      <td>0.388410</td>\n",
       "      <td>0.583274</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.786386</td>\n",
       "      <td>0.570039</td>\n",
       "      <td>0.496775</td>\n",
       "      <td>0.754366</td>\n",
       "      <td>0.731581</td>\n",
       "      <td>0.588903</td>\n",
       "      <td>0.531405</td>\n",
       "      <td>0.472208</td>\n",
       "      <td>0.693943</td>\n",
       "      <td>0.478677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436863</td>\n",
       "      <td>0.540070</td>\n",
       "      <td>0.413623</td>\n",
       "      <td>0.435573</td>\n",
       "      <td>0.381316</td>\n",
       "      <td>0.574634</td>\n",
       "      <td>0.493015</td>\n",
       "      <td>0.369902</td>\n",
       "      <td>0.502731</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.810553</td>\n",
       "      <td>0.613983</td>\n",
       "      <td>0.499748</td>\n",
       "      <td>0.645507</td>\n",
       "      <td>0.731505</td>\n",
       "      <td>0.617283</td>\n",
       "      <td>0.499459</td>\n",
       "      <td>0.488158</td>\n",
       "      <td>0.567542</td>\n",
       "      <td>0.502843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306206</td>\n",
       "      <td>0.476674</td>\n",
       "      <td>0.564807</td>\n",
       "      <td>0.367314</td>\n",
       "      <td>0.347459</td>\n",
       "      <td>0.593353</td>\n",
       "      <td>0.517851</td>\n",
       "      <td>0.250259</td>\n",
       "      <td>0.637445</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.628722</td>\n",
       "      <td>0.657938</td>\n",
       "      <td>0.356865</td>\n",
       "      <td>0.584840</td>\n",
       "      <td>0.725283</td>\n",
       "      <td>0.521924</td>\n",
       "      <td>0.559803</td>\n",
       "      <td>0.600596</td>\n",
       "      <td>0.615933</td>\n",
       "      <td>0.536472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351643</td>\n",
       "      <td>0.654072</td>\n",
       "      <td>0.557189</td>\n",
       "      <td>0.447027</td>\n",
       "      <td>0.362921</td>\n",
       "      <td>0.506199</td>\n",
       "      <td>0.504778</td>\n",
       "      <td>0.406993</td>\n",
       "      <td>0.576834</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.843553  0.625444  0.555617  0.760166  0.765526  0.596982  0.530243   \n",
       "1   0.859244  0.567619  0.547963  0.713528  0.747644  0.608982  0.519941   \n",
       "2   0.780039  0.697458  0.389511  0.597518  0.771891  0.571629  0.488341   \n",
       "3   0.713523  0.607888  0.483635  0.694529  0.806823  0.612920  0.660157   \n",
       "4   0.850672  0.522852  0.504845  0.707535  0.770107  0.603788  0.553652   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "36  0.744582  0.536951  0.559382  0.815555  0.734042  0.535882  0.612130   \n",
       "37  0.832064  0.514286  0.526122  0.714009  0.752858  0.577719  0.559788   \n",
       "38  0.786386  0.570039  0.496775  0.754366  0.731581  0.588903  0.531405   \n",
       "39  0.810553  0.613983  0.499748  0.645507  0.731505  0.617283  0.499459   \n",
       "40  0.628722  0.657938  0.356865  0.584840  0.725283  0.521924  0.559803   \n",
       "\n",
       "           7         8         9  ...       7.3       8.3       9.3      10.3  \\\n",
       "0   0.402120  0.651977  0.514481  ...  0.335399  0.423963  0.414680  0.411113   \n",
       "1   0.431107  0.577883  0.488516  ...  0.348661  0.562291  0.436564  0.310992   \n",
       "2   0.486743  0.583345  0.527227  ...  0.475333  0.490168  0.445705  0.661218   \n",
       "3   0.640414  0.640178  0.572145  ...  0.475699  0.624069  0.442532  0.440203   \n",
       "4   0.456883  0.595856  0.495372  ...  0.496580  0.552390  0.502629  0.433395   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "36  0.526636  0.729768  0.497337  ...  0.513009  0.608218  0.707544  0.544682   \n",
       "37  0.471312  0.605351  0.481386  ...  0.501527  0.496052  0.501094  0.480891   \n",
       "38  0.472208  0.693943  0.478677  ...  0.436863  0.540070  0.413623  0.435573   \n",
       "39  0.488158  0.567542  0.502843  ...  0.306206  0.476674  0.564807  0.367314   \n",
       "40  0.600596  0.615933  0.536472  ...  0.351643  0.654072  0.557189  0.447027   \n",
       "\n",
       "        11.3      12.3      13.3      14.3      15.3   num  \n",
       "0   0.356875  0.589239  0.453639  0.364173  0.671544  0.75  \n",
       "1   0.336308  0.473487  0.448962  0.331380  0.644962  0.75  \n",
       "2   0.534539  0.667475  0.329092  0.603276  0.497078  0.50  \n",
       "3   0.509695  0.357667  0.390793  0.520910  0.665331  0.25  \n",
       "4   0.426027  0.632972  0.384774  0.414650  0.560253  0.25  \n",
       "..       ...       ...       ...       ...       ...   ...  \n",
       "36  0.521964  0.579941  0.385669  0.648660  0.460335  0.25  \n",
       "37  0.444719  0.616671  0.458290  0.388410  0.583274  0.25  \n",
       "38  0.381316  0.574634  0.493015  0.369902  0.502731  0.75  \n",
       "39  0.347459  0.593353  0.517851  0.250259  0.637445  0.25  \n",
       "40  0.362921  0.506199  0.504778  0.406993  0.576834  0.75  \n",
       "\n",
       "[123 rows x 65 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swi_test_new = pd.concat([swi_train, swi_test])\n",
    "swi_test_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd79e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_test_temp = swi_test_new.iloc[:,:-17]\n",
    "swi_test_Y = swi_test_new.iloc[:,-1]\n",
    "swi_test = pd.concat([swi_test_temp, swi_test_Y], axis=1)\n",
    "swi_test.to_csv('swi_metadata_rnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55a9da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for deep learning testing\n",
    "def Test(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "    \n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e623e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c86ca29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 2s 59ms/step - loss: 0.6965 - accuracy: 0.5146\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.6585 - accuracy: 0.6131\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.5267 - accuracy: 0.7372\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.4973 - accuracy: 0.7737\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.4708 - accuracy: 0.7974\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.4379 - accuracy: 0.7993\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.4211 - accuracy: 0.8029\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.4233 - accuracy: 0.8175\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.4310 - accuracy: 0.8047\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.3882 - accuracy: 0.8431\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.3947 - accuracy: 0.8285\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.3751 - accuracy: 0.8266\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.3851 - accuracy: 0.8376\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3732 - accuracy: 0.8431\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 1s 64ms/step - loss: 0.3615 - accuracy: 0.8485\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.3357 - accuracy: 0.8504\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.3604 - accuracy: 0.8431\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3442 - accuracy: 0.8595\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.3400 - accuracy: 0.8595\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3381 - accuracy: 0.8558\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3271 - accuracy: 0.8558\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.2946 - accuracy: 0.8741\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.2886 - accuracy: 0.8832\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3197 - accuracy: 0.8759\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 1s 63ms/step - loss: 0.2817 - accuracy: 0.8850\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.2663 - accuracy: 0.8923\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.3381 - accuracy: 0.8467\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 1s 66ms/step - loss: 0.3166 - accuracy: 0.8650\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 1s 68ms/step - loss: 0.3111 - accuracy: 0.8741\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 1s 66ms/step - loss: 0.2576 - accuracy: 0.8978\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.3129 - accuracy: 0.8723\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 1s 63ms/step - loss: 0.2389 - accuracy: 0.9051\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 1s 69ms/step - loss: 0.2566 - accuracy: 0.8942\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.2227 - accuracy: 0.9142\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 1s 64ms/step - loss: 0.1956 - accuracy: 0.9252\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 1s 64ms/step - loss: 0.2559 - accuracy: 0.9124\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 1s 69ms/step - loss: 0.2146 - accuracy: 0.9252\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.2166 - accuracy: 0.9051\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2465 - accuracy: 0.9106\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1821 - accuracy: 0.9325\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1781 - accuracy: 0.9307\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.2274 - accuracy: 0.9033\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.2139 - accuracy: 0.9252\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.2338 - accuracy: 0.9033\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1762 - accuracy: 0.9361\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1828 - accuracy: 0.9197\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.1927 - accuracy: 0.9106\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.1499 - accuracy: 0.9580\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1257 - accuracy: 0.9580\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.1234 - accuracy: 0.9562\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 1s 65ms/step - loss: 0.1039 - accuracy: 0.9672\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.0877 - accuracy: 0.9726\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 1s 60ms/step - loss: 0.1134 - accuracy: 0.9580\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 1s 58ms/step - loss: 0.1005 - accuracy: 0.9672\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.0987 - accuracy: 0.9617\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1595 - accuracy: 0.9398\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 1s 57ms/step - loss: 0.1218 - accuracy: 0.9544\n",
      "[[104 138]\n",
      " [ 19 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4298    0.8455    0.5699       123\n",
      "           1     0.8538    0.4458    0.5858       249\n",
      "\n",
      "    accuracy                         0.5780       372\n",
      "   macro avg     0.6418    0.6457    0.5778       372\n",
      "weighted avg     0.7136    0.5780    0.5805       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(48,1)))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f15bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/RNNMeta_CNN_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bf045",
   "metadata": {},
   "source": [
    "# Test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bfc8384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "3/3 [==============================] - 0s 12ms/step\n",
      "[[37  4]\n",
      " [ 9 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9024    0.8043    0.8506        46\n",
      "           1     0.8269    0.9149    0.8687        47\n",
      "\n",
      "    accuracy                         0.8602        93\n",
      "   macro avg     0.8647    0.8596    0.8596        93\n",
      "weighted avg     0.8643    0.8602    0.8597        93\n",
      "\n",
      "[18, 25, 44, 47, 49, 50, 58, 59, 62, 69, 72, 79, 89]\n",
      "==================\n",
      "vir test\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "[[ 5  2]\n",
      " [ 6 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.4545    0.5556        11\n",
      "           1     0.8909    0.9608    0.9245        51\n",
      "\n",
      "    accuracy                         0.8710        62\n",
      "   macro avg     0.8026    0.7077    0.7400        62\n",
      "weighted avg     0.8596    0.8710    0.8591        62\n",
      "\n",
      "[6, 7, 17, 20, 23, 32, 53, 54]\n",
      "==================\n",
      "hun test\n",
      "3/3 [==============================] - 0s 13ms/step\n",
      "[[50  1]\n",
      " [ 8 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9804    0.8621    0.9174        58\n",
      "           1     0.8140    0.9722    0.8861        36\n",
      "\n",
      "    accuracy                         0.9043        94\n",
      "   macro avg     0.8972    0.9171    0.9018        94\n",
      "weighted avg     0.9166    0.9043    0.9054        94\n",
      "\n",
      "[7, 12, 34, 54, 60, 65, 66, 68, 69]\n",
      "==================\n",
      "swi test\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "[[  3   5]\n",
      " [  5 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3750    0.3750    0.3750         8\n",
      "           1     0.9565    0.9565    0.9565       115\n",
      "\n",
      "    accuracy                         0.9187       123\n",
      "   macro avg     0.6658    0.6658    0.6658       123\n",
      "weighted avg     0.9187    0.9187    0.9187       123\n",
      "\n",
      "[7, 8, 44, 77, 82, 92, 94, 97, 110, 118]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/RNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/RNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/RNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/RNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0813f",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fddd185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7847\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8394\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8431\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8467\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8431\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8449\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8358\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8449\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8358\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8467\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8467\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8540\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8449\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8449\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8504\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8412\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8540\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8540\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8394\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8449\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8449\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8522\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "[[102  14]\n",
      " [ 21 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8793    0.8293    0.8536       123\n",
      "           1     0.9180    0.9438    0.9307       249\n",
      "\n",
      "    accuracy                         0.9059       372\n",
      "   macro avg     0.8986    0.8865    0.8921       372\n",
      "weighted avg     0.9052    0.9059    0.9052       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(48,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e39f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_DNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a844",
   "metadata": {},
   "source": [
    "# test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53f9946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[[44  5]\n",
      " [ 2 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8980    0.9565    0.9263        46\n",
      "           1     0.9545    0.8936    0.9231        47\n",
      "\n",
      "    accuracy                         0.9247        93\n",
      "   macro avg     0.9263    0.9251    0.9247        93\n",
      "weighted avg     0.9266    0.9247    0.9247        93\n",
      "\n",
      "[17, 18, 58, 59, 69, 72, 89]\n",
      "==================\n",
      "vir test\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[[ 4  1]\n",
      " [ 7 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.3636    0.5000        11\n",
      "           1     0.8772    0.9804    0.9259        51\n",
      "\n",
      "    accuracy                         0.8710        62\n",
      "   macro avg     0.8386    0.6720    0.7130        62\n",
      "weighted avg     0.8635    0.8710    0.8504        62\n",
      "\n",
      "[6, 7, 17, 20, 23, 32, 49, 54]\n",
      "==================\n",
      "hun test\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "[[51  0]\n",
      " [ 7 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8793    0.9358        58\n",
      "           1     0.8372    1.0000    0.9114        36\n",
      "\n",
      "    accuracy                         0.9255        94\n",
      "   macro avg     0.9186    0.9397    0.9236        94\n",
      "weighted avg     0.9377    0.9255    0.9264        94\n",
      "\n",
      "[7, 12, 34, 54, 65, 68, 69]\n",
      "==================\n",
      "swi test\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "[[  3   8]\n",
      " [  5 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2727    0.3750    0.3158         8\n",
      "           1     0.9554    0.9304    0.9427       115\n",
      "\n",
      "    accuracy                         0.8943       123\n",
      "   macro avg     0.6140    0.6527    0.6293       123\n",
      "weighted avg     0.9110    0.8943    0.9020       123\n",
      "\n",
      "[7, 8, 33, 44, 52, 77, 82, 92, 94, 97, 106, 110, 118]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12522ce3",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "880e0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e78c2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 3s 18ms/step - loss: 0.5653 - accuracy: 0.7427\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4559 - accuracy: 0.7865\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4227 - accuracy: 0.8084\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4078 - accuracy: 0.8321\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4139 - accuracy: 0.8212\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4093 - accuracy: 0.8303\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4026 - accuracy: 0.8321\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4044 - accuracy: 0.8339\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4372 - accuracy: 0.8157\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4142 - accuracy: 0.8230\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3940 - accuracy: 0.8394\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3915 - accuracy: 0.8358\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4008 - accuracy: 0.8431\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3895 - accuracy: 0.8376\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3988 - accuracy: 0.8394\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4132 - accuracy: 0.8321\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.3977 - accuracy: 0.8339\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3839 - accuracy: 0.8467\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4016 - accuracy: 0.8394\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3833 - accuracy: 0.8394\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3797 - accuracy: 0.8540\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3739 - accuracy: 0.8485\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3890 - accuracy: 0.8248\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3828 - accuracy: 0.8358\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3808 - accuracy: 0.8558\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3809 - accuracy: 0.8449\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.3817 - accuracy: 0.8431\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "[[101  24]\n",
      " [ 22 225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8080    0.8211    0.8145       123\n",
      "           1     0.9109    0.9036    0.9073       249\n",
      "\n",
      "    accuracy                         0.8763       372\n",
      "   macro avg     0.8595    0.8624    0.8609       372\n",
      "weighted avg     0.8769    0.8763    0.8766       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(48, 1)))\n",
    "model.add(SimpleRNN(units=32, return_sequences=True))\n",
    "model.add(SimpleRNN(units=16))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fedaab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_RNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69fae7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "[[40  5]\n",
      " [ 6 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.8696    0.8791        46\n",
      "           1     0.8750    0.8936    0.8842        47\n",
      "\n",
      "    accuracy                         0.8817        93\n",
      "   macro avg     0.8819    0.8816    0.8817        93\n",
      "weighted avg     0.8819    0.8817    0.8817        93\n",
      "\n",
      "[0, 19, 25, 44, 49, 58, 59, 69, 72, 79, 89]\n",
      "==================\n",
      "vir test\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "[[ 7  3]\n",
      " [ 4 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7000    0.6364    0.6667        11\n",
      "           1     0.9231    0.9412    0.9320        51\n",
      "\n",
      "    accuracy                         0.8871        62\n",
      "   macro avg     0.8115    0.7888    0.7994        62\n",
      "weighted avg     0.8835    0.8871    0.8850        62\n",
      "\n",
      "[6, 7, 17, 20, 23, 25, 53]\n",
      "==================\n",
      "hun test\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "[[51  0]\n",
      " [ 7 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8793    0.9358        58\n",
      "           1     0.8372    1.0000    0.9114        36\n",
      "\n",
      "    accuracy                         0.9255        94\n",
      "   macro avg     0.9186    0.9397    0.9236        94\n",
      "weighted avg     0.9377    0.9255    0.9264        94\n",
      "\n",
      "[7, 12, 34, 54, 60, 69, 75]\n",
      "==================\n",
      "swi test\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "[[ 3 16]\n",
      " [ 5 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1579    0.3750    0.2222         8\n",
      "           1     0.9519    0.8609    0.9041       115\n",
      "\n",
      "    accuracy                         0.8293       123\n",
      "   macro avg     0.5549    0.6179    0.5632       123\n",
      "weighted avg     0.9003    0.8293    0.8598       123\n",
      "\n",
      "[7, 8, 14, 20, 28, 33, 36, 39, 44, 47, 55, 60, 64, 77, 79, 82, 92, 94, 97, 110, 118]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812110c",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bde29",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "61dc493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2175bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is:\n",
      "[[ 88  54]\n",
      " [ 35 195]]\n",
      "Accuracy is : 0.760752688172043\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.66       123\n",
      "           1       0.85      0.78      0.81       249\n",
      "\n",
      "    accuracy                           0.76       372\n",
      "   macro avg       0.73      0.75      0.74       372\n",
      "weighted avg       0.77      0.76      0.76       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_train, Y_train_binary)\n",
    "Y_predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(Y_predictions, Y_test_binary)\n",
    "print(\"Confusion Matrix is:\")\n",
    "print(cm)\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "print(\"Accuracy is : \" + str(accuracy(cm)))\n",
    "    \n",
    "print(\"Report\")\n",
    "print(classification_report(Y_test_binary, Y_predictions))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b7d529c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/Meta_only/CNNMeta_dt.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save clf model\n",
    "from joblib import dump, load\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_dt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08cf24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Decision tree, and random forest testing\n",
    "def Test_DT(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = load(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "475fef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "[[38 13]\n",
      " [ 8 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7451    0.8261    0.7835        46\n",
      "           1     0.8095    0.7234    0.7640        47\n",
      "\n",
      "    accuracy                         0.7742        93\n",
      "   macro avg     0.7773    0.7747    0.7738        93\n",
      "weighted avg     0.7777    0.7742    0.7737        93\n",
      "\n",
      "[4, 9, 15, 17, 19, 22, 25, 33, 34, 38, 41, 44, 47, 52, 59, 69, 70, 72, 76, 78, 89]\n",
      "==================\n",
      "vir test\n",
      "[[ 7  5]\n",
      " [ 4 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5833    0.6364    0.6087        11\n",
      "           1     0.9200    0.9020    0.9109        51\n",
      "\n",
      "    accuracy                         0.8548        62\n",
      "   macro avg     0.7517    0.7692    0.7598        62\n",
      "weighted avg     0.8603    0.8548    0.8573        62\n",
      "\n",
      "[4, 7, 17, 20, 31, 32, 53, 58, 60]\n",
      "==================\n",
      "hun test\n",
      "[[41  5]\n",
      " [17 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8913    0.7069    0.7885        58\n",
      "           1     0.6458    0.8611    0.7381        36\n",
      "\n",
      "    accuracy                         0.7660        94\n",
      "   macro avg     0.7686    0.7840    0.7633        94\n",
      "weighted avg     0.7973    0.7660    0.7692        94\n",
      "\n",
      "[6, 7, 12, 20, 21, 25, 29, 32, 34, 38, 53, 54, 57, 62, 68, 71, 75, 79, 81, 83, 90, 93]\n",
      "==================\n",
      "swi test\n",
      "[[ 2 31]\n",
      " [ 6 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0606    0.2500    0.0976         8\n",
      "           1     0.9333    0.7304    0.8195       115\n",
      "\n",
      "    accuracy                         0.6992       123\n",
      "   macro avg     0.4970    0.4902    0.4585       123\n",
      "weighted avg     0.8766    0.6992    0.7726       123\n",
      "\n",
      "[0, 7, 10, 13, 14, 21, 24, 30, 33, 34, 35, 36, 37, 38, 39, 44, 51, 52, 65, 67, 77, 78, 79, 82, 83, 89, 91, 93, 94, 97, 102, 104, 107, 110, 111, 112, 118]\n"
     ]
    }
   ],
   "source": [
    "#test on each dataset for decision tree\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f058a8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7dee5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e9459fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101  15]\n",
      " [ 22 234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8707    0.8211    0.8452       123\n",
      "           1     0.9141    0.9398    0.9267       249\n",
      "\n",
      "    accuracy                         0.9005       372\n",
      "   macro avg     0.8924    0.8804    0.8860       372\n",
      "weighted avg     0.8997    0.9005    0.8998       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c54a50ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/Meta_only/CNNMeta_rf_9005.joblib']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(classifier, '../Models/Meta_only/CNNMeta_rf_9005.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49633d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "[[42  6]\n",
      " [ 4 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8750    0.9130    0.8936        46\n",
      "           1     0.9111    0.8723    0.8913        47\n",
      "\n",
      "    accuracy                         0.8925        93\n",
      "   macro avg     0.8931    0.8927    0.8925        93\n",
      "weighted avg     0.8932    0.8925    0.8924        93\n",
      "\n",
      "[17, 18, 32, 49, 59, 69, 72, 76, 79, 89]\n",
      "==================\n",
      "vir test\n",
      "[[ 6  4]\n",
      " [ 5 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6000    0.5455    0.5714        11\n",
      "           1     0.9038    0.9216    0.9126        51\n",
      "\n",
      "    accuracy                         0.8548        62\n",
      "   macro avg     0.7519    0.7335    0.7420        62\n",
      "weighted avg     0.8499    0.8548    0.8521        62\n",
      "\n",
      "[4, 6, 7, 17, 20, 23, 32, 39, 53]\n",
      "==================\n",
      "hun test\n",
      "[[50  2]\n",
      " [ 8 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9615    0.8621    0.9091        58\n",
      "           1     0.8095    0.9444    0.8718        36\n",
      "\n",
      "    accuracy                         0.8936        94\n",
      "   macro avg     0.8855    0.9033    0.8904        94\n",
      "weighted avg     0.9033    0.8936    0.8948        94\n",
      "\n",
      "[7, 12, 16, 34, 53, 54, 60, 62, 68, 69]\n",
      "==================\n",
      "swi test\n",
      "[[  3   3]\n",
      " [  5 112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.3750    0.4286         8\n",
      "           1     0.9573    0.9739    0.9655       115\n",
      "\n",
      "    accuracy                         0.9350       123\n",
      "   macro avg     0.7286    0.6745    0.6970       123\n",
      "weighted avg     0.9275    0.9350    0.9306       123\n",
      "\n",
      "[7, 33, 44, 77, 82, 94, 97, 118]\n"
     ]
    }
   ],
   "source": [
    "#test on each dataset for Random Forest\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511e046",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5efc17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcb18996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100  23]\n",
      " [ 15 234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8696    0.8130    0.8403       123\n",
      "           1     0.9105    0.9398    0.9249       249\n",
      "\n",
      "    accuracy                         0.8978       372\n",
      "   macro avg     0.8900    0.8764    0.8826       372\n",
      "weighted avg     0.8970    0.8978    0.8969       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train_binary.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(Y_test_binary, y_pred))\n",
    "print(classification_report(Y_test_binary, y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d339f40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/Meta_only/CNNMeta_svm_8978.pkl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(svc, \"../Models/Meta_only/CNNMeta_svm_8978.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "295a07bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "[[41  4]\n",
      " [ 5 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9111    0.8913    0.9011        46\n",
      "           1     0.8958    0.9149    0.9053        47\n",
      "\n",
      "    accuracy                         0.9032        93\n",
      "   macro avg     0.9035    0.9031    0.9032        93\n",
      "weighted avg     0.9034    0.9032    0.9032        93\n",
      "\n",
      "[18, 25, 49, 58, 59, 69, 72, 79, 89]\n",
      "==================\n",
      "vir test\n",
      "[[ 5  2]\n",
      " [ 6 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.4545    0.5556        11\n",
      "           1     0.8909    0.9608    0.9245        51\n",
      "\n",
      "    accuracy                         0.8710        62\n",
      "   macro avg     0.8026    0.7077    0.7400        62\n",
      "weighted avg     0.8596    0.8710    0.8591        62\n",
      "\n",
      "[4, 6, 7, 17, 20, 23, 32, 54]\n",
      "==================\n",
      "hun test\n",
      "[[51  1]\n",
      " [ 7 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9808    0.8793    0.9273        58\n",
      "           1     0.8333    0.9722    0.8974        36\n",
      "\n",
      "    accuracy                         0.9149        94\n",
      "   macro avg     0.9071    0.9258    0.9124        94\n",
      "weighted avg     0.9243    0.9149    0.9158        94\n",
      "\n",
      "[7, 12, 34, 54, 60, 66, 68, 69]\n",
      "==================\n",
      "swi test\n",
      "[[  3   8]\n",
      " [  5 107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2727    0.3750    0.3158         8\n",
      "           1     0.9554    0.9304    0.9427       115\n",
      "\n",
      "    accuracy                         0.8943       123\n",
      "   macro avg     0.6140    0.6527    0.6293       123\n",
      "weighted avg     0.9110    0.8943    0.9020       123\n",
      "\n",
      "[7, 8, 33, 39, 44, 64, 77, 82, 92, 94, 97, 110, 118]\n"
     ]
    }
   ],
   "source": [
    "#test on each dataset for SVM\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26593df9",
   "metadata": {},
   "source": [
    "# Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a4a7abee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103  26]\n",
      " [ 20 223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7984    0.8374    0.8175       123\n",
      "           1     0.9177    0.8956    0.9065       249\n",
      "\n",
      "    accuracy                         0.8763       372\n",
      "   macro avg     0.8581    0.8665    0.8620       372\n",
      "weighted avg     0.8783    0.8763    0.8771       372\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../Models/Meta_only/CNNMeta_NB_dropswi.joblib']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits = 4))\n",
    "\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_NB_dropswi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41fa94ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cle test\n",
      "[[38 13]\n",
      " [ 8 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7451    0.8261    0.7835        46\n",
      "           1     0.8095    0.7234    0.7640        47\n",
      "\n",
      "    accuracy                         0.7742        93\n",
      "   macro avg     0.7773    0.7747    0.7738        93\n",
      "weighted avg     0.7777    0.7742    0.7737        93\n",
      "\n",
      "[4, 9, 15, 17, 19, 22, 25, 33, 34, 38, 41, 44, 47, 52, 59, 69, 70, 72, 76, 78, 89]\n",
      "==================\n",
      "vir test\n",
      "[[ 7  5]\n",
      " [ 4 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5833    0.6364    0.6087        11\n",
      "           1     0.9200    0.9020    0.9109        51\n",
      "\n",
      "    accuracy                         0.8548        62\n",
      "   macro avg     0.7517    0.7692    0.7598        62\n",
      "weighted avg     0.8603    0.8548    0.8573        62\n",
      "\n",
      "[4, 7, 17, 20, 31, 32, 53, 58, 60]\n",
      "==================\n",
      "hun test\n",
      "[[41  5]\n",
      " [17 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8913    0.7069    0.7885        58\n",
      "           1     0.6458    0.8611    0.7381        36\n",
      "\n",
      "    accuracy                         0.7660        94\n",
      "   macro avg     0.7686    0.7840    0.7633        94\n",
      "weighted avg     0.7973    0.7660    0.7692        94\n",
      "\n",
      "[6, 7, 12, 20, 21, 25, 29, 32, 34, 38, 53, 54, 57, 62, 68, 71, 75, 79, 81, 83, 90, 93]\n",
      "==================\n",
      "swi test\n",
      "[[ 2 31]\n",
      " [ 6 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0606    0.2500    0.0976         8\n",
      "           1     0.9333    0.7304    0.8195       115\n",
      "\n",
      "    accuracy                         0.6992       123\n",
      "   macro avg     0.4970    0.4902    0.4585       123\n",
      "weighted avg     0.8766    0.6992    0.7726       123\n",
      "\n",
      "[0, 7, 10, 13, 14, 21, 24, 30, 33, 34, 35, 36, 37, 38, 39, 44, 51, 52, 65, 67, 77, 78, 79, 82, 83, 89, 91, 93, 94, 97, 102, 104, 107, 110, 111, 112, 118]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2670c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
