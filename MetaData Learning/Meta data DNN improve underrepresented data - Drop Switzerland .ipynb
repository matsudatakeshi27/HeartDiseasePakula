{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1ee0e",
   "metadata": {},
   "source": [
    "# DNN metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3360ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_train=pd.read_csv('cle_metadata_dnn_train.csv')\n",
    "cle_test=pd.read_csv('cle_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b8fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train=pd.read_csv('vir_metadata_dnn_train.csv' )\n",
    "vir_test=pd.read_csv('vir_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92518ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train=pd.read_csv('hun_metadata_dnn_train.csv' )\n",
    "hun_test=pd.read_csv('hun_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe3741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_train=pd.read_csv('swi_metadata_dnn_train.csv' )\n",
    "swi_test=pd.read_csv('swi_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([cle_train,vir_train,hun_train])\n",
    "Test = pd.concat([cle_test,vir_test,hun_test,swi_test,swi_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.iloc[:,:-1]\n",
    "X_test = Test.iloc[:,:-1]\n",
    "\n",
    "y_train = Train.iloc[:,-1]\n",
    "y_test = Test.iloc[:,-1]\n",
    "\n",
    "Y_train_binary = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c43269e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482027</td>\n",
       "      <td>0.499887</td>\n",
       "      <td>0.530806</td>\n",
       "      <td>0.538419</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.513956</td>\n",
       "      <td>0.498010</td>\n",
       "      <td>0.488720</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456004</td>\n",
       "      <td>0.549547</td>\n",
       "      <td>0.518709</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.519562</td>\n",
       "      <td>0.484019</td>\n",
       "      <td>0.472015</td>\n",
       "      <td>0.508887</td>\n",
       "      <td>0.467478</td>\n",
       "      <td>0.486530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454859</td>\n",
       "      <td>0.529616</td>\n",
       "      <td>0.526296</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.496266</td>\n",
       "      <td>0.510415</td>\n",
       "      <td>0.484137</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>0.496896</td>\n",
       "      <td>0.540834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477837</td>\n",
       "      <td>0.488366</td>\n",
       "      <td>0.493662</td>\n",
       "      <td>0.497254</td>\n",
       "      <td>0.565816</td>\n",
       "      <td>0.497960</td>\n",
       "      <td>0.456738</td>\n",
       "      <td>0.500947</td>\n",
       "      <td>0.496931</td>\n",
       "      <td>0.517806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463892</td>\n",
       "      <td>0.528533</td>\n",
       "      <td>0.529637</td>\n",
       "      <td>0.528451</td>\n",
       "      <td>0.506440</td>\n",
       "      <td>0.525559</td>\n",
       "      <td>0.475964</td>\n",
       "      <td>0.484750</td>\n",
       "      <td>0.524651</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476820</td>\n",
       "      <td>0.499960</td>\n",
       "      <td>0.477971</td>\n",
       "      <td>0.530497</td>\n",
       "      <td>0.613168</td>\n",
       "      <td>0.473111</td>\n",
       "      <td>0.434871</td>\n",
       "      <td>0.508940</td>\n",
       "      <td>0.505146</td>\n",
       "      <td>0.497114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487112</td>\n",
       "      <td>0.502789</td>\n",
       "      <td>0.547796</td>\n",
       "      <td>0.545979</td>\n",
       "      <td>0.500581</td>\n",
       "      <td>0.501580</td>\n",
       "      <td>0.497734</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.481571</td>\n",
       "      <td>0.520887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467420</td>\n",
       "      <td>0.523350</td>\n",
       "      <td>0.508465</td>\n",
       "      <td>0.497361</td>\n",
       "      <td>0.530505</td>\n",
       "      <td>0.484081</td>\n",
       "      <td>0.486503</td>\n",
       "      <td>0.484897</td>\n",
       "      <td>0.458825</td>\n",
       "      <td>0.480811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.487966</td>\n",
       "      <td>0.502613</td>\n",
       "      <td>0.530262</td>\n",
       "      <td>0.509978</td>\n",
       "      <td>0.498579</td>\n",
       "      <td>0.490217</td>\n",
       "      <td>0.480382</td>\n",
       "      <td>0.510005</td>\n",
       "      <td>0.498182</td>\n",
       "      <td>0.530342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497544</td>\n",
       "      <td>0.513097</td>\n",
       "      <td>0.488849</td>\n",
       "      <td>0.503623</td>\n",
       "      <td>0.556923</td>\n",
       "      <td>0.495072</td>\n",
       "      <td>0.435286</td>\n",
       "      <td>0.503057</td>\n",
       "      <td>0.478725</td>\n",
       "      <td>0.497577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.483704</td>\n",
       "      <td>0.504237</td>\n",
       "      <td>0.479324</td>\n",
       "      <td>0.476369</td>\n",
       "      <td>0.498507</td>\n",
       "      <td>0.506080</td>\n",
       "      <td>0.533774</td>\n",
       "      <td>0.483517</td>\n",
       "      <td>0.510733</td>\n",
       "      <td>0.496863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516407</td>\n",
       "      <td>0.483216</td>\n",
       "      <td>0.524806</td>\n",
       "      <td>0.516051</td>\n",
       "      <td>0.522063</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.507316</td>\n",
       "      <td>0.535838</td>\n",
       "      <td>0.534950</td>\n",
       "      <td>0.464300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.490108</td>\n",
       "      <td>0.492367</td>\n",
       "      <td>0.488563</td>\n",
       "      <td>0.487793</td>\n",
       "      <td>0.495198</td>\n",
       "      <td>0.502775</td>\n",
       "      <td>0.517487</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.509056</td>\n",
       "      <td>0.507079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493095</td>\n",
       "      <td>0.480466</td>\n",
       "      <td>0.526394</td>\n",
       "      <td>0.524396</td>\n",
       "      <td>0.544080</td>\n",
       "      <td>0.490351</td>\n",
       "      <td>0.515740</td>\n",
       "      <td>0.517255</td>\n",
       "      <td>0.547517</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.483685</td>\n",
       "      <td>0.498613</td>\n",
       "      <td>0.478604</td>\n",
       "      <td>0.487754</td>\n",
       "      <td>0.510728</td>\n",
       "      <td>0.487946</td>\n",
       "      <td>0.529723</td>\n",
       "      <td>0.493159</td>\n",
       "      <td>0.498613</td>\n",
       "      <td>0.495365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489138</td>\n",
       "      <td>0.522639</td>\n",
       "      <td>0.530010</td>\n",
       "      <td>0.516468</td>\n",
       "      <td>0.533154</td>\n",
       "      <td>0.477123</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.522138</td>\n",
       "      <td>0.539904</td>\n",
       "      <td>0.508322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.476345</td>\n",
       "      <td>0.496224</td>\n",
       "      <td>0.485959</td>\n",
       "      <td>0.488809</td>\n",
       "      <td>0.503595</td>\n",
       "      <td>0.518979</td>\n",
       "      <td>0.520347</td>\n",
       "      <td>0.491363</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>0.511617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497776</td>\n",
       "      <td>0.501086</td>\n",
       "      <td>0.517439</td>\n",
       "      <td>0.512927</td>\n",
       "      <td>0.525908</td>\n",
       "      <td>0.490491</td>\n",
       "      <td>0.506457</td>\n",
       "      <td>0.526181</td>\n",
       "      <td>0.510480</td>\n",
       "      <td>0.513963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.490297</td>\n",
       "      <td>0.497950</td>\n",
       "      <td>0.473245</td>\n",
       "      <td>0.498749</td>\n",
       "      <td>0.507454</td>\n",
       "      <td>0.481953</td>\n",
       "      <td>0.528355</td>\n",
       "      <td>0.495543</td>\n",
       "      <td>0.491902</td>\n",
       "      <td>0.507735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493537</td>\n",
       "      <td>0.515256</td>\n",
       "      <td>0.532098</td>\n",
       "      <td>0.525226</td>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.467642</td>\n",
       "      <td>0.509273</td>\n",
       "      <td>0.514771</td>\n",
       "      <td>0.511319</td>\n",
       "      <td>0.514755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.482027  0.499887  0.530806  0.538419  0.491713  0.513956  0.498010   \n",
       "1    0.454859  0.529616  0.526296  0.552197  0.496266  0.510415  0.484137   \n",
       "2    0.463892  0.528533  0.529637  0.528451  0.506440  0.525559  0.475964   \n",
       "3    0.487112  0.502789  0.547796  0.545979  0.500581  0.501580  0.497734   \n",
       "4    0.487966  0.502613  0.530262  0.509978  0.498579  0.490217  0.480382   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.483704  0.504237  0.479324  0.476369  0.498507  0.506080  0.533774   \n",
       "196  0.490108  0.492367  0.488563  0.487793  0.495198  0.502775  0.517487   \n",
       "197  0.483685  0.498613  0.478604  0.487754  0.510728  0.487946  0.529723   \n",
       "198  0.476345  0.496224  0.485959  0.488809  0.503595  0.518979  0.520347   \n",
       "199  0.490297  0.497950  0.473245  0.498749  0.507454  0.481953  0.528355   \n",
       "\n",
       "            7         8         9  ...       6.2       7.2       8.2  \\\n",
       "0    0.488720  0.489319  0.541717  ...  0.456004  0.549547  0.518709   \n",
       "1    0.507131  0.496896  0.540834  ...  0.477837  0.488366  0.493662   \n",
       "2    0.484750  0.524651  0.529517  ...  0.476820  0.499960  0.477971   \n",
       "3    0.493490  0.481571  0.520887  ...  0.467420  0.523350  0.508465   \n",
       "4    0.510005  0.498182  0.530342  ...  0.497544  0.513097  0.488849   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "195  0.483517  0.510733  0.496863  ...  0.516407  0.483216  0.524806   \n",
       "196  0.500597  0.509056  0.507079  ...  0.493095  0.480466  0.526394   \n",
       "197  0.493159  0.498613  0.495365  ...  0.489138  0.522639  0.530010   \n",
       "198  0.491363  0.499720  0.511617  ...  0.497776  0.501086  0.517439   \n",
       "199  0.495543  0.491902  0.507735  ...  0.493537  0.515256  0.532098   \n",
       "\n",
       "          9.2      10.2      11.2      12.2      13.2      14.2      15.2  \n",
       "0    0.493687  0.519562  0.484019  0.472015  0.508887  0.467478  0.486530  \n",
       "1    0.497254  0.565816  0.497960  0.456738  0.500947  0.496931  0.517806  \n",
       "2    0.530497  0.613168  0.473111  0.434871  0.508940  0.505146  0.497114  \n",
       "3    0.497361  0.530505  0.484081  0.486503  0.484897  0.458825  0.480811  \n",
       "4    0.503623  0.556923  0.495072  0.435286  0.503057  0.478725  0.497577  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "195  0.516051  0.522063  0.520908  0.507316  0.535838  0.534950  0.464300  \n",
       "196  0.524396  0.544080  0.490351  0.515740  0.517255  0.547517  0.485666  \n",
       "197  0.516468  0.533154  0.477123  0.505441  0.522138  0.539904  0.508322  \n",
       "198  0.512927  0.525908  0.490491  0.506457  0.526181  0.510480  0.513963  \n",
       "199  0.525226  0.531579  0.467642  0.509273  0.514771  0.511319  0.514755  \n",
       "\n",
       "[548 rows x 48 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.iloc[:,:-16]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db3d3c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428787</td>\n",
       "      <td>0.525325</td>\n",
       "      <td>0.542139</td>\n",
       "      <td>0.478648</td>\n",
       "      <td>0.506824</td>\n",
       "      <td>0.490862</td>\n",
       "      <td>0.482278</td>\n",
       "      <td>0.505213</td>\n",
       "      <td>0.516506</td>\n",
       "      <td>0.520210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469042</td>\n",
       "      <td>0.494732</td>\n",
       "      <td>0.483015</td>\n",
       "      <td>0.492952</td>\n",
       "      <td>0.539282</td>\n",
       "      <td>0.433638</td>\n",
       "      <td>0.487028</td>\n",
       "      <td>0.496327</td>\n",
       "      <td>0.451854</td>\n",
       "      <td>0.460499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444054</td>\n",
       "      <td>0.518033</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.527710</td>\n",
       "      <td>0.511543</td>\n",
       "      <td>0.505929</td>\n",
       "      <td>0.505096</td>\n",
       "      <td>0.473268</td>\n",
       "      <td>0.500194</td>\n",
       "      <td>0.563858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462495</td>\n",
       "      <td>0.520767</td>\n",
       "      <td>0.514996</td>\n",
       "      <td>0.479704</td>\n",
       "      <td>0.547857</td>\n",
       "      <td>0.469282</td>\n",
       "      <td>0.477678</td>\n",
       "      <td>0.534086</td>\n",
       "      <td>0.459659</td>\n",
       "      <td>0.482997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.464015</td>\n",
       "      <td>0.547513</td>\n",
       "      <td>0.534929</td>\n",
       "      <td>0.515994</td>\n",
       "      <td>0.526294</td>\n",
       "      <td>0.519013</td>\n",
       "      <td>0.493227</td>\n",
       "      <td>0.487353</td>\n",
       "      <td>0.533328</td>\n",
       "      <td>0.515880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485028</td>\n",
       "      <td>0.492818</td>\n",
       "      <td>0.466966</td>\n",
       "      <td>0.514667</td>\n",
       "      <td>0.588129</td>\n",
       "      <td>0.480854</td>\n",
       "      <td>0.432877</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.507247</td>\n",
       "      <td>0.502260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464099</td>\n",
       "      <td>0.502493</td>\n",
       "      <td>0.530403</td>\n",
       "      <td>0.543423</td>\n",
       "      <td>0.488266</td>\n",
       "      <td>0.506906</td>\n",
       "      <td>0.496008</td>\n",
       "      <td>0.470768</td>\n",
       "      <td>0.488893</td>\n",
       "      <td>0.567098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449605</td>\n",
       "      <td>0.551441</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>0.478567</td>\n",
       "      <td>0.537422</td>\n",
       "      <td>0.471184</td>\n",
       "      <td>0.465805</td>\n",
       "      <td>0.508096</td>\n",
       "      <td>0.466514</td>\n",
       "      <td>0.465507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451514</td>\n",
       "      <td>0.539376</td>\n",
       "      <td>0.544900</td>\n",
       "      <td>0.502148</td>\n",
       "      <td>0.503703</td>\n",
       "      <td>0.533397</td>\n",
       "      <td>0.448659</td>\n",
       "      <td>0.478863</td>\n",
       "      <td>0.508552</td>\n",
       "      <td>0.546285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482086</td>\n",
       "      <td>0.511703</td>\n",
       "      <td>0.477694</td>\n",
       "      <td>0.494675</td>\n",
       "      <td>0.542177</td>\n",
       "      <td>0.473592</td>\n",
       "      <td>0.467832</td>\n",
       "      <td>0.478610</td>\n",
       "      <td>0.443659</td>\n",
       "      <td>0.481261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.499596</td>\n",
       "      <td>0.503362</td>\n",
       "      <td>0.522893</td>\n",
       "      <td>0.496161</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>0.461692</td>\n",
       "      <td>0.509040</td>\n",
       "      <td>0.502430</td>\n",
       "      <td>0.476613</td>\n",
       "      <td>0.537732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515923</td>\n",
       "      <td>0.500189</td>\n",
       "      <td>0.543489</td>\n",
       "      <td>0.511016</td>\n",
       "      <td>0.494478</td>\n",
       "      <td>0.466297</td>\n",
       "      <td>0.458757</td>\n",
       "      <td>0.538558</td>\n",
       "      <td>0.475912</td>\n",
       "      <td>0.485755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.497214</td>\n",
       "      <td>0.491898</td>\n",
       "      <td>0.538590</td>\n",
       "      <td>0.533611</td>\n",
       "      <td>0.515420</td>\n",
       "      <td>0.481304</td>\n",
       "      <td>0.514259</td>\n",
       "      <td>0.486543</td>\n",
       "      <td>0.492588</td>\n",
       "      <td>0.514609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538429</td>\n",
       "      <td>0.494881</td>\n",
       "      <td>0.531248</td>\n",
       "      <td>0.523854</td>\n",
       "      <td>0.466190</td>\n",
       "      <td>0.529339</td>\n",
       "      <td>0.471890</td>\n",
       "      <td>0.531397</td>\n",
       "      <td>0.437475</td>\n",
       "      <td>0.486962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.517050</td>\n",
       "      <td>0.514450</td>\n",
       "      <td>0.509608</td>\n",
       "      <td>0.503844</td>\n",
       "      <td>0.533506</td>\n",
       "      <td>0.505198</td>\n",
       "      <td>0.480254</td>\n",
       "      <td>0.489807</td>\n",
       "      <td>0.471894</td>\n",
       "      <td>0.506556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523795</td>\n",
       "      <td>0.467489</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.530422</td>\n",
       "      <td>0.487560</td>\n",
       "      <td>0.493201</td>\n",
       "      <td>0.484776</td>\n",
       "      <td>0.545881</td>\n",
       "      <td>0.466940</td>\n",
       "      <td>0.477744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.525592</td>\n",
       "      <td>0.497026</td>\n",
       "      <td>0.542631</td>\n",
       "      <td>0.507730</td>\n",
       "      <td>0.521060</td>\n",
       "      <td>0.475272</td>\n",
       "      <td>0.506918</td>\n",
       "      <td>0.474250</td>\n",
       "      <td>0.486505</td>\n",
       "      <td>0.510403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519751</td>\n",
       "      <td>0.510182</td>\n",
       "      <td>0.530916</td>\n",
       "      <td>0.509050</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.491346</td>\n",
       "      <td>0.493666</td>\n",
       "      <td>0.532326</td>\n",
       "      <td>0.481168</td>\n",
       "      <td>0.488967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.521995</td>\n",
       "      <td>0.499324</td>\n",
       "      <td>0.531584</td>\n",
       "      <td>0.508733</td>\n",
       "      <td>0.551871</td>\n",
       "      <td>0.488382</td>\n",
       "      <td>0.494927</td>\n",
       "      <td>0.486490</td>\n",
       "      <td>0.486524</td>\n",
       "      <td>0.511331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525063</td>\n",
       "      <td>0.488777</td>\n",
       "      <td>0.522951</td>\n",
       "      <td>0.528720</td>\n",
       "      <td>0.499248</td>\n",
       "      <td>0.509396</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>0.546639</td>\n",
       "      <td>0.460442</td>\n",
       "      <td>0.474039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.428787  0.525325  0.542139  0.478648  0.506824  0.490862  0.482278   \n",
       "1   0.444054  0.518033  0.532847  0.527710  0.511543  0.505929  0.505096   \n",
       "2   0.464015  0.547513  0.534929  0.515994  0.526294  0.519013  0.493227   \n",
       "3   0.464099  0.502493  0.530403  0.543423  0.488266  0.506906  0.496008   \n",
       "4   0.451514  0.539376  0.544900  0.502148  0.503703  0.533397  0.448659   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.499596  0.503362  0.522893  0.496161  0.543045  0.461692  0.509040   \n",
       "78  0.497214  0.491898  0.538590  0.533611  0.515420  0.481304  0.514259   \n",
       "79  0.517050  0.514450  0.509608  0.503844  0.533506  0.505198  0.480254   \n",
       "80  0.525592  0.497026  0.542631  0.507730  0.521060  0.475272  0.506918   \n",
       "81  0.521995  0.499324  0.531584  0.508733  0.551871  0.488382  0.494927   \n",
       "\n",
       "           7         8         9  ...       6.2       7.2       8.2       9.2  \\\n",
       "0   0.505213  0.516506  0.520210  ...  0.469042  0.494732  0.483015  0.492952   \n",
       "1   0.473268  0.500194  0.563858  ...  0.462495  0.520767  0.514996  0.479704   \n",
       "2   0.487353  0.533328  0.515880  ...  0.485028  0.492818  0.466966  0.514667   \n",
       "3   0.470768  0.488893  0.567098  ...  0.449605  0.551441  0.525775  0.478567   \n",
       "4   0.478863  0.508552  0.546285  ...  0.482086  0.511703  0.477694  0.494675   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "77  0.502430  0.476613  0.537732  ...  0.515923  0.500189  0.543489  0.511016   \n",
       "78  0.486543  0.492588  0.514609  ...  0.538429  0.494881  0.531248  0.523854   \n",
       "79  0.489807  0.471894  0.506556  ...  0.523795  0.467489  0.512300  0.530422   \n",
       "80  0.474250  0.486505  0.510403  ...  0.519751  0.510182  0.530916  0.509050   \n",
       "81  0.486490  0.486524  0.511331  ...  0.525063  0.488777  0.522951  0.528720   \n",
       "\n",
       "        10.2      11.2      12.2      13.2      14.2      15.2  \n",
       "0   0.539282  0.433638  0.487028  0.496327  0.451854  0.460499  \n",
       "1   0.547857  0.469282  0.477678  0.534086  0.459659  0.482997  \n",
       "2   0.588129  0.480854  0.432877  0.501815  0.507247  0.502260  \n",
       "3   0.537422  0.471184  0.465805  0.508096  0.466514  0.465507  \n",
       "4   0.542177  0.473592  0.467832  0.478610  0.443659  0.481261  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "77  0.494478  0.466297  0.458757  0.538558  0.475912  0.485755  \n",
       "78  0.466190  0.529339  0.471890  0.531397  0.437475  0.486962  \n",
       "79  0.487560  0.493201  0.484776  0.545881  0.466940  0.477744  \n",
       "80  0.477800  0.491346  0.493666  0.532326  0.481168  0.488967  \n",
       "81  0.499248  0.509396  0.497447  0.546639  0.460442  0.474039  \n",
       "\n",
       "[454 rows x 48 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.iloc[:,:-16]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3016ecb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cle_train_temp = cle_train.iloc[:,:-17]\n",
    "cle_train_Y = cle_train.iloc[:,-1]\n",
    "cle_train = pd.concat([cle_train_temp, cle_train_Y], axis=1)\n",
    "cle_train.to_csv('cle_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0fd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train_temp = vir_train.iloc[:,:-17]\n",
    "vir_train_Y = vir_train.iloc[:,-1]\n",
    "vir_train = pd.concat([vir_train_temp, vir_train_Y], axis=1)\n",
    "vir_train.to_csv('vir_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad66556",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train_temp = hun_train.iloc[:,:-17]\n",
    "hun_train_Y = hun_train.iloc[:,-1]\n",
    "hun_train = pd.concat([hun_train_temp, hun_train_Y], axis=1)\n",
    "hun_train.to_csv('hun_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04e852ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_test_temp = cle_test.iloc[:,:-17]\n",
    "cle_test_Y = cle_test.iloc[:,-1]\n",
    "cle_test = pd.concat([cle_test_temp, cle_test_Y], axis=1)\n",
    "cle_test.to_csv('cle_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9041c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_test_temp = vir_test.iloc[:,:-17]\n",
    "vir_test_Y = vir_test.iloc[:,-1]\n",
    "vir_test = pd.concat([vir_test_temp, vir_test_Y], axis=1)\n",
    "vir_test.to_csv('vir_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4764f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_test_temp = hun_test.iloc[:,:-17]\n",
    "hun_test_Y = hun_test.iloc[:,-1]\n",
    "hun_test = pd.concat([hun_test_temp, hun_test_Y], axis=1)\n",
    "hun_test.to_csv('hun_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4349043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7.3</th>\n",
       "      <th>8.3</th>\n",
       "      <th>9.3</th>\n",
       "      <th>10.3</th>\n",
       "      <th>11.3</th>\n",
       "      <th>12.3</th>\n",
       "      <th>13.3</th>\n",
       "      <th>14.3</th>\n",
       "      <th>15.3</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.522762</td>\n",
       "      <td>0.504038</td>\n",
       "      <td>0.527250</td>\n",
       "      <td>0.498387</td>\n",
       "      <td>0.565987</td>\n",
       "      <td>0.509586</td>\n",
       "      <td>0.479623</td>\n",
       "      <td>0.509473</td>\n",
       "      <td>0.480492</td>\n",
       "      <td>0.534721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537556</td>\n",
       "      <td>0.453480</td>\n",
       "      <td>0.577583</td>\n",
       "      <td>0.446029</td>\n",
       "      <td>0.485879</td>\n",
       "      <td>0.386280</td>\n",
       "      <td>0.497379</td>\n",
       "      <td>0.454557</td>\n",
       "      <td>0.509074</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512266</td>\n",
       "      <td>0.496535</td>\n",
       "      <td>0.537593</td>\n",
       "      <td>0.512366</td>\n",
       "      <td>0.549310</td>\n",
       "      <td>0.491441</td>\n",
       "      <td>0.498024</td>\n",
       "      <td>0.484337</td>\n",
       "      <td>0.487093</td>\n",
       "      <td>0.521420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519116</td>\n",
       "      <td>0.457791</td>\n",
       "      <td>0.554603</td>\n",
       "      <td>0.459480</td>\n",
       "      <td>0.484268</td>\n",
       "      <td>0.438276</td>\n",
       "      <td>0.499722</td>\n",
       "      <td>0.489912</td>\n",
       "      <td>0.514547</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529690</td>\n",
       "      <td>0.491952</td>\n",
       "      <td>0.524946</td>\n",
       "      <td>0.485390</td>\n",
       "      <td>0.539485</td>\n",
       "      <td>0.485555</td>\n",
       "      <td>0.503719</td>\n",
       "      <td>0.480027</td>\n",
       "      <td>0.475724</td>\n",
       "      <td>0.530794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544467</td>\n",
       "      <td>0.473762</td>\n",
       "      <td>0.562892</td>\n",
       "      <td>0.473715</td>\n",
       "      <td>0.511834</td>\n",
       "      <td>0.417594</td>\n",
       "      <td>0.485931</td>\n",
       "      <td>0.456725</td>\n",
       "      <td>0.503743</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.515700</td>\n",
       "      <td>0.495323</td>\n",
       "      <td>0.521070</td>\n",
       "      <td>0.486139</td>\n",
       "      <td>0.526061</td>\n",
       "      <td>0.464749</td>\n",
       "      <td>0.493206</td>\n",
       "      <td>0.486621</td>\n",
       "      <td>0.492749</td>\n",
       "      <td>0.515017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515474</td>\n",
       "      <td>0.460602</td>\n",
       "      <td>0.541977</td>\n",
       "      <td>0.508290</td>\n",
       "      <td>0.469738</td>\n",
       "      <td>0.478705</td>\n",
       "      <td>0.516899</td>\n",
       "      <td>0.476888</td>\n",
       "      <td>0.537910</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.504315</td>\n",
       "      <td>0.504432</td>\n",
       "      <td>0.526749</td>\n",
       "      <td>0.493828</td>\n",
       "      <td>0.539291</td>\n",
       "      <td>0.465600</td>\n",
       "      <td>0.504622</td>\n",
       "      <td>0.498895</td>\n",
       "      <td>0.482281</td>\n",
       "      <td>0.543537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527635</td>\n",
       "      <td>0.454373</td>\n",
       "      <td>0.578429</td>\n",
       "      <td>0.465488</td>\n",
       "      <td>0.502486</td>\n",
       "      <td>0.381890</td>\n",
       "      <td>0.476488</td>\n",
       "      <td>0.486014</td>\n",
       "      <td>0.542625</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.521899</td>\n",
       "      <td>0.506514</td>\n",
       "      <td>0.491817</td>\n",
       "      <td>0.525493</td>\n",
       "      <td>0.516104</td>\n",
       "      <td>0.489461</td>\n",
       "      <td>0.497187</td>\n",
       "      <td>0.504617</td>\n",
       "      <td>0.488040</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.493402</td>\n",
       "      <td>0.513794</td>\n",
       "      <td>0.503867</td>\n",
       "      <td>0.505538</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>0.468497</td>\n",
       "      <td>0.501576</td>\n",
       "      <td>0.509287</td>\n",
       "      <td>0.484469</td>\n",
       "      <td>0.535978</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.497897</td>\n",
       "      <td>0.508730</td>\n",
       "      <td>0.510682</td>\n",
       "      <td>0.498494</td>\n",
       "      <td>0.547744</td>\n",
       "      <td>0.476758</td>\n",
       "      <td>0.501776</td>\n",
       "      <td>0.500636</td>\n",
       "      <td>0.481379</td>\n",
       "      <td>0.542525</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.506661</td>\n",
       "      <td>0.498455</td>\n",
       "      <td>0.525077</td>\n",
       "      <td>0.517549</td>\n",
       "      <td>0.547720</td>\n",
       "      <td>0.491332</td>\n",
       "      <td>0.483464</td>\n",
       "      <td>0.487521</td>\n",
       "      <td>0.464264</td>\n",
       "      <td>0.503385</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.517776</td>\n",
       "      <td>0.477103</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>0.512531</td>\n",
       "      <td>0.520010</td>\n",
       "      <td>0.488564</td>\n",
       "      <td>0.503612</td>\n",
       "      <td>0.492379</td>\n",
       "      <td>0.505658</td>\n",
       "      <td>0.513014</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.522762  0.504038  0.527250  0.498387  0.565987  0.509586  0.479623   \n",
       "1    0.512266  0.496535  0.537593  0.512366  0.549310  0.491441  0.498024   \n",
       "2    0.529690  0.491952  0.524946  0.485390  0.539485  0.485555  0.503719   \n",
       "3    0.515700  0.495323  0.521070  0.486139  0.526061  0.464749  0.493206   \n",
       "4    0.504315  0.504432  0.526749  0.493828  0.539291  0.465600  0.504622   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "118  0.521899  0.506514  0.491817  0.525493  0.516104  0.489461  0.497187   \n",
       "119  0.493402  0.513794  0.503867  0.505538  0.537071  0.468497  0.501576   \n",
       "120  0.497897  0.508730  0.510682  0.498494  0.547744  0.476758  0.501776   \n",
       "121  0.506661  0.498455  0.525077  0.517549  0.547720  0.491332  0.483464   \n",
       "122  0.517776  0.477103  0.549429  0.512531  0.520010  0.488564  0.503612   \n",
       "\n",
       "            7         8         9  ...       7.3       8.3       9.3  \\\n",
       "0    0.509473  0.480492  0.534721  ...  0.537556  0.453480  0.577583   \n",
       "1    0.484337  0.487093  0.521420  ...  0.519116  0.457791  0.554603   \n",
       "2    0.480027  0.475724  0.530794  ...  0.544467  0.473762  0.562892   \n",
       "3    0.486621  0.492749  0.515017  ...  0.515474  0.460602  0.541977   \n",
       "4    0.498895  0.482281  0.543537  ...  0.527635  0.454373  0.578429   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "118  0.504617  0.488040  0.539020  ...       NaN       NaN       NaN   \n",
       "119  0.509287  0.484469  0.535978  ...       NaN       NaN       NaN   \n",
       "120  0.500636  0.481379  0.542525  ...       NaN       NaN       NaN   \n",
       "121  0.487521  0.464264  0.503385  ...       NaN       NaN       NaN   \n",
       "122  0.492379  0.505658  0.513014  ...       NaN       NaN       NaN   \n",
       "\n",
       "         10.3      11.3      12.3      13.3      14.3      15.3   num  \n",
       "0    0.446029  0.485879  0.386280  0.497379  0.454557  0.509074  0.75  \n",
       "1    0.459480  0.484268  0.438276  0.499722  0.489912  0.514547  0.75  \n",
       "2    0.473715  0.511834  0.417594  0.485931  0.456725  0.503743  0.50  \n",
       "3    0.508290  0.469738  0.478705  0.516899  0.476888  0.537910  0.25  \n",
       "4    0.465488  0.502486  0.381890  0.476488  0.486014  0.542625  0.25  \n",
       "..        ...       ...       ...       ...       ...       ...   ...  \n",
       "118       NaN       NaN       NaN       NaN       NaN       NaN  0.25  \n",
       "119       NaN       NaN       NaN       NaN       NaN       NaN  0.25  \n",
       "120       NaN       NaN       NaN       NaN       NaN       NaN  0.75  \n",
       "121       NaN       NaN       NaN       NaN       NaN       NaN  0.25  \n",
       "122       NaN       NaN       NaN       NaN       NaN       NaN  0.75  \n",
       "\n",
       "[205 rows x 65 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swi_test_new = pd.concat([swi_train, swi_test])\n",
    "swi_test_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bd79e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_test_temp = swi_test_new.iloc[:,:-17]\n",
    "swi_test_Y = swi_test_new.iloc[:,-1]\n",
    "swi_test = pd.concat([swi_test_temp, swi_test_Y], axis=1)\n",
    "swi_test.to_csv('swi_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55a9da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for deep learning testing\n",
    "def Test(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "    \n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e623e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86ca29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(48,1)))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/DNNMeta_CNN_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bf045",
   "metadata": {},
   "source": [
    "# Test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_dnn_train.csv'\n",
    "path_test = 'cle_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_dnn_train.csv'\n",
    "path_test = 'vir_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_dnn_train.csv'\n",
    "path_test = 'hun_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_dnn_train.csv'\n",
    "path_test = 'swi_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0813f",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fddd185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 1s 5ms/step - loss: 0.6979 - accuracy: 0.4891\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5255\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5255\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5255\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5748\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5128\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.6478\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6787 - accuracy: 0.5365\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.5328\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5310\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.5420\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5274\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.6387\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.5693\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.6131\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.5474\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6706 - accuracy: 0.5839\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.6515\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.5639\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.5912\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6223\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6679\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.5931\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6515\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6825\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6150\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6442\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.6004\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6965 - accuracy: 0.5274\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6515\n",
      "[[115 263]\n",
      " [ 13  63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3042    0.8984    0.4545       128\n",
      "           1     0.8289    0.1933    0.3134       326\n",
      "\n",
      "    accuracy                         0.3921       454\n",
      "   macro avg     0.5666    0.5458    0.3840       454\n",
      "weighted avg     0.6810    0.3921    0.3532       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(48,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_DNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a844",
   "metadata": {},
   "source": [
    "# test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12522ce3",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "880e0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e78c2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 4s 31ms/step - loss: 0.6837 - accuracy: 0.5511\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6725 - accuracy: 0.5566\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.6516 - accuracy: 0.6004\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.6282 - accuracy: 0.6697\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.7023 - accuracy: 0.5347\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6890 - accuracy: 0.5328\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6684 - accuracy: 0.5949\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.6395 - accuracy: 0.6606\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5876 - accuracy: 0.7153\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5735 - accuracy: 0.6971\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5532 - accuracy: 0.6934\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5332 - accuracy: 0.7427\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.5512 - accuracy: 0.7226\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.4935 - accuracy: 0.7719\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.4789 - accuracy: 0.7792\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5473 - accuracy: 0.7591\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.5308 - accuracy: 0.7591\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.5130 - accuracy: 0.7664\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5140 - accuracy: 0.7573\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5298 - accuracy: 0.7409\n",
      "[[ 98 224]\n",
      " [ 30 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3043    0.7656    0.4356       128\n",
      "           1     0.7727    0.3129    0.4454       326\n",
      "\n",
      "    accuracy                         0.4405       454\n",
      "   macro avg     0.5385    0.5393    0.4405       454\n",
      "weighted avg     0.6407    0.4405    0.4426       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(48, 1)))\n",
    "model.add(SimpleRNN(units=32, return_sequences=True))\n",
    "model.add(SimpleRNN(units=16))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedaab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_RNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fae7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812110c",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bde29",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61dc493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2175bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is:\n",
      "[[ 82  43]\n",
      " [ 46 283]]\n",
      "Accuracy is : 0.8039647577092511\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65       128\n",
      "           1       0.86      0.87      0.86       326\n",
      "\n",
      "    accuracy                           0.80       454\n",
      "   macro avg       0.76      0.75      0.76       454\n",
      "weighted avg       0.80      0.80      0.80       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_train, Y_train_binary)\n",
    "Y_predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(Y_predictions, Y_test_binary)\n",
    "print(\"Confusion Matrix is:\")\n",
    "print(cm)\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "print(\"Accuracy is : \" + str(accuracy(cm)))\n",
    "    \n",
    "print(\"Report\")\n",
    "print(classification_report(Y_test_binary, Y_predictions))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d529c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save clf model\n",
    "from joblib import dump, load\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_dt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08cf24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Decision tree, and random forest testing\n",
    "def Test_DT(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = load(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for decision tree\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f058a8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dee5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e9459fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103 185]\n",
      " [ 25 141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3576    0.8047    0.4952       128\n",
      "           1     0.8494    0.4325    0.5732       326\n",
      "\n",
      "    accuracy                         0.5374       454\n",
      "   macro avg     0.6035    0.6186    0.5342       454\n",
      "weighted avg     0.7108    0.5374    0.5512       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(classifier, '../Models/Meta_only/CNNMeta_rf_9005.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49633d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for Random Forest\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511e046",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb18996",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train_binary.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(Y_test_binary, y_pred))\n",
    "print(classification_report(Y_test_binary, y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svc, \"../Models/Meta_only/CNNMeta_svm_8978.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for SVM\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26593df9",
   "metadata": {},
   "source": [
    "# Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits = 4))\n",
    "\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_NB_dropswi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2670c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
