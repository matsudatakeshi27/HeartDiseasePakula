{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_10124\\3283149789.py:12: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85500b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle = pd.read_csv('cle_metadata_dnn.csv')\n",
    "vir = pd.read_csv('vir_metadata_dnn.csv')\n",
    "hun = pd.read_csv('hun_metadata_dnn.csv')\n",
    "swi = pd.read_csv('swi_metadata_dnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e570ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_train,cle_test = train_test_split(cle,test_size=0.33, random_state=42)\n",
    "vir_train,vir_test = train_test_split(vir,test_size=0.33, random_state=42)\n",
    "hun_train,hun_test = train_test_split(hun,test_size=0.33, random_state=42)\n",
    "swi_train,swi_test = train_test_split(swi,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([cle_train,vir_train,hun_train])\n",
    "Test = pd.concat([cle_test,vir_test,hun_test,swi_test,swi_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.iloc[:,:-1]\n",
    "X_test = Test.iloc[:,:-1]\n",
    "\n",
    "y_train = Train.iloc[:,-1]\n",
    "y_test = Test.iloc[:,-1]\n",
    "\n",
    "Y_train_binary = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e623e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75dce5a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.822429895401001\n",
      "\n",
      "Best val_accuracy So Far: 0.9065420627593994\n",
      "Total elapsed time: 00h 05m 04s\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 60, 96)            576       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 56, 96)            46176     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 28, 96)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 24, 96)            46176     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 12, 96)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 96)                110688    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 194       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,810\n",
      "Trainable params: 203,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define your CNN model function\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Define the hyperparameter search space\n",
    "    hp_filters = hp.Int('num_filters', min_value=32, max_value=128, step=32)\n",
    "    hp_kernel_size = hp.Int('kernel_size', min_value=3, max_value=5)\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    model.add(layers.Conv1D(hp_filters, hp_kernel_size, activation='relu', input_shape=(64,1)))\n",
    "    model.add(layers.Conv1D(hp_filters, hp_kernel_size, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "              \n",
    "    model.add(layers.Conv1D(hp_filters, hp_kernel_size, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Add fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(hp_units, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a RandomSearch tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',  # Hyperparameter optimization goal\n",
    "    max_trials=100,             # Number of trials (random combinations of hyperparameters)\n",
    "    directory='random_search', # Directory to save results\n",
    "    project_name='cnn_tuning'  # Name of the tuning project\n",
    ")\n",
    "\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, Y_train_binary, epochs=20, validation_split=0.2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the final model with the best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "#display the best model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c86ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 0.6938 - accuracy: 0.5122\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.5553\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6901 - accuracy: 0.6173\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.4709\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.5516\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.5854\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.6417\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.6848\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.7261\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.7054\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7580\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7786\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7730\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7824\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.8030\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8199\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8124\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8049\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8049\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8218\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8274\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8199\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8386\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8405\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.8236\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8386\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8386\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8368\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8537\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8668\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8499\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.8649\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8612\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8462\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.8593\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8518\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8349\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8630\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8668\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8762\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3171 - accuracy: 0.8724\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8799\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8856\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3001 - accuracy: 0.8799\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8687\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.3115 - accuracy: 0.8912\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2932 - accuracy: 0.8799\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2899 - accuracy: 0.8912\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2850 - accuracy: 0.8912\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8818\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2754 - accuracy: 0.9062\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2764 - accuracy: 0.8799\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2740 - accuracy: 0.8893\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9024\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.9024\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.9062\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2614 - accuracy: 0.8949\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.8968\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2485 - accuracy: 0.8931\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2533 - accuracy: 0.9062\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2287 - accuracy: 0.9174\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2297 - accuracy: 0.9099\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2216 - accuracy: 0.9156\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2204 - accuracy: 0.9043\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2269 - accuracy: 0.9156\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2097 - accuracy: 0.9250\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2191 - accuracy: 0.9156\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2145 - accuracy: 0.9212\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.9231\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.9362\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9306\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1798 - accuracy: 0.9381\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.2073 - accuracy: 0.9156\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1864 - accuracy: 0.9287\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1676 - accuracy: 0.9362\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9418\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1605 - accuracy: 0.9475\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9400\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1614 - accuracy: 0.9493\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9531\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1565 - accuracy: 0.9475\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.9418\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1533 - accuracy: 0.9531\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9531\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.9156\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.9568\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1383 - accuracy: 0.9475\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.9587\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9644\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9456\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1412 - accuracy: 0.9475\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9568\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9606\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9662\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.9644\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9587\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1037 - accuracy: 0.9662\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0957 - accuracy: 0.9719\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9700\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0955 - accuracy: 0.9719\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9662\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9775\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9775\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9775\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9719\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.9831\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9831\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9887\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9794\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9775\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9606\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9850\n",
      "Epoch 113/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9944\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9887\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9812\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9831\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9869\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9850\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0620 - accuracy: 0.9831\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9812\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9869\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9794\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "[[109 125]\n",
      " [ 26 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4658    0.8074    0.5908       135\n",
      "           1     0.8301    0.5040    0.6272       252\n",
      "\n",
      "    accuracy                         0.6098       387\n",
      "   macro avg     0.6479    0.6557    0.6090       387\n",
      "weighted avg     0.7030    0.6098    0.6145       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "best_model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = best_model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f34fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
