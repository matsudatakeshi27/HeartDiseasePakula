{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_10124\\3283149789.py:12: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85500b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle = pd.read_csv('cle_metadata_dnn.csv')\n",
    "vir = pd.read_csv('vir_metadata_dnn.csv')\n",
    "hun = pd.read_csv('hun_metadata_dnn.csv')\n",
    "swi = pd.read_csv('swi_metadata_dnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e570ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_train,cle_test = train_test_split(cle,test_size=0.33, random_state=42)\n",
    "vir_train,vir_test = train_test_split(vir,test_size=0.33, random_state=42)\n",
    "hun_train,hun_test = train_test_split(hun,test_size=0.33, random_state=42)\n",
    "swi_train,swi_test = train_test_split(swi,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([cle_train,vir_train,hun_train])\n",
    "Test = pd.concat([cle_test,vir_test,hun_test,swi_test,swi_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.iloc[:,:-1]\n",
    "X_test = Test.iloc[:,:-1]\n",
    "\n",
    "y_train = Train.iloc[:,-1]\n",
    "y_test = Test.iloc[:,-1]\n",
    "\n",
    "Y_train_binary = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e623e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75dce5a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.822429895401001\n",
      "\n",
      "Best val_accuracy So Far: 0.9065420627593994\n",
      "Total elapsed time: 00h 05m 04s\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 60, 96)            576       \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 56, 96)            46176     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 28, 96)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 24, 96)            46176     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 12, 96)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 96)                110688    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 194       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,810\n",
      "Trainable params: 203,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define your CNN model function\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Define the hyperparameter search space\n",
    "    hp_filters = hp.Int('num_filters', min_value=32, max_value=128, step=32)\n",
    "    hp_kernel_size = hp.Int('kernel_size', min_value=3, max_value=5)\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    model.add(layers.Conv1D(hp_filters, hp_kernel_size, activation='relu', input_shape=(64,1)))\n",
    "    model.add(layers.Conv1D(hp_filters, hp_kernel_size, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "              \n",
    "    model.add(layers.Conv1D(hp_filters, hp_kernel_size, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Add fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(hp_units, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a RandomSearch tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',  # Hyperparameter optimization goal\n",
    "    max_trials=100,             # Number of trials (random combinations of hyperparameters)\n",
    "    directory='random_search', # Directory to save results\n",
    "    project_name='cnn_tuning'  # Name of the tuning project\n",
    ")\n",
    "\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, Y_train_binary, epochs=20, validation_split=0.2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the final model with the best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "#display the best model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c86ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 1s 8ms/step - loss: 0.6961 - accuracy: 0.4878\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.6929 - accuracy: 0.5197\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.6925 - accuracy: 0.5141\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.5178\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.6899 - accuracy: 0.5347\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.6840 - accuracy: 0.6116\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.6700 - accuracy: 0.6285\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.6335 - accuracy: 0.6529\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5875 - accuracy: 0.6961\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5591 - accuracy: 0.7542\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5394 - accuracy: 0.7542\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5219 - accuracy: 0.7580\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4849 - accuracy: 0.7842\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.7861\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.7936\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.7992\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4544 - accuracy: 0.7899\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.8049\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.8086\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.8218\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8068\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4017 - accuracy: 0.8124\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8124\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8180\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.8274\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.8274\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3816 - accuracy: 0.8349\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3694 - accuracy: 0.8349\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3621 - accuracy: 0.8424\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3639 - accuracy: 0.8518\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.8424\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3605 - accuracy: 0.8537\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3599 - accuracy: 0.8574\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3470 - accuracy: 0.8593\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3366 - accuracy: 0.8668\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.8630\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8668\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3294 - accuracy: 0.8687\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3159 - accuracy: 0.8743\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3231 - accuracy: 0.8705\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3383 - accuracy: 0.8462\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.8612\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2982 - accuracy: 0.8837\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2964 - accuracy: 0.8912\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2960 - accuracy: 0.8705\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2943 - accuracy: 0.8874\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2967 - accuracy: 0.8799\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2855 - accuracy: 0.8874\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2802 - accuracy: 0.8874\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2759 - accuracy: 0.8893\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2634 - accuracy: 0.9006\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2697 - accuracy: 0.8893\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2693 - accuracy: 0.8856\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2870 - accuracy: 0.8799\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2725 - accuracy: 0.8837\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2399 - accuracy: 0.9137\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2342 - accuracy: 0.9231\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2275 - accuracy: 0.9193\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2373 - accuracy: 0.9156\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2397 - accuracy: 0.9118\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2334 - accuracy: 0.9099\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2209 - accuracy: 0.9212\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.9193\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2295 - accuracy: 0.9081\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2108 - accuracy: 0.9287\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2164 - accuracy: 0.9099\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2091 - accuracy: 0.9268\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2123 - accuracy: 0.9156\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2013 - accuracy: 0.9268\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1969 - accuracy: 0.9325\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2260 - accuracy: 0.9156\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1996 - accuracy: 0.9381\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2035 - accuracy: 0.9287\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1827 - accuracy: 0.9362\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1735 - accuracy: 0.9437\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1744 - accuracy: 0.9400\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.9531\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.9437\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1616 - accuracy: 0.9493\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1654 - accuracy: 0.9475\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.9550\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1522 - accuracy: 0.9550\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.9493\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 0.9531\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1806 - accuracy: 0.9381\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1508 - accuracy: 0.9568\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1581 - accuracy: 0.9400\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1494 - accuracy: 0.9456\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1452 - accuracy: 0.9587\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.9437\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9662\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1378 - accuracy: 0.9550\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1230 - accuracy: 0.9662\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1377 - accuracy: 0.9512\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1273 - accuracy: 0.9681\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1171 - accuracy: 0.9681\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1201 - accuracy: 0.9568\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1205 - accuracy: 0.9625\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1277 - accuracy: 0.9606\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 0.9456\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1379 - accuracy: 0.9550\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "[[106 121]\n",
      " [ 29 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4670    0.7852    0.5856       135\n",
      "           1     0.8187    0.5198    0.6359       252\n",
      "\n",
      "    accuracy                         0.6124       387\n",
      "   macro avg     0.6429    0.6525    0.6108       387\n",
      "weighted avg     0.6960    0.6124    0.6184       387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "best_model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = best_model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f6bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
