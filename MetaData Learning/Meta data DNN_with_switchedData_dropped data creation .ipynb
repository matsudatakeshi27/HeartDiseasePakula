{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b1ee0e",
   "metadata": {},
   "source": [
    "# DNN metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3360ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_train=pd.read_csv('cle_metadata_dnn_train.csv')\n",
    "cle_test=pd.read_csv('cle_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b8fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train=pd.read_csv('vir_metadata_dnn_train.csv' )\n",
    "vir_test=pd.read_csv('vir_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92518ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train=pd.read_csv('hun_metadata_dnn_train.csv' )\n",
    "hun_test=pd.read_csv('hun_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe3741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_train=pd.read_csv('swi_metadata_dnn_train.csv' )\n",
    "swi_test=pd.read_csv('swi_metadata_dnn_test.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e16fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.concat([cle_train,vir_train,hun_train])\n",
    "Test = pd.concat([cle_test,vir_test,hun_test,swi_test,swi_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a819bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train.iloc[:,:-1]\n",
    "X_test = Test.iloc[:,:-1]\n",
    "\n",
    "y_train = Train.iloc[:,-1]\n",
    "y_test = Test.iloc[:,-1]\n",
    "\n",
    "Y_train_binary = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "Y_test_binary = y_test.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0a875",
   "metadata": {},
   "source": [
    "# get rid of swi columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43269e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.482027</td>\n",
       "      <td>0.499887</td>\n",
       "      <td>0.530806</td>\n",
       "      <td>0.538419</td>\n",
       "      <td>0.491713</td>\n",
       "      <td>0.513956</td>\n",
       "      <td>0.498010</td>\n",
       "      <td>0.488720</td>\n",
       "      <td>0.489319</td>\n",
       "      <td>0.541717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456004</td>\n",
       "      <td>0.549547</td>\n",
       "      <td>0.518709</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.519562</td>\n",
       "      <td>0.484019</td>\n",
       "      <td>0.472015</td>\n",
       "      <td>0.508887</td>\n",
       "      <td>0.467478</td>\n",
       "      <td>0.486530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.454859</td>\n",
       "      <td>0.529616</td>\n",
       "      <td>0.526296</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.496266</td>\n",
       "      <td>0.510415</td>\n",
       "      <td>0.484137</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>0.496896</td>\n",
       "      <td>0.540834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477837</td>\n",
       "      <td>0.488366</td>\n",
       "      <td>0.493662</td>\n",
       "      <td>0.497254</td>\n",
       "      <td>0.565816</td>\n",
       "      <td>0.497960</td>\n",
       "      <td>0.456738</td>\n",
       "      <td>0.500947</td>\n",
       "      <td>0.496931</td>\n",
       "      <td>0.517806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463892</td>\n",
       "      <td>0.528533</td>\n",
       "      <td>0.529637</td>\n",
       "      <td>0.528451</td>\n",
       "      <td>0.506440</td>\n",
       "      <td>0.525559</td>\n",
       "      <td>0.475964</td>\n",
       "      <td>0.484750</td>\n",
       "      <td>0.524651</td>\n",
       "      <td>0.529517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476820</td>\n",
       "      <td>0.499960</td>\n",
       "      <td>0.477971</td>\n",
       "      <td>0.530497</td>\n",
       "      <td>0.613168</td>\n",
       "      <td>0.473111</td>\n",
       "      <td>0.434871</td>\n",
       "      <td>0.508940</td>\n",
       "      <td>0.505146</td>\n",
       "      <td>0.497114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487112</td>\n",
       "      <td>0.502789</td>\n",
       "      <td>0.547796</td>\n",
       "      <td>0.545979</td>\n",
       "      <td>0.500581</td>\n",
       "      <td>0.501580</td>\n",
       "      <td>0.497734</td>\n",
       "      <td>0.493490</td>\n",
       "      <td>0.481571</td>\n",
       "      <td>0.520887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467420</td>\n",
       "      <td>0.523350</td>\n",
       "      <td>0.508465</td>\n",
       "      <td>0.497361</td>\n",
       "      <td>0.530505</td>\n",
       "      <td>0.484081</td>\n",
       "      <td>0.486503</td>\n",
       "      <td>0.484897</td>\n",
       "      <td>0.458825</td>\n",
       "      <td>0.480811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.487966</td>\n",
       "      <td>0.502613</td>\n",
       "      <td>0.530262</td>\n",
       "      <td>0.509978</td>\n",
       "      <td>0.498579</td>\n",
       "      <td>0.490217</td>\n",
       "      <td>0.480382</td>\n",
       "      <td>0.510005</td>\n",
       "      <td>0.498182</td>\n",
       "      <td>0.530342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497544</td>\n",
       "      <td>0.513097</td>\n",
       "      <td>0.488849</td>\n",
       "      <td>0.503623</td>\n",
       "      <td>0.556923</td>\n",
       "      <td>0.495072</td>\n",
       "      <td>0.435286</td>\n",
       "      <td>0.503057</td>\n",
       "      <td>0.478725</td>\n",
       "      <td>0.497577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.483704</td>\n",
       "      <td>0.504237</td>\n",
       "      <td>0.479324</td>\n",
       "      <td>0.476369</td>\n",
       "      <td>0.498507</td>\n",
       "      <td>0.506080</td>\n",
       "      <td>0.533774</td>\n",
       "      <td>0.483517</td>\n",
       "      <td>0.510733</td>\n",
       "      <td>0.496863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516407</td>\n",
       "      <td>0.483216</td>\n",
       "      <td>0.524806</td>\n",
       "      <td>0.516051</td>\n",
       "      <td>0.522063</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.507316</td>\n",
       "      <td>0.535838</td>\n",
       "      <td>0.534950</td>\n",
       "      <td>0.464300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.490108</td>\n",
       "      <td>0.492367</td>\n",
       "      <td>0.488563</td>\n",
       "      <td>0.487793</td>\n",
       "      <td>0.495198</td>\n",
       "      <td>0.502775</td>\n",
       "      <td>0.517487</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.509056</td>\n",
       "      <td>0.507079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493095</td>\n",
       "      <td>0.480466</td>\n",
       "      <td>0.526394</td>\n",
       "      <td>0.524396</td>\n",
       "      <td>0.544080</td>\n",
       "      <td>0.490351</td>\n",
       "      <td>0.515740</td>\n",
       "      <td>0.517255</td>\n",
       "      <td>0.547517</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.483685</td>\n",
       "      <td>0.498613</td>\n",
       "      <td>0.478604</td>\n",
       "      <td>0.487754</td>\n",
       "      <td>0.510728</td>\n",
       "      <td>0.487946</td>\n",
       "      <td>0.529723</td>\n",
       "      <td>0.493159</td>\n",
       "      <td>0.498613</td>\n",
       "      <td>0.495365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489138</td>\n",
       "      <td>0.522639</td>\n",
       "      <td>0.530010</td>\n",
       "      <td>0.516468</td>\n",
       "      <td>0.533154</td>\n",
       "      <td>0.477123</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.522138</td>\n",
       "      <td>0.539904</td>\n",
       "      <td>0.508322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.476345</td>\n",
       "      <td>0.496224</td>\n",
       "      <td>0.485959</td>\n",
       "      <td>0.488809</td>\n",
       "      <td>0.503595</td>\n",
       "      <td>0.518979</td>\n",
       "      <td>0.520347</td>\n",
       "      <td>0.491363</td>\n",
       "      <td>0.499720</td>\n",
       "      <td>0.511617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497776</td>\n",
       "      <td>0.501086</td>\n",
       "      <td>0.517439</td>\n",
       "      <td>0.512927</td>\n",
       "      <td>0.525908</td>\n",
       "      <td>0.490491</td>\n",
       "      <td>0.506457</td>\n",
       "      <td>0.526181</td>\n",
       "      <td>0.510480</td>\n",
       "      <td>0.513963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.490297</td>\n",
       "      <td>0.497950</td>\n",
       "      <td>0.473245</td>\n",
       "      <td>0.498749</td>\n",
       "      <td>0.507454</td>\n",
       "      <td>0.481953</td>\n",
       "      <td>0.528355</td>\n",
       "      <td>0.495543</td>\n",
       "      <td>0.491902</td>\n",
       "      <td>0.507735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493537</td>\n",
       "      <td>0.515256</td>\n",
       "      <td>0.532098</td>\n",
       "      <td>0.525226</td>\n",
       "      <td>0.531579</td>\n",
       "      <td>0.467642</td>\n",
       "      <td>0.509273</td>\n",
       "      <td>0.514771</td>\n",
       "      <td>0.511319</td>\n",
       "      <td>0.514755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.482027  0.499887  0.530806  0.538419  0.491713  0.513956  0.498010   \n",
       "1    0.454859  0.529616  0.526296  0.552197  0.496266  0.510415  0.484137   \n",
       "2    0.463892  0.528533  0.529637  0.528451  0.506440  0.525559  0.475964   \n",
       "3    0.487112  0.502789  0.547796  0.545979  0.500581  0.501580  0.497734   \n",
       "4    0.487966  0.502613  0.530262  0.509978  0.498579  0.490217  0.480382   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.483704  0.504237  0.479324  0.476369  0.498507  0.506080  0.533774   \n",
       "196  0.490108  0.492367  0.488563  0.487793  0.495198  0.502775  0.517487   \n",
       "197  0.483685  0.498613  0.478604  0.487754  0.510728  0.487946  0.529723   \n",
       "198  0.476345  0.496224  0.485959  0.488809  0.503595  0.518979  0.520347   \n",
       "199  0.490297  0.497950  0.473245  0.498749  0.507454  0.481953  0.528355   \n",
       "\n",
       "            7         8         9  ...       6.2       7.2       8.2  \\\n",
       "0    0.488720  0.489319  0.541717  ...  0.456004  0.549547  0.518709   \n",
       "1    0.507131  0.496896  0.540834  ...  0.477837  0.488366  0.493662   \n",
       "2    0.484750  0.524651  0.529517  ...  0.476820  0.499960  0.477971   \n",
       "3    0.493490  0.481571  0.520887  ...  0.467420  0.523350  0.508465   \n",
       "4    0.510005  0.498182  0.530342  ...  0.497544  0.513097  0.488849   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "195  0.483517  0.510733  0.496863  ...  0.516407  0.483216  0.524806   \n",
       "196  0.500597  0.509056  0.507079  ...  0.493095  0.480466  0.526394   \n",
       "197  0.493159  0.498613  0.495365  ...  0.489138  0.522639  0.530010   \n",
       "198  0.491363  0.499720  0.511617  ...  0.497776  0.501086  0.517439   \n",
       "199  0.495543  0.491902  0.507735  ...  0.493537  0.515256  0.532098   \n",
       "\n",
       "          9.2      10.2      11.2      12.2      13.2      14.2      15.2  \n",
       "0    0.493687  0.519562  0.484019  0.472015  0.508887  0.467478  0.486530  \n",
       "1    0.497254  0.565816  0.497960  0.456738  0.500947  0.496931  0.517806  \n",
       "2    0.530497  0.613168  0.473111  0.434871  0.508940  0.505146  0.497114  \n",
       "3    0.497361  0.530505  0.484081  0.486503  0.484897  0.458825  0.480811  \n",
       "4    0.503623  0.556923  0.495072  0.435286  0.503057  0.478725  0.497577  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "195  0.516051  0.522063  0.520908  0.507316  0.535838  0.534950  0.464300  \n",
       "196  0.524396  0.544080  0.490351  0.515740  0.517255  0.547517  0.485666  \n",
       "197  0.516468  0.533154  0.477123  0.505441  0.522138  0.539904  0.508322  \n",
       "198  0.512927  0.525908  0.490491  0.506457  0.526181  0.510480  0.513963  \n",
       "199  0.525226  0.531579  0.467642  0.509273  0.514771  0.511319  0.514755  \n",
       "\n",
       "[548 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.iloc[:,:-16]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3d3c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6.2</th>\n",
       "      <th>7.2</th>\n",
       "      <th>8.2</th>\n",
       "      <th>9.2</th>\n",
       "      <th>10.2</th>\n",
       "      <th>11.2</th>\n",
       "      <th>12.2</th>\n",
       "      <th>13.2</th>\n",
       "      <th>14.2</th>\n",
       "      <th>15.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428787</td>\n",
       "      <td>0.525325</td>\n",
       "      <td>0.542139</td>\n",
       "      <td>0.478648</td>\n",
       "      <td>0.506824</td>\n",
       "      <td>0.490862</td>\n",
       "      <td>0.482278</td>\n",
       "      <td>0.505213</td>\n",
       "      <td>0.516506</td>\n",
       "      <td>0.520210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469042</td>\n",
       "      <td>0.494732</td>\n",
       "      <td>0.483015</td>\n",
       "      <td>0.492952</td>\n",
       "      <td>0.539282</td>\n",
       "      <td>0.433638</td>\n",
       "      <td>0.487028</td>\n",
       "      <td>0.496327</td>\n",
       "      <td>0.451854</td>\n",
       "      <td>0.460499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444054</td>\n",
       "      <td>0.518033</td>\n",
       "      <td>0.532847</td>\n",
       "      <td>0.527710</td>\n",
       "      <td>0.511543</td>\n",
       "      <td>0.505929</td>\n",
       "      <td>0.505096</td>\n",
       "      <td>0.473268</td>\n",
       "      <td>0.500194</td>\n",
       "      <td>0.563858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462495</td>\n",
       "      <td>0.520767</td>\n",
       "      <td>0.514996</td>\n",
       "      <td>0.479704</td>\n",
       "      <td>0.547857</td>\n",
       "      <td>0.469282</td>\n",
       "      <td>0.477678</td>\n",
       "      <td>0.534086</td>\n",
       "      <td>0.459659</td>\n",
       "      <td>0.482997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.464015</td>\n",
       "      <td>0.547513</td>\n",
       "      <td>0.534929</td>\n",
       "      <td>0.515994</td>\n",
       "      <td>0.526294</td>\n",
       "      <td>0.519013</td>\n",
       "      <td>0.493227</td>\n",
       "      <td>0.487353</td>\n",
       "      <td>0.533328</td>\n",
       "      <td>0.515880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485028</td>\n",
       "      <td>0.492818</td>\n",
       "      <td>0.466966</td>\n",
       "      <td>0.514667</td>\n",
       "      <td>0.588129</td>\n",
       "      <td>0.480854</td>\n",
       "      <td>0.432877</td>\n",
       "      <td>0.501815</td>\n",
       "      <td>0.507247</td>\n",
       "      <td>0.502260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464099</td>\n",
       "      <td>0.502493</td>\n",
       "      <td>0.530403</td>\n",
       "      <td>0.543423</td>\n",
       "      <td>0.488266</td>\n",
       "      <td>0.506906</td>\n",
       "      <td>0.496008</td>\n",
       "      <td>0.470768</td>\n",
       "      <td>0.488893</td>\n",
       "      <td>0.567098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449605</td>\n",
       "      <td>0.551441</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>0.478567</td>\n",
       "      <td>0.537422</td>\n",
       "      <td>0.471184</td>\n",
       "      <td>0.465805</td>\n",
       "      <td>0.508096</td>\n",
       "      <td>0.466514</td>\n",
       "      <td>0.465507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451514</td>\n",
       "      <td>0.539376</td>\n",
       "      <td>0.544900</td>\n",
       "      <td>0.502148</td>\n",
       "      <td>0.503703</td>\n",
       "      <td>0.533397</td>\n",
       "      <td>0.448659</td>\n",
       "      <td>0.478863</td>\n",
       "      <td>0.508552</td>\n",
       "      <td>0.546285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482086</td>\n",
       "      <td>0.511703</td>\n",
       "      <td>0.477694</td>\n",
       "      <td>0.494675</td>\n",
       "      <td>0.542177</td>\n",
       "      <td>0.473592</td>\n",
       "      <td>0.467832</td>\n",
       "      <td>0.478610</td>\n",
       "      <td>0.443659</td>\n",
       "      <td>0.481261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.499596</td>\n",
       "      <td>0.503362</td>\n",
       "      <td>0.522893</td>\n",
       "      <td>0.496161</td>\n",
       "      <td>0.543045</td>\n",
       "      <td>0.461692</td>\n",
       "      <td>0.509040</td>\n",
       "      <td>0.502430</td>\n",
       "      <td>0.476613</td>\n",
       "      <td>0.537732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515923</td>\n",
       "      <td>0.500189</td>\n",
       "      <td>0.543489</td>\n",
       "      <td>0.511016</td>\n",
       "      <td>0.494478</td>\n",
       "      <td>0.466297</td>\n",
       "      <td>0.458757</td>\n",
       "      <td>0.538558</td>\n",
       "      <td>0.475912</td>\n",
       "      <td>0.485755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.497214</td>\n",
       "      <td>0.491898</td>\n",
       "      <td>0.538590</td>\n",
       "      <td>0.533611</td>\n",
       "      <td>0.515420</td>\n",
       "      <td>0.481304</td>\n",
       "      <td>0.514259</td>\n",
       "      <td>0.486543</td>\n",
       "      <td>0.492588</td>\n",
       "      <td>0.514609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538429</td>\n",
       "      <td>0.494881</td>\n",
       "      <td>0.531248</td>\n",
       "      <td>0.523854</td>\n",
       "      <td>0.466190</td>\n",
       "      <td>0.529339</td>\n",
       "      <td>0.471890</td>\n",
       "      <td>0.531397</td>\n",
       "      <td>0.437475</td>\n",
       "      <td>0.486962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.517050</td>\n",
       "      <td>0.514450</td>\n",
       "      <td>0.509608</td>\n",
       "      <td>0.503844</td>\n",
       "      <td>0.533506</td>\n",
       "      <td>0.505198</td>\n",
       "      <td>0.480254</td>\n",
       "      <td>0.489807</td>\n",
       "      <td>0.471894</td>\n",
       "      <td>0.506556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523795</td>\n",
       "      <td>0.467489</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.530422</td>\n",
       "      <td>0.487560</td>\n",
       "      <td>0.493201</td>\n",
       "      <td>0.484776</td>\n",
       "      <td>0.545881</td>\n",
       "      <td>0.466940</td>\n",
       "      <td>0.477744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.525592</td>\n",
       "      <td>0.497026</td>\n",
       "      <td>0.542631</td>\n",
       "      <td>0.507730</td>\n",
       "      <td>0.521060</td>\n",
       "      <td>0.475272</td>\n",
       "      <td>0.506918</td>\n",
       "      <td>0.474250</td>\n",
       "      <td>0.486505</td>\n",
       "      <td>0.510403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519751</td>\n",
       "      <td>0.510182</td>\n",
       "      <td>0.530916</td>\n",
       "      <td>0.509050</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.491346</td>\n",
       "      <td>0.493666</td>\n",
       "      <td>0.532326</td>\n",
       "      <td>0.481168</td>\n",
       "      <td>0.488967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.521995</td>\n",
       "      <td>0.499324</td>\n",
       "      <td>0.531584</td>\n",
       "      <td>0.508733</td>\n",
       "      <td>0.551871</td>\n",
       "      <td>0.488382</td>\n",
       "      <td>0.494927</td>\n",
       "      <td>0.486490</td>\n",
       "      <td>0.486524</td>\n",
       "      <td>0.511331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525063</td>\n",
       "      <td>0.488777</td>\n",
       "      <td>0.522951</td>\n",
       "      <td>0.528720</td>\n",
       "      <td>0.499248</td>\n",
       "      <td>0.509396</td>\n",
       "      <td>0.497447</td>\n",
       "      <td>0.546639</td>\n",
       "      <td>0.460442</td>\n",
       "      <td>0.474039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.428787  0.525325  0.542139  0.478648  0.506824  0.490862  0.482278   \n",
       "1   0.444054  0.518033  0.532847  0.527710  0.511543  0.505929  0.505096   \n",
       "2   0.464015  0.547513  0.534929  0.515994  0.526294  0.519013  0.493227   \n",
       "3   0.464099  0.502493  0.530403  0.543423  0.488266  0.506906  0.496008   \n",
       "4   0.451514  0.539376  0.544900  0.502148  0.503703  0.533397  0.448659   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.499596  0.503362  0.522893  0.496161  0.543045  0.461692  0.509040   \n",
       "78  0.497214  0.491898  0.538590  0.533611  0.515420  0.481304  0.514259   \n",
       "79  0.517050  0.514450  0.509608  0.503844  0.533506  0.505198  0.480254   \n",
       "80  0.525592  0.497026  0.542631  0.507730  0.521060  0.475272  0.506918   \n",
       "81  0.521995  0.499324  0.531584  0.508733  0.551871  0.488382  0.494927   \n",
       "\n",
       "           7         8         9  ...       6.2       7.2       8.2       9.2  \\\n",
       "0   0.505213  0.516506  0.520210  ...  0.469042  0.494732  0.483015  0.492952   \n",
       "1   0.473268  0.500194  0.563858  ...  0.462495  0.520767  0.514996  0.479704   \n",
       "2   0.487353  0.533328  0.515880  ...  0.485028  0.492818  0.466966  0.514667   \n",
       "3   0.470768  0.488893  0.567098  ...  0.449605  0.551441  0.525775  0.478567   \n",
       "4   0.478863  0.508552  0.546285  ...  0.482086  0.511703  0.477694  0.494675   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "77  0.502430  0.476613  0.537732  ...  0.515923  0.500189  0.543489  0.511016   \n",
       "78  0.486543  0.492588  0.514609  ...  0.538429  0.494881  0.531248  0.523854   \n",
       "79  0.489807  0.471894  0.506556  ...  0.523795  0.467489  0.512300  0.530422   \n",
       "80  0.474250  0.486505  0.510403  ...  0.519751  0.510182  0.530916  0.509050   \n",
       "81  0.486490  0.486524  0.511331  ...  0.525063  0.488777  0.522951  0.528720   \n",
       "\n",
       "        10.2      11.2      12.2      13.2      14.2      15.2  \n",
       "0   0.539282  0.433638  0.487028  0.496327  0.451854  0.460499  \n",
       "1   0.547857  0.469282  0.477678  0.534086  0.459659  0.482997  \n",
       "2   0.588129  0.480854  0.432877  0.501815  0.507247  0.502260  \n",
       "3   0.537422  0.471184  0.465805  0.508096  0.466514  0.465507  \n",
       "4   0.542177  0.473592  0.467832  0.478610  0.443659  0.481261  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "77  0.494478  0.466297  0.458757  0.538558  0.475912  0.485755  \n",
       "78  0.466190  0.529339  0.471890  0.531397  0.437475  0.486962  \n",
       "79  0.487560  0.493201  0.484776  0.545881  0.466940  0.477744  \n",
       "80  0.477800  0.491346  0.493666  0.532326  0.481168  0.488967  \n",
       "81  0.499248  0.509396  0.497447  0.546639  0.460442  0.474039  \n",
       "\n",
       "[372 rows x 48 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.iloc[:,:-16]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3016ecb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cle_train_temp = cle_train.iloc[:,:-17]\n",
    "cle_train_Y = cle_train.iloc[:,-1]\n",
    "cle_train = pd.concat([cle_train_temp, cle_train_Y], axis=1)\n",
    "cle_train.to_csv('cle_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0fd515",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_train_temp = vir_train.iloc[:,:-17]\n",
    "vir_train_Y = vir_train.iloc[:,-1]\n",
    "vir_train = pd.concat([vir_train_temp, vir_train_Y], axis=1)\n",
    "vir_train.to_csv('vir_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad66556",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_train_temp = hun_train.iloc[:,:-17]\n",
    "hun_train_Y = hun_train.iloc[:,-1]\n",
    "hun_train = pd.concat([hun_train_temp, hun_train_Y], axis=1)\n",
    "hun_train.to_csv('hun_metadata_dnn_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e852ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle_test_temp = cle_test.iloc[:,:-17]\n",
    "cle_test_Y = cle_test.iloc[:,-1]\n",
    "cle_test = pd.concat([cle_test_temp, cle_test_Y], axis=1)\n",
    "cle_test.to_csv('cle_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9041c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vir_test_temp = vir_test.iloc[:,:-17]\n",
    "vir_test_Y = vir_test.iloc[:,-1]\n",
    "vir_test = pd.concat([vir_test_temp, vir_test_Y], axis=1)\n",
    "vir_test.to_csv('vir_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4764f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hun_test_temp = hun_test.iloc[:,:-17]\n",
    "hun_test_Y = hun_test.iloc[:,-1]\n",
    "hun_test = pd.concat([hun_test_temp, hun_test_Y], axis=1)\n",
    "hun_test.to_csv('hun_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd79e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_test_new = pd.concat([swi_train, swi_test])\n",
    "\n",
    "swi_test_temp = swi_test_new.iloc[:,:-17]\n",
    "swi_test_Y = swi_test_new.iloc[:,-1]\n",
    "swi_test = pd.concat([swi_test_temp, swi_test_Y], axis=1)\n",
    "swi_test.to_csv('swi_metadata_dnn_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55a9da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for deep learning testing\n",
    "def Test(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "    \n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e623e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c86ca29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.6947 - accuracy: 0.5255\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.6962 - accuracy: 0.5255\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.6928 - accuracy: 0.5255\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.6923 - accuracy: 0.5255\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.6921 - accuracy: 0.5255\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.6919 - accuracy: 0.5255\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.6919 - accuracy: 0.5255\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.6917 - accuracy: 0.5255\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.6927 - accuracy: 0.5255\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.6921 - accuracy: 0.5255\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.6911 - accuracy: 0.5255\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.6920 - accuracy: 0.5292\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.6820 - accuracy: 0.5566\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.6581 - accuracy: 0.6204\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.6024 - accuracy: 0.7026\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.5530 - accuracy: 0.7336\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.5304 - accuracy: 0.7573\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.5504 - accuracy: 0.7464\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.5363 - accuracy: 0.7573\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4986 - accuracy: 0.7719\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4883 - accuracy: 0.7755\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4676 - accuracy: 0.7883\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4828 - accuracy: 0.7828\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4788 - accuracy: 0.7828\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4599 - accuracy: 0.7938\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4663 - accuracy: 0.7883\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4629 - accuracy: 0.7719\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4483 - accuracy: 0.7828\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4497 - accuracy: 0.7974\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4601 - accuracy: 0.7901\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4406 - accuracy: 0.7974\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4347 - accuracy: 0.8139\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4435 - accuracy: 0.8084\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4279 - accuracy: 0.8120\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4317 - accuracy: 0.8029\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4323 - accuracy: 0.8175\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4119 - accuracy: 0.8394\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4136 - accuracy: 0.8285\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4057 - accuracy: 0.8230\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4063 - accuracy: 0.8193\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4093 - accuracy: 0.8193\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4000 - accuracy: 0.8303\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.3930 - accuracy: 0.8412\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.4235 - accuracy: 0.8157\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4505 - accuracy: 0.8066\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4322 - accuracy: 0.7956\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.4156 - accuracy: 0.8193\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4045 - accuracy: 0.8266\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "[[ 96 136]\n",
      " [ 27 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4138    0.7805    0.5408       123\n",
      "           1     0.8071    0.4538    0.5810       249\n",
      "\n",
      "    accuracy                         0.5618       372\n",
      "   macro avg     0.6105    0.6172    0.5609       372\n",
      "weighted avg     0.6771    0.5618    0.5677       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(48,1)))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/DNNMeta_CNN_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bf045",
   "metadata": {},
   "source": [
    "# Test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_dnn_train.csv'\n",
    "path_test = 'cle_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_dnn_train.csv'\n",
    "path_test = 'vir_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_dnn_train.csv'\n",
    "path_test = 'hun_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_dnn_train.csv'\n",
    "path_test = 'swi_metadata_dnn_test.csv'\n",
    "model = '../Models/Meta_Only/DNNMeta_CNN_test.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ee9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779d148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = \n",
    "X_test = \n",
    "Y_train_binary = \n",
    "Y_test_binary = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad0813f",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fddd185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.7106 - accuracy: 0.4945\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6920 - accuracy: 0.5292\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6910 - accuracy: 0.5182\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6911 - accuracy: 0.5055\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6861 - accuracy: 0.5456\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6841 - accuracy: 0.6113\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6934 - accuracy: 0.5310\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.7002 - accuracy: 0.5255\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6864 - accuracy: 0.5657\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6835 - accuracy: 0.5401\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6892 - accuracy: 0.5182\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6775 - accuracy: 0.5620\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6836 - accuracy: 0.5474\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6740 - accuracy: 0.5912\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6727 - accuracy: 0.5839\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.6567 - accuracy: 0.6405\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6684 - accuracy: 0.5912\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6624 - accuracy: 0.6004\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6653 - accuracy: 0.5912\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6630 - accuracy: 0.5803\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6432 - accuracy: 0.6515\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6850 - accuracy: 0.5876\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6653 - accuracy: 0.6077\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6475 - accuracy: 0.6697\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6306 - accuracy: 0.6460\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6280 - accuracy: 0.6496\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.7067 - accuracy: 0.5620\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6613 - accuracy: 0.5894\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.6511 - accuracy: 0.6405\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6393 - accuracy: 0.6442\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.6398 - accuracy: 0.6423\n",
      "12/12 [==============================] - 0s 545us/step\n",
      "[[ 38  30]\n",
      " [ 85 219]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5588    0.3089    0.3979       123\n",
      "           1     0.7204    0.8795    0.7920       249\n",
      "\n",
      "    accuracy                         0.6909       372\n",
      "   macro avg     0.6396    0.5942    0.5950       372\n",
      "weighted avg     0.6670    0.6909    0.6617       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(48,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_DNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a844",
   "metadata": {},
   "source": [
    "# test on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_DNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12522ce3",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "880e0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e78c2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 4s 31ms/step - loss: 0.6837 - accuracy: 0.5511\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6725 - accuracy: 0.5566\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.6516 - accuracy: 0.6004\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.6282 - accuracy: 0.6697\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.7023 - accuracy: 0.5347\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6890 - accuracy: 0.5328\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6684 - accuracy: 0.5949\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.6395 - accuracy: 0.6606\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5876 - accuracy: 0.7153\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5735 - accuracy: 0.6971\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5532 - accuracy: 0.6934\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5332 - accuracy: 0.7427\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.5512 - accuracy: 0.7226\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.4935 - accuracy: 0.7719\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.4789 - accuracy: 0.7792\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5473 - accuracy: 0.7591\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 1s 50ms/step - loss: 0.5308 - accuracy: 0.7591\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.5130 - accuracy: 0.7664\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5140 - accuracy: 0.7573\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.5298 - accuracy: 0.7409\n",
      "[[ 98 224]\n",
      " [ 30 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3043    0.7656    0.4356       128\n",
      "           1     0.7727    0.3129    0.4454       326\n",
      "\n",
      "    accuracy                         0.4405       454\n",
      "   macro avg     0.5385    0.5393    0.4405       454\n",
      "weighted avg     0.6407    0.4405    0.4426       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, return_sequences=True, input_shape=(48, 1)))\n",
    "model.add(SimpleRNN(units=32, return_sequences=True))\n",
    "model.add(SimpleRNN(units=16))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train_binary, epochs=1000, batch_size=32,callbacks=[callback])\n",
    "Y_pred = model.predict(X_test).argmax(axis=1)\n",
    "    \n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedaab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Meta_Only/CNNMeta_RNN_dropswi.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fae7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_Only/CNNMeta_RNN_dropswi.h5'\n",
    "Test(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812110c",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bde29",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61dc493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2175bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is:\n",
      "[[ 82  43]\n",
      " [ 46 283]]\n",
      "Accuracy is : 0.8039647577092511\n",
      "Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65       128\n",
      "           1       0.86      0.87      0.86       326\n",
      "\n",
      "    accuracy                           0.80       454\n",
      "   macro avg       0.76      0.75      0.76       454\n",
      "weighted avg       0.80      0.80      0.80       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# decision tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_train, Y_train_binary)\n",
    "Y_predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(Y_predictions, Y_test_binary)\n",
    "print(\"Confusion Matrix is:\")\n",
    "print(cm)\n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "print(\"Accuracy is : \" + str(accuracy(cm)))\n",
    "    \n",
    "print(\"Report\")\n",
    "print(classification_report(Y_test_binary, Y_predictions))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d529c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save clf model\n",
    "from joblib import dump, load\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_dt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08cf24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for Decision tree, and random forest testing\n",
    "def Test_DT(path_train,path_test,model_name):\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    model = load(model_name)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test_binary, Y_pred, digits=4))\n",
    "    \n",
    "    mismatch = [i for i, (a,b) in enumerate(zip(Y_pred, Y_test_binary)) if a != b]\n",
    "    print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for decision tree\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_dt.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f058a8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dee5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e9459fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103 185]\n",
      " [ 25 141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3576    0.8047    0.4952       128\n",
      "           1     0.8494    0.4325    0.5732       326\n",
      "\n",
      "    accuracy                         0.5374       454\n",
      "   macro avg     0.6035    0.6186    0.5342       454\n",
      "weighted avg     0.7108    0.5374    0.5512       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred,digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(classifier, '../Models/Meta_only/CNNMeta_rf_9005.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49633d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for Random Forest\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_rf_9005.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511e046",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb18996",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train_binary.values.ravel())\n",
    "y_pred = svc.predict(X_test)\n",
    "print(confusion_matrix(Y_test_binary, y_pred))\n",
    "print(classification_report(Y_test_binary, y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svc, \"../Models/Meta_only/CNNMeta_svm_8978.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on each dataset for SVM\n",
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_svm_8978.pkl'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26593df9",
   "metadata": {},
   "source": [
    "# Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a7abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, Y_train_binary)\n",
    "Y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(Y_pred, Y_test_binary)\n",
    "print(cm)\n",
    "print(classification_report(Y_test_binary, Y_pred, digits = 4))\n",
    "\n",
    "dump(clf, '../Models/Meta_only/CNNMeta_NB_dropswi.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cle test\")\n",
    "path_train = 'cle_metadata_cnn_train.csv'\n",
    "path_test = 'cle_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "print(\"vir test\")\n",
    "path_train = 'vir_metadata_cnn_train.csv'\n",
    "path_test = 'vir_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"hun test\")\n",
    "path_train = 'hun_metadata_cnn_train.csv'\n",
    "path_test = 'hun_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)\n",
    "\n",
    "print(\"==================\")\n",
    "print(\"swi test\")\n",
    "path_train = 'swi_metadata_cnn_train.csv'\n",
    "path_test = 'swi_metadata_cnn_test.csv'\n",
    "model = '../Models/Meta_only/CNNMeta_NB_dropswi.joblib'\n",
    "Test_DT(path_train,path_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2670c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD:MetaData Learning/Meta data DNN improve underrepresented data - Drop Switzerland .ipynb
   "version": "3.9.12"
=======
   "version": "3.9.16"
>>>>>>> 21a611729e2bbb4c4fa528c375b5b6e0c5014494:MetaData Learning/Meta data DNN_with_switchedData_dropped data creation .ipynb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
