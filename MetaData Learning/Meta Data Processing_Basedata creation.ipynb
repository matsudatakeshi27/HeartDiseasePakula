{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a140d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1470c377",
   "metadata": {},
   "source": [
    "# CNN meta data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfb1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wholeData(path_train,path_test):\n",
    "    #Split the data\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "    \n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "    \n",
    "    X_entire = pd.concat([X_train,X_test])\n",
    "    Y_entire = pd.concat([Y_train,Y_test])\n",
    "    return X_entire,Y_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c2ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl(path_train, path_test):\n",
    "    #Split the data\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    list = [\"cle_cnn.h5\", \"vir_cnn.h5\", \"hun_cnn.h5\", \"swi_cnn.h5\"]\n",
    "    output = pd.DataFrame()\n",
    "    for i in list:\n",
    "        model = tf.keras.models.load_model('../Models/CNN_only/' + i)\n",
    "        model2 = Sequential()\n",
    "        model2.add(Conv1D(filters=256, kernel_size=3, activation='relu', input_shape=(22,1)))\n",
    "        model2.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "        model2.add(Conv1D(filters=512, kernel_size=3, activation='relu'))\n",
    "        model2.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "        model2.add(Flatten())\n",
    "        model2.add(Dense(16, activation='relu'))\n",
    "\n",
    "        model2.set_weights(model.get_weights()[:-2]) \n",
    "\n",
    "        model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        X_entire,labels = wholeData(path_train,path_test)\n",
    "\n",
    "        Y_predictions = model2.predict(X_entire)\n",
    "        Y_predictions.shape\n",
    "\n",
    "        temp = pd.DataFrame(Y_predictions)\n",
    "        output = pd.concat([output,temp],axis = 1)\n",
    "        \n",
    "    labels = labels.reset_index()\n",
    "    labels = labels.drop(columns = ['index'])\n",
    "\n",
    "    output = pd.concat([output,labels],axis = 1)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3109a2f",
   "metadata": {},
   "source": [
    "# Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4869202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/cle_train.csv'\n",
    "path_test = '../TrainTestData/cle_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/\" + \"cle_metadata_cnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda735f",
   "metadata": {},
   "source": [
    "# Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804f93fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/vir_train.csv'\n",
    "path_test = '../TrainTestData/vir_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/\" + \"vir_metadata_cnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52570f93",
   "metadata": {},
   "source": [
    "# Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26723604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/hun_train.csv'\n",
    "path_test = '../TrainTestData/hun_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/\" + \"hun_metadata_cnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c5ab4",
   "metadata": {},
   "source": [
    "# Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f326ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/swi_train.csv'\n",
    "path_test = '../TrainTestData/swi_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/\" + \"swi_metadata_cnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd9aee6",
   "metadata": {},
   "source": [
    "# RNN metadata creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df23968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wholeData(path_train,path_test):\n",
    "    #Split the data\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "    \n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "    \n",
    "    X_entire = pd.concat([X_train,X_test])\n",
    "    Y_entire = pd.concat([Y_train,Y_test])\n",
    "    return X_entire,Y_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03ded6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl(path_train, path_test):\n",
    "    #Split the data\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    list = [\"cle_rnn.h5\", \"vir_rnn.h5\", \"hun_rnn.h5\", \"swi_rnn.h5\"]\n",
    "    output = pd.DataFrame()\n",
    "    for i in list:\n",
    "        model = tf.keras.models.load_model('../Models/RNN_only/' + i)\n",
    "        model2= Sequential()\n",
    "        model2.add(SimpleRNN(units=64, return_sequences=True, input_shape=(22, 1)))\n",
    "        model2.add(SimpleRNN(units=32, return_sequences=True))\n",
    "        model2.add(SimpleRNN(units=16))\n",
    "        model2.add(Dense(units=16, activation='sigmoid'))\n",
    "        model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        X_entire,labels = wholeData(path_train,path_test)\n",
    "\n",
    "        Y_predictions = model2.predict(X_entire)\n",
    "        Y_predictions.shape\n",
    "\n",
    "        temp = pd.DataFrame(Y_predictions)\n",
    "        output = pd.concat([output,temp],axis = 1)\n",
    "        \n",
    "    labels = labels.reset_index()\n",
    "    labels = labels.drop(columns = ['index'])\n",
    "\n",
    "    output = pd.concat([output,labels],axis = 1)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb2948",
   "metadata": {},
   "source": [
    "# Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7df535e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/cle_train.csv'\n",
    "path_test = '../TrainTestData/cle_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/\" + \"cle_metadata_rnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980744d3",
   "metadata": {},
   "source": [
    "# Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4397dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/vir_train.csv'\n",
    "path_test = '../TrainTestData/vir_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/\" + \"vir_metadata_rnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c751ad",
   "metadata": {},
   "source": [
    "# Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc95a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/hun_train.csv'\n",
    "path_test = '../TrainTestData/hun_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/\" + \"hun_metadata_rnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c59b12",
   "metadata": {},
   "source": [
    "# Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df6c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/swi_train.csv'\n",
    "path_test = '../TrainTestData/swi_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/\" + \"swi_metadata_rnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e28dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7d13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "296b1ea4",
   "metadata": {},
   "source": [
    "# DNN metadata creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df624ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wholeData(path_train,path_test):\n",
    "    #Split the data\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "    \n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "    \n",
    "    X_entire = pd.concat([X_train,X_test])\n",
    "    Y_entire = pd.concat([Y_train,Y_test])\n",
    "    return X_entire,Y_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3edbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl(path_train, path_test):\n",
    "    #Split the data\n",
    "    Train = pd.read_csv(path_train)\n",
    "    Test = pd.read_csv(path_test)\n",
    "    \n",
    "    X_train = Train.iloc[:,:-1]\n",
    "    Y_train = Train.iloc[:,-1]\n",
    "\n",
    "    X_test = Test.iloc[:,:-1]\n",
    "    Y_test = Test.iloc[:,-1]\n",
    "\n",
    "    #binarize the target\n",
    "    Y_train_binary = Y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "    Y_test_binary = Y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    list = [\"cle_dnn.h5\", \"vir_dnn.h5\", \"hun_dnn.h5\", \"swi_dnn.h5\"]\n",
    "    output = pd.DataFrame()\n",
    "    for i in list:\n",
    "        model = tf.keras.models.load_model('../Models/DNN_only/' + i)\n",
    "        model2 = Sequential()\n",
    "        model2.add(Dense(64, input_shape=(22,), activation='relu'))\n",
    "        model2.add(Dense(128, activation='relu'))\n",
    "        model2.add(Dense(256, activation='relu'))\n",
    "        model2.add(Dense(16, activation='sigmoid'))\n",
    "\n",
    "        model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        X_entire,labels = wholeData(path_train,path_test)\n",
    "\n",
    "        Y_predictions = model2.predict(X_entire)\n",
    "        Y_predictions.shape\n",
    "\n",
    "        temp = pd.DataFrame(Y_predictions)\n",
    "        output = pd.concat([output,temp],axis = 1)\n",
    "        \n",
    "    labels = labels.reset_index()\n",
    "    labels = labels.drop(columns = ['index'])\n",
    "\n",
    "    output = pd.concat([output,labels],axis = 1)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb32c5",
   "metadata": {},
   "source": [
    "# Cleveland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c446d7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 667us/step\n",
      "10/10 [==============================] - 0s 555us/step\n",
      "10/10 [==============================] - 0s 667us/step\n",
      "10/10 [==============================] - 0s 555us/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/cle_train.csv'\n",
    "path_test = '../TrainTestData/cle_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/BaseMetaData/\" + \"cle_metadata_dnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285e08c",
   "metadata": {},
   "source": [
    "# Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9447aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 667us/step\n",
      "7/7 [==============================] - 0s 667us/step\n",
      "7/7 [==============================] - 0s 667us/step\n",
      "7/7 [==============================] - 0s 667us/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/vir_train.csv'\n",
    "path_test = '../TrainTestData/vir_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/BaseMetaData/\" + \"vir_metadata_dnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0779f",
   "metadata": {},
   "source": [
    "# Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe67a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 667us/step\n",
      "10/10 [==============================] - 0s 667us/step\n",
      "10/10 [==============================] - 0s 555us/step\n",
      "10/10 [==============================] - 0s 556us/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/hun_train.csv'\n",
    "path_test = '../TrainTestData/hun_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/BaseMetaData/\" + \"hun_metadata_dnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0474c6",
   "metadata": {},
   "source": [
    "# Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2745cdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1000us/step\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "4/4 [==============================] - 0s 667us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "path_train = '../TrainTestData/swi_train.csv'\n",
    "path_test = '../TrainTestData/swi_test.csv'\n",
    "\n",
    "output = tl(path_train, path_test)\n",
    "\n",
    "output.to_csv(\"../Metadata Learning/BaseMetaData/\" + \"swi_metadata_dnn.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d921ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD:MetaData Learning/Meta Data Processing.ipynb
   "version": "3.9.12"
=======
   "version": "3.9.16"
>>>>>>> 21a611729e2bbb4c4fa528c375b5b6e0c5014494:MetaData Learning/Meta Data Processing_Basedata creation.ipynb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
